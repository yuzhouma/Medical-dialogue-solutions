{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17f029d-9bfb-41e1-8154-3faa92b1ad5c",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-09-27T15:40:14.803893Z",
     "iopub.status.busy": "2025-09-27T15:40:14.803676Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.cloud.aliyuncs.com/pypi/simple\n",
      "Collecting git+https://github.com/mobiusml/hqq.git\n",
      "  Cloning https://github.com/mobiusml/hqq.git to /tmp/pip-req-build-3vs5iekv\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/mobiusml/hqq.git /tmp/pip-req-build-3vs5iekv\n",
      "  Resolved https://github.com/mobiusml/hqq.git to commit 595e5cf665d8632f2f8f59493a3a8f17f6de897d\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.11/site-packages (from hqq==0.2.8) (1.26.4)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.11/site-packages (from hqq==0.2.8) (4.67.1)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.11/site-packages (from hqq==0.2.8) (0.8.1)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/site-packages (from hqq==0.2.8) (1.10.0)\n",
      "Requirement already satisfied: transformers>=4.36.1 in /usr/local/lib/python3.11/site-packages (from hqq==0.2.8) (4.55.2)\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/site-packages (from hqq==0.2.8) (0.34.3)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/site-packages (from hqq==0.2.8) (3.1.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from transformers>=4.36.1->hqq==0.2.8) (3.18.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/site-packages (from transformers>=4.36.1->hqq==0.2.8) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/site-packages (from transformers>=4.36.1->hqq==0.2.8) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/site-packages (from transformers>=4.36.1->hqq==0.2.8) (2025.7.34)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (from transformers>=4.36.1->hqq==0.2.8) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/site-packages (from transformers>=4.36.1->hqq==0.2.8) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/site-packages (from transformers>=4.36.1->hqq==0.2.8) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/site-packages (from huggingface_hub->hqq==0.2.8) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/site-packages (from huggingface_hub->hqq==0.2.8) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/site-packages (from huggingface_hub->hqq==0.2.8) (1.1.7)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/site-packages (from accelerate->hqq==0.2.8) (7.0.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/site-packages (from accelerate->hqq==0.2.8) (2.6.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->hqq==0.2.8) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->hqq==0.2.8) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->hqq==0.2.8) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->hqq==0.2.8) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->hqq==0.2.8) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->hqq==0.2.8) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->hqq==0.2.8) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->hqq==0.2.8) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->hqq==0.2.8) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->hqq==0.2.8) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->hqq==0.2.8) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->hqq==0.2.8) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->hqq==0.2.8) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->hqq==0.2.8) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->hqq==0.2.8) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->hqq==0.2.8) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->hqq==0.2.8) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate->hqq==0.2.8) (1.3.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests->transformers>=4.36.1->hqq==0.2.8) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests->transformers>=4.36.1->hqq==0.2.8) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests->transformers>=4.36.1->hqq==0.2.8) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests->transformers>=4.36.1->hqq==0.2.8) (2025.8.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate->hqq==0.2.8) (3.0.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "开始时间: 2025-09-27 23:40:26\n",
      "\n",
      "即将执行的命令:\n",
      "CUDA_VISIBLE_DEVICES=0 swift sft --model Qwen/Qwen2.5-7B-Instruct --train_type lora --dataset /mnt/workspace/final_data/train.json --torch_dtype bfloat16 --quant_method hqq --quant_bits 4 --num_train_epochs 2 --per_device_train_batch_size 2 --per_device_eval_batch_size 1 --learning_rate 1e-4 --lora_rank 8 --lora_alpha 32 --gradient_accumulation_steps 16 --eval_steps 50 --save_steps 50 --save_total_limit 2 --logging_steps 5 --max_length 1024 --output_dir output --system You are a helpful assistant. --warmup_ratio 0.05 --dataloader_num_workers 4 --model_author swift --model_name swift-robot\n",
      "\n",
      "开始执行命令，实时日志如下：\n",
      "\n",
      "run sh: `/usr/local/bin/python /usr/local/lib/python3.11/site-packages/swift/cli/sft.py --model Qwen/Qwen2.5-7B-Instruct --train_type lora --dataset /mnt/workspace/final_data/train.json --torch_dtype bfloat16 --quant_method hqq --quant_bits 4 --num_train_epochs 2 --per_device_train_batch_size 2 --per_device_eval_batch_size 1 --learning_rate 1e-4 --lora_rank 8 --lora_alpha 32 --gradient_accumulation_steps 16 --eval_steps 50 --save_steps 50 --save_total_limit 2 --logging_steps 5 --max_length 1024 --output_dir output --system You are a helpful assistant. --warmup_ratio 0.05 --dataloader_num_workers 4 --model_author swift --model_name swift-robot`\n",
      "[INFO:swift] Successfully registered `/usr/local/lib/python3.11/site-packages/swift/llm/dataset/data/dataset_info.json`.\n",
      "[INFO:swift] rank: -1, local_rank: -1, world_size: 1, local_world_size: 1\n",
      "[INFO:swift] Downloading the model from ModelScope Hub, model_id: Qwen/Qwen2.5-7B-Instruct\n",
      "[INFO:modelscope] Target directory already exists, skipping creation.\n",
      "[INFO:swift] Loading the model using model_dir: /mnt/workspace/.cache/modelscope/models/Qwen/Qwen2___5-7B-Instruct\n",
      "[INFO:swift] Setting args.lazy_tokenize: False\n",
      "[INFO:swift] output_dir: /mnt/workspace/output/v10-20250927-234036\n",
      "[INFO:swift] Global seed set to 42\n",
      "[INFO:swift] args: TrainArguments(\n",
      "_n_gpu=-1,\n",
      "acc_strategy=token,\n",
      "accelerator_config={'dispatch_batches': False},\n",
      "adafactor=False,\n",
      "adalora_beta1=0.85,\n",
      "adalora_beta2=0.85,\n",
      "adalora_deltaT=1,\n",
      "adalora_init_r=12,\n",
      "adalora_orth_reg_weight=0.5,\n",
      "adalora_target_r=8,\n",
      "adalora_tfinal=0,\n",
      "adalora_tinit=0,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.95,\n",
      "adam_epsilon=1e-08,\n",
      "adapter_act=gelu,\n",
      "adapter_length=128,\n",
      "adapters=[],\n",
      "add_version=True,\n",
      "agent_template=None,\n",
      "aligner_lr=None,\n",
      "attn_impl=None,\n",
      "auto_find_batch_size=False,\n",
      "average_tokens_across_devices=True,\n",
      "batch_eval_metrics=False,\n",
      "bf16=True,\n",
      "bf16_full_eval=False,\n",
      "bnb_4bit_compute_dtype=torch.bfloat16,\n",
      "bnb_4bit_quant_storage=None,\n",
      "bnb_4bit_quant_type=nf4,\n",
      "bnb_4bit_use_double_quant=True,\n",
      "boft_block_num=0,\n",
      "boft_block_size=4,\n",
      "boft_dropout=0.0,\n",
      "boft_n_butterfly_factor=1,\n",
      "cached_dataset=[],\n",
      "channels=None,\n",
      "check_model=True,\n",
      "ckpt_dir=None,\n",
      "columns={},\n",
      "create_checkpoint_symlink=False,\n",
      "custom_dataset_info=[],\n",
      "custom_register_path=[],\n",
      "data_seed=42,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=4,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_prefetch_factor=None,\n",
      "dataset=['/mnt/workspace/final_data/train.json'],\n",
      "dataset_num_proc=1,\n",
      "dataset_shuffle=True,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=18000000,\n",
      "debug=None,\n",
      "deepspeed=None,\n",
      "deepspeed_autotp_size=None,\n",
      "device_map=None,\n",
      "disable_tqdm=None,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "download_mode=reuse_dataset_if_exists,\n",
      "ds3_gather_for_generation=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_dataset=[],\n",
      "eval_dataset_args=None,\n",
      "eval_delay=0,\n",
      "eval_do_concat_batches=True,\n",
      "eval_generation_config=None,\n",
      "eval_limit=None,\n",
      "eval_on_start=False,\n",
      "eval_steps=50.0,\n",
      "eval_strategy=no,\n",
      "eval_use_evalscope=False,\n",
      "eval_use_gather_object=False,\n",
      "external_plugins=[],\n",
      "fourier_n_frequency=2000,\n",
      "fourier_scaling=300.0,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "freeze_aligner=True,\n",
      "freeze_llm=False,\n",
      "freeze_parameters=[],\n",
      "freeze_parameters_ratio=0.0,\n",
      "freeze_parameters_regex=None,\n",
      "freeze_vit=True,\n",
      "fsdp=,\n",
      "fsdp_config=None,\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "galore_cos_threshold=0.4,\n",
      "galore_gamma_proj=2,\n",
      "galore_optim_per_parameter=False,\n",
      "galore_proj_bits=4,\n",
      "galore_proj_group_size=256,\n",
      "galore_proj_quant=False,\n",
      "galore_proj_type=std,\n",
      "galore_quantization=False,\n",
      "galore_queue_size=5,\n",
      "galore_rank=128,\n",
      "galore_scale=1.0,\n",
      "galore_target_modules=None,\n",
      "galore_update_proj_gap=50,\n",
      "galore_with_embedding=False,\n",
      "generation_config=None,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=16,\n",
      "gradient_checkpointing=True,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=False,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hqq_axis=None,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=None,\n",
      "hub_revision=None,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_args_error=False,\n",
      "ignore_data_skip=False,\n",
      "include_for_metrics=[],\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "init_strategy=None,\n",
      "init_weights=True,\n",
      "interleave_prob=None,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "lazy_tokenize=False,\n",
      "learning_rate=0.0001,\n",
      "length_column_name=length,\n",
      "liger_kernel_config=None,\n",
      "lisa_activated_layers=0,\n",
      "lisa_step_interval=20,\n",
      "llamapro_num_groups=None,\n",
      "llamapro_num_new_blocks=4,\n",
      "load_args=False,\n",
      "load_best_model_at_end=False,\n",
      "load_data_args=False,\n",
      "load_from_cache_file=True,\n",
      "local_rank=-1,\n",
      "local_repo_path=None,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/mnt/workspace/output/v10-20250927-234036/runs,\n",
      "logging_first_step=True,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=5,\n",
      "logging_strategy=steps,\n",
      "logprobs=False,\n",
      "lora_alpha=32,\n",
      "lora_bias=none,\n",
      "lora_dropout=0.05,\n",
      "lora_dtype=None,\n",
      "lora_ga_batch_size=2,\n",
      "lora_ga_direction=ArB2r,\n",
      "lora_ga_iters=2,\n",
      "lora_ga_max_length=1024,\n",
      "lora_ga_scale=stable,\n",
      "lora_ga_stable_gamma=16,\n",
      "lora_modules=[],\n",
      "lora_rank=8,\n",
      "lorap_lr_ratio=None,\n",
      "loss_scale=default,\n",
      "loss_type=None,\n",
      "lr_scheduler_kwargs=None,\n",
      "lr_scheduler_type=cosine,\n",
      "max_epochs=None,\n",
      "max_grad_norm=1.0,\n",
      "max_length=1024,\n",
      "max_memory={},\n",
      "max_model_len=None,\n",
      "max_new_tokens=64,\n",
      "max_pixels=None,\n",
      "max_steps=-1,\n",
      "metric=None,\n",
      "metric_for_best_model=loss,\n",
      "model=Qwen/Qwen2.5-7B-Instruct,\n",
      "model_author=['swift'],\n",
      "model_kwargs={},\n",
      "model_name=['swift-robot'],\n",
      "model_revision=None,\n",
      "model_type=qwen2_5,\n",
      "modules_to_save=[],\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "new_special_tokens=[],\n",
      "no_cuda=False,\n",
      "norm_bbox=None,\n",
      "num_beams=1,\n",
      "num_labels=None,\n",
      "num_train_epochs=2.0,\n",
      "optim=adamw_torch,\n",
      "optim_args=None,\n",
      "optim_target_modules=None,\n",
      "optimizer=None,\n",
      "output_dir=/mnt/workspace/output/v10-20250927-234036,\n",
      "overwrite_output_dir=False,\n",
      "packing=False,\n",
      "padding_free=False,\n",
      "padding_side=right,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=1,\n",
      "per_device_train_batch_size=2,\n",
      "predict_with_generate=False,\n",
      "prediction_loss_only=False,\n",
      "problem_type=None,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "quant_bits=4,\n",
      "quant_method=hqq,\n",
      "ray_scope=last,\n",
      "reft_args=None,\n",
      "reft_intervention_type=LoreftIntervention,\n",
      "reft_layer_key=None,\n",
      "reft_layers=None,\n",
      "reft_rank=4,\n",
      "remove_unused_columns=True,\n",
      "repetition_penalty=None,\n",
      "report_to=['tensorboard'],\n",
      "response_prefix=None,\n",
      "restore_callback_states_from_checkpoint=False,\n",
      "resume_from_checkpoint=None,\n",
      "resume_only_model=False,\n",
      "rope_scaling=None,\n",
      "router_aux_loss_coef=0.0,\n",
      "run_name=/mnt/workspace/output/v10-20250927-234036,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=50.0,\n",
      "save_strategy=steps,\n",
      "save_total_limit=2,\n",
      "seed=42,\n",
      "sequence_parallel_size=1,\n",
      "shuffle_buffer_size=1000,\n",
      "skip_memory_metrics=True,\n",
      "sortish_sampler=False,\n",
      "split_dataset_ratio=0.0,\n",
      "stop_words=[],\n",
      "stopping_strategy=first_exhausted,\n",
      "stream=False,\n",
      "streaming=False,\n",
      "strict=False,\n",
      "swanlab_exp_name=None,\n",
      "swanlab_lark_secret=None,\n",
      "swanlab_lark_webhook_url=None,\n",
      "swanlab_mode=cloud,\n",
      "swanlab_project=None,\n",
      "swanlab_token=<SWANLAB_TOKEN>,\n",
      "swanlab_workspace=None,\n",
      "system=You are a helpful assistant.,\n",
      "target_modules=['all-linear'],\n",
      "target_regex=None,\n",
      "task_type=causal_lm,\n",
      "temperature=0.0,\n",
      "template=qwen2_5,\n",
      "template_backend=swift,\n",
      "tf32=None,\n",
      "top_k=None,\n",
      "top_logprobs=None,\n",
      "top_p=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torch_dtype=torch.bfloat16,\n",
      "torch_empty_cache_steps=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "train_dataloader_shuffle=True,\n",
      "train_type=lora,\n",
      "trainable_parameters=[],\n",
      "trainable_parameters_regex=None,\n",
      "truncation_strategy=delete,\n",
      "tuner_backend=peft,\n",
      "use_chat_template=True,\n",
      "use_cpu=False,\n",
      "use_dora=False,\n",
      "use_galore=False,\n",
      "use_hf=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_liger_kernel=False,\n",
      "use_logits_to_keep=None,\n",
      "use_mps_device=False,\n",
      "use_rslora=False,\n",
      "use_swift_lora=False,\n",
      "val_dataset=[],\n",
      "val_dataset_shuffle=False,\n",
      "vera_d_initial=0.1,\n",
      "vera_dropout=0.0,\n",
      "vera_projection_prng_key=0,\n",
      "vera_rank=256,\n",
      "vit_gradient_checkpointing=None,\n",
      "vit_lr=None,\n",
      "warmup_ratio=0.05,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.1,\n",
      "zero_hpz_partition_size=None,\n",
      ")\n",
      "[INFO:swift] Downloading the model from ModelScope Hub, model_id: Qwen/Qwen2.5-7B-Instruct\n",
      "[INFO:modelscope] Target directory already exists, skipping creation.\n",
      "[INFO:swift] Loading the model using model_dir: /mnt/workspace/.cache/modelscope/models/Qwen/Qwen2___5-7B-Instruct\n",
      "[INFO:swift] model_kwargs: {'device_map': 'cuda:0', 'quantization_config': HqqConfig {\n",
      "  \"quant_config\": {\n",
      "    \"offload_meta\": false,\n",
      "    \"scale_quant_params\": null,\n",
      "    \"weight_quant_params\": {\n",
      "      \"axis\": 1,\n",
      "      \"channel_wise\": true,\n",
      "      \"group_size\": 64,\n",
      "      \"nbits\": 4,\n",
      "      \"optimize\": true,\n",
      "      \"round_zero\": true,\n",
      "      \"view_as_float\": false\n",
      "    },\n",
      "    \"zero_quant_params\": null\n",
      "  },\n",
      "  \"quant_method\": \"hqq\",\n",
      "  \"skip_modules\": [\n",
      "    \"lm_head\"\n",
      "  ]\n",
      "}\n",
      "}\n",
      "Downloading Model from https://www.modelscope.cn to directory: /mnt/workspace/.cache/modelscope/models/Qwen/Qwen2.5-7B-Instruct\n",
      "Downloading Model from https://www.modelscope.cn to directory: /mnt/workspace/.cache/modelscope/models/Qwen/Qwen2.5-7B-Instruct\n",
      "\n",
      "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Loading checkpoint shards:  25%|██▌       | 1/4 [00:17<00:51, 17.30s/it]\n",
      "Loading checkpoint shards:  50%|█████     | 2/4 [01:06<01:12, 36.21s/it]\n",
      "Loading checkpoint shards:  75%|███████▌  | 3/4 [01:55<00:42, 42.12s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [02:38<00:00, 42.44s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [02:38<00:00, 39.71s/it]\n",
      "[INFO:swift] model.hf_device_map: {'': device(type='cuda', index=0)}\n",
      "[INFO:swift] model_info: ModelInfo(model_type='qwen2_5', model_dir='/mnt/workspace/.cache/modelscope/models/Qwen/Qwen2___5-7B-Instruct', torch_dtype=torch.bfloat16, max_model_len=32768, quant_method=<QuantizationMethod.HQQ: 'hqq'>, quant_bits=4, rope_scaling=None, is_moe_model=False, config=Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3584,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 18944,\n",
      "  \"layer_types\": [\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\"\n",
      "  ],\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 28,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 4,\n",
      "  \"pad_token_id\": 151643,\n",
      "  \"quantization_config\": {\n",
      "    \"quant_config\": {\n",
      "      \"offload_meta\": false,\n",
      "      \"scale_quant_params\": null,\n",
      "      \"weight_quant_params\": {\n",
      "        \"axis\": 1,\n",
      "        \"channel_wise\": true,\n",
      "        \"group_size\": 64,\n",
      "        \"nbits\": 4,\n",
      "        \"optimize\": true,\n",
      "        \"round_zero\": true,\n",
      "        \"view_as_float\": false\n",
      "      },\n",
      "      \"zero_quant_params\": null\n",
      "    },\n",
      "    \"quant_method\": \"hqq\",\n",
      "    \"skip_modules\": [\n",
      "      \"lm_head\"\n",
      "    ]\n",
      "  },\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.55.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 152064\n",
      "}\n",
      ", task_type='causal_lm', num_labels=None)\n",
      "[INFO:swift] model.generation_config: GenerationConfig {\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": [\n",
      "    151645,\n",
      "    151643\n",
      "  ],\n",
      "  \"max_new_tokens\": 64,\n",
      "  \"pad_token_id\": 151643,\n",
      "  \"repetition_penalty\": 1.05\n",
      "}\n",
      "\n",
      "[INFO:swift] default_system: 'You are a helpful assistant.'\n",
      "[INFO:swift] max_length: 1024\n",
      "[INFO:swift] response_prefix: ''\n",
      "[INFO:swift] agent_template: hermes\n",
      "[INFO:swift] Start time of running main: 2025-09-27 23:43:16.627524\n",
      "[INFO:swift] swift.__version__: 3.7.1\n",
      "[INFO:swift] SelfCognitionPreprocessor has been successfully configured with name: ('swift-robot', 'swift-robot'), author: ('swift', 'swift').\n",
      "\n",
      "Generating train split: 0 examples [00:00, ? examples/s]\n",
      "Generating train split: 37361 examples [00:00, 70783.23 examples/s]\n",
      "Generating train split: 37361 examples [00:00, 70694.88 examples/s]\n",
      "\n",
      "Map:   0%|          | 0/37361 [00:00<?, ? examples/s]\n",
      "Map:  27%|██▋       | 10000/37361 [00:00<00:00, 85040.76 examples/s]\n",
      "Map:  54%|█████▎    | 20000/37361 [00:00<00:00, 87047.04 examples/s]\n",
      "Map:  80%|████████  | 30000/37361 [00:00<00:00, 87903.67 examples/s]\n",
      "Map: 100%|██████████| 37361/37361 [00:00<00:00, 83507.45 examples/s]\n",
      "[INFO:swift] train_dataset: Dataset({\n",
      "    features: ['messages'],\n",
      "    num_rows: 37361\n",
      "})\n",
      "[INFO:swift] val_dataset: None\n",
      "\n",
      "Map:   0%|          | 0/37361 [00:00<?, ? examples/s][INFO:swift] Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/dataset/preprocessor/core.py\", line 183, in batched_preprocess\n",
      "    row = self.preprocess(row)\n",
      "          ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/dataset/utils.py\", line 283, in preprocess\n",
      "    encoded = self.template.encode(row, return_length=True)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/template/base.py\", line 500, in encode\n",
      "    encoded = self._encode_truncated(inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/template/base.py\", line 1209, in _encode_truncated\n",
      "    raise MaxLengthError(f'Current length of row({length}) is larger'\n",
      "swift.llm.template.base.MaxLengthError: Current length of row(1608) is larger than the max_length(1024).\n",
      "\n",
      "[WARNING:swift] 👆👆👆There are errors in the dataset, the data will be deleted\n",
      "[INFO:swift] Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/dataset/preprocessor/core.py\", line 183, in batched_preprocess\n",
      "    row = self.preprocess(row)\n",
      "          ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/dataset/utils.py\", line 283, in preprocess\n",
      "    encoded = self.template.encode(row, return_length=True)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/template/base.py\", line 500, in encode\n",
      "    encoded = self._encode_truncated(inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/template/base.py\", line 1209, in _encode_truncated\n",
      "    raise MaxLengthError(f'Current length of row({length}) is larger'\n",
      "swift.llm.template.base.MaxLengthError: Current length of row(4405) is larger than the max_length(1024).\n",
      "\n",
      "[WARNING:swift] 👆👆👆There are errors in the dataset, the data will be deleted\n",
      "[INFO:swift] Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/dataset/preprocessor/core.py\", line 183, in batched_preprocess\n",
      "    row = self.preprocess(row)\n",
      "          ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/dataset/utils.py\", line 283, in preprocess\n",
      "    encoded = self.template.encode(row, return_length=True)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/template/base.py\", line 500, in encode\n",
      "    encoded = self._encode_truncated(inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/template/base.py\", line 1209, in _encode_truncated\n",
      "    raise MaxLengthError(f'Current length of row({length}) is larger'\n",
      "swift.llm.template.base.MaxLengthError: Current length of row(1133) is larger than the max_length(1024).\n",
      "\n",
      "[WARNING:swift] 👆👆👆There are errors in the dataset, the data will be deleted\n",
      "\n",
      "Map:   3%|▎         | 1000/37361 [00:00<00:24, 1489.76 examples/s][INFO:swift] Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/dataset/preprocessor/core.py\", line 183, in batched_preprocess\n",
      "    row = self.preprocess(row)\n",
      "          ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/dataset/utils.py\", line 283, in preprocess\n",
      "    encoded = self.template.encode(row, return_length=True)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/template/base.py\", line 500, in encode\n",
      "    encoded = self._encode_truncated(inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/template/base.py\", line 1209, in _encode_truncated\n",
      "    raise MaxLengthError(f'Current length of row({length}) is larger'\n",
      "swift.llm.template.base.MaxLengthError: Current length of row(1078) is larger than the max_length(1024).\n",
      "\n",
      "[WARNING:swift] 👆👆👆There are errors in the dataset, the data will be deleted\n",
      "[INFO:swift] Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/dataset/preprocessor/core.py\", line 183, in batched_preprocess\n",
      "    row = self.preprocess(row)\n",
      "          ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/dataset/utils.py\", line 283, in preprocess\n",
      "    encoded = self.template.encode(row, return_length=True)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/template/base.py\", line 500, in encode\n",
      "    encoded = self._encode_truncated(inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/template/base.py\", line 1209, in _encode_truncated\n",
      "    raise MaxLengthError(f'Current length of row({length}) is larger'\n",
      "swift.llm.template.base.MaxLengthError: Current length of row(2218) is larger than the max_length(1024).\n",
      "\n",
      "[WARNING:swift] 👆👆👆There are errors in the dataset, the data will be deleted\n",
      "[INFO:swift] Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/dataset/preprocessor/core.py\", line 183, in batched_preprocess\n",
      "    row = self.preprocess(row)\n",
      "          ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/dataset/utils.py\", line 283, in preprocess\n",
      "    encoded = self.template.encode(row, return_length=True)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/template/base.py\", line 500, in encode\n",
      "    encoded = self._encode_truncated(inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/template/base.py\", line 1209, in _encode_truncated\n",
      "    raise MaxLengthError(f'Current length of row({length}) is larger'\n",
      "swift.llm.template.base.MaxLengthError: Current length of row(3702) is larger than the max_length(1024).\n",
      "\n",
      "[WARNING:swift] 👆👆👆There are errors in the dataset, the data will be deleted\n",
      "[INFO:swift] Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/dataset/preprocessor/core.py\", line 183, in batched_preprocess\n",
      "    row = self.preprocess(row)\n",
      "          ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/dataset/utils.py\", line 283, in preprocess\n",
      "    encoded = self.template.encode(row, return_length=True)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/template/base.py\", line 500, in encode\n",
      "    encoded = self._encode_truncated(inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/template/base.py\", line 1209, in _encode_truncated\n",
      "    raise MaxLengthError(f'Current length of row({length}) is larger'\n",
      "swift.llm.template.base.MaxLengthError: Current length of row(1223) is larger than the max_length(1024).\n",
      "\n",
      "[WARNING:swift] 👆👆👆There are errors in the dataset, the data will be deleted\n",
      "[INFO:swift] Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/dataset/preprocessor/core.py\", line 183, in batched_preprocess\n",
      "    row = self.preprocess(row)\n",
      "          ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/dataset/utils.py\", line 283, in preprocess\n",
      "    encoded = self.template.encode(row, return_length=True)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/template/base.py\", line 500, in encode\n",
      "    encoded = self._encode_truncated(inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/template/base.py\", line 1209, in _encode_truncated\n",
      "    raise MaxLengthError(f'Current length of row({length}) is larger'\n",
      "swift.llm.template.base.MaxLengthError: Current length of row(3340) is larger than the max_length(1024).\n",
      "\n",
      "[WARNING:swift] 👆👆👆There are errors in the dataset, the data will be deleted\n",
      "\n",
      "Map:   5%|▌         | 2000/37361 [00:01<00:23, 1492.33 examples/s][INFO:swift] Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/dataset/preprocessor/core.py\", line 183, in batched_preprocess\n",
      "    row = self.preprocess(row)\n",
      "          ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/dataset/utils.py\", line 283, in preprocess\n",
      "    encoded = self.template.encode(row, return_length=True)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/template/base.py\", line 500, in encode\n",
      "    encoded = self._encode_truncated(inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/template/base.py\", line 1209, in _encode_truncated\n",
      "    raise MaxLengthError(f'Current length of row({length}) is larger'\n",
      "swift.llm.template.base.MaxLengthError: Current length of row(1263) is larger than the max_length(1024).\n",
      "\n",
      "[WARNING:swift] 👆👆👆There are errors in the dataset, the data will be deleted\n",
      "[INFO:swift] Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/dataset/preprocessor/core.py\", line 183, in batched_preprocess\n",
      "    row = self.preprocess(row)\n",
      "          ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/dataset/utils.py\", line 283, in preprocess\n",
      "    encoded = self.template.encode(row, return_length=True)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/template/base.py\", line 500, in encode\n",
      "    encoded = self._encode_truncated(inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/template/base.py\", line 1209, in _encode_truncated\n",
      "    raise MaxLengthError(f'Current length of row({length}) is larger'\n",
      "swift.llm.template.base.MaxLengthError: Current length of row(2641) is larger than the max_length(1024).\n",
      "\n",
      "[WARNING:swift] 👆👆👆There are errors in the dataset, the data will be deleted\n",
      "\n",
      "Map:   8%|▊         | 3000/37361 [00:02<00:23, 1484.87 examples/s]\n",
      "Map:  11%|█         | 4000/37361 [00:02<00:22, 1468.03 examples/s]\n",
      "Map:  13%|█▎        | 5000/37361 [00:03<00:21, 1473.89 examples/s]\n",
      "Map:  16%|█▌        | 6000/37361 [00:04<00:20, 1501.89 examples/s]\n",
      "Map:  19%|█▊        | 7000/37361 [00:04<00:20, 1511.45 examples/s]\n",
      "Map:  21%|██▏       | 8000/37361 [00:05<00:19, 1517.85 examples/s]\n",
      "Map:  24%|██▍       | 9000/37361 [00:05<00:18, 1525.92 examples/s]\n",
      "Map:  27%|██▋       | 10000/37361 [00:06<00:18, 1457.80 examples/s]\n",
      "Map:  29%|██▉       | 11000/37361 [00:07<00:18, 1454.55 examples/s]\n",
      "Map:  32%|███▏      | 12000/37361 [00:08<00:17, 1462.02 examples/s]\n",
      "Map:  35%|███▍      | 13000/37361 [00:08<00:16, 1462.98 examples/s]\n",
      "Map:  37%|███▋      | 14000/37361 [00:09<00:15, 1482.77 examples/s]\n",
      "Map:  40%|████      | 15000/37361 [00:10<00:15, 1485.05 examples/s]\n",
      "Map:  43%|████▎     | 16000/37361 [00:10<00:14, 1487.65 examples/s]\n",
      "Map:  46%|████▌     | 17000/37361 [00:11<00:13, 1481.88 examples/s]\n",
      "Map:  48%|████▊     | 18000/37361 [00:12<00:12, 1490.11 examples/s]\n",
      "Map:  51%|█████     | 19000/37361 [00:12<00:12, 1500.36 examples/s]\n",
      "Map:  54%|█████▎    | 20000/37361 [00:13<00:11, 1481.21 examples/s]\n",
      "Map:  56%|█████▌    | 21000/37361 [00:14<00:10, 1503.82 examples/s]\n",
      "Map:  59%|█████▉    | 22000/37361 [00:14<00:10, 1514.20 examples/s]\n",
      "Map:  62%|██████▏   | 23000/37361 [00:15<00:09, 1510.11 examples/s]\n",
      "Map:  64%|██████▍   | 24000/37361 [00:16<00:08, 1501.50 examples/s]\n",
      "Map:  67%|██████▋   | 25000/37361 [00:16<00:08, 1489.80 examples/s]\n",
      "Map:  70%|██████▉   | 26000/37361 [00:17<00:07, 1488.14 examples/s]\n",
      "Map:  72%|███████▏  | 27000/37361 [00:18<00:06, 1504.28 examples/s]\n",
      "Map:  75%|███████▍  | 28000/37361 [00:18<00:06, 1504.95 examples/s]\n",
      "Map:  78%|███████▊  | 29000/37361 [00:19<00:05, 1490.71 examples/s]\n",
      "Map:  80%|████████  | 30000/37361 [00:20<00:04, 1489.70 examples/s]\n",
      "Map:  83%|████████▎ | 31000/37361 [00:20<00:04, 1486.60 examples/s]\n",
      "Map:  86%|████████▌ | 32000/37361 [00:21<00:03, 1475.62 examples/s]\n",
      "Map:  88%|████████▊ | 33000/37361 [00:22<00:02, 1480.38 examples/s]\n",
      "Map:  91%|█████████ | 34000/37361 [00:22<00:02, 1479.81 examples/s]\n",
      "Map:  94%|█████████▎| 35000/37361 [00:23<00:01, 1475.05 examples/s]\n",
      "Map:  96%|█████████▋| 36000/37361 [00:24<00:00, 1488.90 examples/s]\n",
      "Map:  99%|█████████▉| 37000/37361 [00:24<00:00, 1498.03 examples/s]\n",
      "Map: 100%|██████████| 37361/37361 [00:25<00:00, 1502.75 examples/s]\n",
      "Map: 100%|██████████| 37361/37361 [00:25<00:00, 1482.54 examples/s]\n",
      "[INFO:swift] Dataset filtered, origin length: 37361, filtered dataset length: 37186\n",
      "[INFO:swift] [INPUT_IDS] [151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 99601, 56568, 101909, 106045, 104391, 103998, 37945, 100345, 101924, 103936, 107485, 99912, 9370, 100182, 101898, 28311, 70108, 3837, 19, 16, 92015, 3837, 91777, 20412, 100347, 99389, 102395, 102072, 3837, 104373, 85336, 101071, 106012, 101743, 120449, 100575, 37945, 56007, 18830, 101743, 120449, 100575, 105184, 101368, 20412, 99387, 100535, 151645, 198, 151644, 77091, 198, 101743, 120449, 100575, 73670, 110966, 42192, 100406, 99389, 102395, 3837, 104047, 18830, 102395, 64952, 102395, 99508, 102395, 100406, 101368, 3837, 103929, 101368, 102410, 20412, 102395, 45995, 101304, 100631, 113801, 3837, 101898, 56568, 112189, 99190, 102395, 106307, 33108, 99414, 71304, 104857, 101071, 3837, 114671, 113422, 87256, 71817, 101899, 1773, 99604, 113422, 100771, 101970, 101368, 3837, 101924, 85106, 100345, 101960, 106141, 104883, 26939, 105327, 44991, 100043, 100634, 71817, 72448, 101931, 9370, 101071, 3837, 109095, 32664, 99769, 101899, 1773, 104043, 101924, 101254, 85106, 104466, 118681, 5373, 101906, 99287, 100718, 114331, 99257, 5373, 101254, 104579, 108851, 116283, 101474, 64272, 106232, 5373, 100259, 107663, 33108, 42140, 100399, 103265, 1773, 151645]\n",
      "[INFO:swift] [INPUT] <|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "现在你是一个肿瘤学科医生，请根据患者的问题给出实际的医疗建议：\n",
      "男，41岁，老是出现血尿的情况，昨天去检查说是膀胱癌，请问有膀胱癌早期症状是怎样的<|im_end|>\n",
      "<|im_start|>assistant\n",
      "膀胱癌可以表现为无痛血尿，也可以有尿频尿急尿痛症状，你的症状有可能是尿路感染或者结石，建议你去医院做尿常规和彩超仔细检查，查明病因再进行治疗。不同病因引起不同的症状，患者需要根据自身病情尽快到正规三甲医院进行系统规范的检查，这样才能对症治疗。此外患者日常需要规律作息、做好防寒保暖工作、日常饮食多吃清淡稀软的食物、勤通风和多喝热水。<|im_end|>\n",
      "[INFO:swift] [LABELS_IDS] [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 101743, 120449, 100575, 73670, 110966, 42192, 100406, 99389, 102395, 3837, 104047, 18830, 102395, 64952, 102395, 99508, 102395, 100406, 101368, 3837, 103929, 101368, 102410, 20412, 102395, 45995, 101304, 100631, 113801, 3837, 101898, 56568, 112189, 99190, 102395, 106307, 33108, 99414, 71304, 104857, 101071, 3837, 114671, 113422, 87256, 71817, 101899, 1773, 99604, 113422, 100771, 101970, 101368, 3837, 101924, 85106, 100345, 101960, 106141, 104883, 26939, 105327, 44991, 100043, 100634, 71817, 72448, 101931, 9370, 101071, 3837, 109095, 32664, 99769, 101899, 1773, 104043, 101924, 101254, 85106, 104466, 118681, 5373, 101906, 99287, 100718, 114331, 99257, 5373, 101254, 104579, 108851, 116283, 101474, 64272, 106232, 5373, 100259, 107663, 33108, 42140, 100399, 103265, 1773, 151645]\n",
      "[INFO:swift] [LABELS] [-100 * 66]膀胱癌可以表现为无痛血尿，也可以有尿频尿急尿痛症状，你的症状有可能是尿路感染或者结石，建议你去医院做尿常规和彩超仔细检查，查明病因再进行治疗。不同病因引起不同的症状，患者需要根据自身病情尽快到正规三甲医院进行系统规范的检查，这样才能对症治疗。此外患者日常需要规律作息、做好防寒保暖工作、日常饮食多吃清淡稀软的食物、勤通风和多喝热水。<|im_end|>\n",
      "[INFO:swift] Dataset Token Length: 190.039477±81.113077, min=47.000000, max=1019.000000, size=37186\n",
      "[INFO:swift] The TrainArguments will be saved in: /mnt/workspace/output/v10-20250927-234036/args.json\n",
      "/usr/local/lib/python3.11/site-packages/awq/__init__.py:21: DeprecationWarning: \n",
      "I have left this message as the final dev message to help you transition.\n",
      "\n",
      "Important Notice:\n",
      "- AutoAWQ is officially deprecated and will no longer be maintained.\n",
      "- The last tested configuration used Torch 2.6.0 and Transformers 4.51.3.\n",
      "- If future versions of Transformers break AutoAWQ compatibility, please report the issue to the Transformers project.\n",
      "\n",
      "Alternative:\n",
      "- AutoAWQ has been adopted by the vLLM Project: https://github.com/vllm-project/llm-compressor\n",
      "\n",
      "For further inquiries, feel free to reach out:\n",
      "- X: https://x.com/casper_hansen_\n",
      "- LinkedIn: https://www.linkedin.com/in/casper-hansen-804005170/\n",
      "\n",
      "  warnings.warn(_FINAL_DEV_MESSAGE, category=DeprecationWarning, stacklevel=1)\n",
      "[INFO:swift] lora_config: LoraConfig(task_type='CAUSAL_LM', peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='/mnt/workspace/.cache/modelscope/models/Qwen/Qwen2___5-7B-Instruct', revision=None, inference_mode=False, r=8, target_modules={'down_proj', 'q_proj', 'gate_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj'}, exclude_modules=None, lora_alpha=32, lora_dropout=0.05, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=[], init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', trainable_token_indices=None, loftq_config={}, eva_config=None, corda_config=None, use_dora=False, use_qalora=False, qalora_group_size=16, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False), lora_bias=False, lora_dtype=None, lorap_lr_ratio=None, lorap_emb_lr=1e-06)\n",
      "[INFO:swift] model: PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): Qwen2ForCausalLM(\n",
      "      (model): Qwen2Model(\n",
      "        (embed_tokens): Embedding(152064, 3584)\n",
      "        (layers): ModuleList(\n",
      "          (0-27): 28 x Qwen2DecoderLayer(\n",
      "            (self_attn): Qwen2Attention(\n",
      "              (q_proj): lora.HqqLoraLinear(\n",
      "                (base_layer): HQQLinear(in_features=3584, out_features=3584, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=3584, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (k_proj): lora.HqqLoraLinear(\n",
      "                (base_layer): HQQLinear(in_features=3584, out_features=512, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=512, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (v_proj): lora.HqqLoraLinear(\n",
      "                (base_layer): HQQLinear(in_features=3584, out_features=512, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=512, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (o_proj): lora.HqqLoraLinear(\n",
      "                (base_layer): HQQLinear(in_features=3584, out_features=3584, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=3584, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "            )\n",
      "            (mlp): Qwen2MLP(\n",
      "              (gate_proj): lora.HqqLoraLinear(\n",
      "                (base_layer): HQQLinear(in_features=3584, out_features=18944, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=18944, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (up_proj): lora.HqqLoraLinear(\n",
      "                (base_layer): HQQLinear(in_features=3584, out_features=18944, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=18944, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (down_proj): lora.HqqLoraLinear(\n",
      "                (base_layer): HQQLinear(in_features=18944, out_features=3584, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=18944, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=3584, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "            (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "          )\n",
      "        )\n",
      "        (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "        (rotary_emb): Qwen2RotaryEmbedding()\n",
      "      )\n",
      "      (lm_head): Linear(in_features=3584, out_features=152064, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[INFO:swift] model_parameter_info: PeftModelForCausalLM: 4373.1574M Params (20.1851M Trainable [0.4616%]), 0.0001M Buffers.\n",
      "/usr/local/lib/python3.11/site-packages/swift/trainers/mixin.py:94: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(\n",
      "/usr/local/lib/python3.11/site-packages/deepspeed/ops/op_builder/builder.py:18: DeprecationWarning: The distutils.sysconfig module is deprecated, use sysconfig instead\n",
      "  import distutils.sysconfig\n",
      "[2025-09-27 23:43:45,164] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "df: /root/.triton/autotune: 没有那个文件或目录\n",
      "[2025-09-27 23:43:45,616] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\n",
      "[INFO:swift] use_reentrant: True\n",
      "[INFO:swift] The logging file will be saved in: /mnt/workspace/output/v10-20250927-234036/logging.jsonl\n",
      "\n",
      "Train:   0%|          | 0/2326 [00:00<?, ?it/s][INFO:swift] use_logits_to_keep: True\n",
      "\n",
      "Train:   0%|          | 1/2326 [00:20<13:09:26, 20.37s/it]\n",
      "                                                          \n",
      "\n",
      "Train:   0%|          | 1/2326 [00:20<13:09:26, 20.37s/it]\n",
      "Train:   0%|          | 1/2326 [00:20<13:09:26, 20.37s/it]\n",
      "Train:   0%|          | 2/2326 [00:39<12:34:29, 19.48s/it]\n",
      "Train:   0%|          | 3/2326 [00:58<12:32:28, 19.44s/it]\n",
      "Train:   0%|          | 4/2326 [01:16<12:12:57, 18.94s/it]\n",
      "Train:   0%|          | 5/2326 [01:35<12:07:34, 18.81s/it]\n",
      "                                                          \n",
      "\n",
      "Train:   0%|          | 5/2326 [01:35<12:07:34, 18.81s/it]\n",
      "Train:   0%|          | 5/2326 [01:35<12:07:34, 18.81s/it]\n",
      "Train:   0%|          | 6/2326 [01:54<12:07:38, 18.82s/it]\n",
      "Train:   0%|          | 7/2326 [02:12<12:05:10, 18.76s/it]\n",
      "Train:   0%|          | 8/2326 [02:31<12:07:32, 18.83s/it]\n",
      "Train:   0%|          | 9/2326 [02:51<12:14:04, 19.01s/it]\n",
      "Train:   0%|          | 10/2326 [03:10<12:11:41, 18.96s/it]\n",
      "                                                           \n",
      "\n",
      "Train:   0%|          | 10/2326 [03:10<12:11:41, 18.96s/it]\n",
      "Train:   0%|          | 10/2326 [03:10<12:11:41, 18.96s/it]\n",
      "Train:   0%|          | 11/2326 [03:29<12:14:16, 19.03s/it]\n",
      "Train:   1%|          | 12/2326 [03:48<12:13:30, 19.02s/it]\n",
      "Train:   1%|          | 13/2326 [04:08<12:25:26, 19.34s/it]\n",
      "Train:   1%|          | 14/2326 [04:27<12:22:48, 19.28s/it]\n",
      "Train:   1%|          | 15/2326 [04:46<12:14:44, 19.08s/it]\n",
      "                                                           \n",
      "\n",
      "Train:   1%|          | 15/2326 [04:46<12:14:44, 19.08s/it]\n",
      "Train:   1%|          | 15/2326 [04:46<12:14:44, 19.08s/it]\n",
      "Train:   1%|          | 16/2326 [05:04<12:06:53, 18.88s/it]\n",
      "Train:   1%|          | 17/2326 [05:24<12:15:10, 19.10s/it]\n",
      "Train:   1%|          | 18/2326 [05:43<12:17:02, 19.16s/it]\n",
      "Train:   1%|          | 19/2326 [06:01<12:04:16, 18.84s/it]\n",
      "Train:   1%|          | 20/2326 [06:19<11:59:29, 18.72s/it]\n",
      "                                                           \n",
      "\n",
      "Train:   1%|          | 20/2326 [06:20<11:59:29, 18.72s/it]\n",
      "Train:   1%|          | 20/2326 [06:20<11:59:29, 18.72s/it]\n",
      "Train:   1%|          | 21/2326 [06:39<12:06:09, 18.90s/it]\n",
      "Train:   1%|          | 22/2326 [06:58<12:07:55, 18.96s/it]\n",
      "Train:   1%|          | 23/2326 [07:16<11:56:20, 18.66s/it]\n",
      "Train:   1%|          | 24/2326 [07:34<11:53:47, 18.60s/it]\n",
      "Train:   1%|          | 25/2326 [07:53<11:48:51, 18.48s/it]\n",
      "                                                           \n",
      "\n",
      "Train:   1%|          | 25/2326 [07:53<11:48:51, 18.48s/it]\n",
      "Train:   1%|          | 25/2326 [07:53<11:48:51, 18.48s/it]\n",
      "Train:   1%|          | 26/2326 [08:11<11:43:54, 18.36s/it]\n",
      "Train:   1%|          | 27/2326 [08:30<12:01:13, 18.82s/it]\n",
      "Train:   1%|          | 28/2326 [08:51<12:16:45, 19.24s/it]\n",
      "Train:   1%|          | 29/2326 [09:09<12:07:28, 19.00s/it]\n",
      "Train:   1%|▏         | 30/2326 [09:30<12:23:23, 19.43s/it]\n",
      "                                                           \n",
      "\n",
      "Train:   1%|▏         | 30/2326 [09:30<12:23:23, 19.43s/it]\n",
      "Train:   1%|▏         | 30/2326 [09:30<12:23:23, 19.43s/it]\n",
      "Train:   1%|▏         | 31/2326 [09:48<12:07:43, 19.03s/it]\n",
      "Train:   1%|▏         | 32/2326 [10:06<11:56:27, 18.74s/it]\n",
      "Train:   1%|▏         | 33/2326 [10:24<11:51:04, 18.61s/it]\n",
      "Train:   1%|▏         | 34/2326 [10:42<11:41:34, 18.37s/it]\n",
      "Train:   2%|▏         | 35/2326 [11:00<11:40:02, 18.33s/it]\n",
      "                                                           \n",
      "\n",
      "Train:   2%|▏         | 35/2326 [11:00<11:40:02, 18.33s/it]\n",
      "Train:   2%|▏         | 35/2326 [11:00<11:40:02, 18.33s/it]\n",
      "Train:   2%|▏         | 36/2326 [11:19<11:44:42, 18.46s/it]\n",
      "Train:   2%|▏         | 37/2326 [11:38<11:48:10, 18.56s/it]\n",
      "Train:   2%|▏         | 38/2326 [11:57<11:52:27, 18.68s/it]\n",
      "Train:   2%|▏         | 39/2326 [12:15<11:52:10, 18.68s/it]\n",
      "Train:   2%|▏         | 40/2326 [12:35<12:04:06, 19.01s/it]\n",
      "                                                           \n",
      "\n",
      "Train:   2%|▏         | 40/2326 [12:35<12:04:06, 19.01s/it]\n",
      "Train:   2%|▏         | 40/2326 [12:35<12:04:06, 19.01s/it]\n",
      "Train:   2%|▏         | 41/2326 [12:53<11:56:23, 18.81s/it]\n",
      "Train:   2%|▏         | 42/2326 [13:12<11:57:54, 18.86s/it]\n",
      "Train:   2%|▏         | 43/2326 [13:32<12:02:48, 19.00s/it]\n",
      "Train:   2%|▏         | 44/2326 [13:51<12:00:32, 18.94s/it]\n",
      "Train:   2%|▏         | 45/2326 [14:09<11:57:45, 18.88s/it]\n",
      "                                                           \n",
      "\n",
      "Train:   2%|▏         | 45/2326 [14:09<11:57:45, 18.88s/it]\n",
      "Train:   2%|▏         | 45/2326 [14:09<11:57:45, 18.88s/it]\n",
      "Train:   2%|▏         | 46/2326 [14:28<12:00:14, 18.95s/it]\n",
      "Train:   2%|▏         | 47/2326 [14:47<11:54:51, 18.82s/it]\n",
      "Train:   2%|▏         | 48/2326 [15:06<11:53:44, 18.80s/it]\n",
      "Train:   2%|▏         | 49/2326 [15:24<11:48:55, 18.68s/it]\n",
      "Train:   2%|▏         | 50/2326 [15:43<11:48:18, 18.67s/it]\n",
      "                                                           \n",
      "\n",
      "Train:   2%|▏         | 50/2326 [15:43<11:48:18, 18.67s/it]\n",
      "Train:   2%|▏         | 50/2326 [15:43<11:48:18, 18.67s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v10-20250927-234036/checkpoint-50\n",
      "\n",
      "Train:   2%|▏         | 51/2326 [16:02<12:00:25, 19.00s/it]\n",
      "Train:   2%|▏         | 52/2326 [16:21<11:55:31, 18.88s/it]\n",
      "Train:   2%|▏         | 53/2326 [16:39<11:49:36, 18.73s/it]\n",
      "Train:   2%|▏         | 54/2326 [16:58<11:42:36, 18.55s/it]\n",
      "Train:   2%|▏         | 55/2326 [17:16<11:41:05, 18.52s/it]\n",
      "                                                           \n",
      "\n",
      "Train:   2%|▏         | 55/2326 [17:16<11:41:05, 18.52s/it]\n",
      "Train:   2%|▏         | 55/2326 [17:16<11:41:05, 18.52s/it]\n",
      "Train:   2%|▏         | 56/2326 [17:34<11:38:25, 18.46s/it]\n",
      "Train:   2%|▏         | 57/2326 [17:54<11:51:08, 18.81s/it]\n",
      "Train:   2%|▏         | 58/2326 [18:14<12:00:04, 19.05s/it]\n",
      "Train:   3%|▎         | 59/2326 [18:32<11:49:30, 18.78s/it]\n",
      "Train:   3%|▎         | 60/2326 [18:50<11:42:48, 18.61s/it]\n",
      "                                                           \n",
      "\n",
      "Train:   3%|▎         | 60/2326 [18:50<11:42:48, 18.61s/it]\n",
      "Train:   3%|▎         | 60/2326 [18:50<11:42:48, 18.61s/it]\n",
      "Train:   3%|▎         | 61/2326 [19:08<11:41:02, 18.57s/it]\n",
      "Train:   3%|▎         | 62/2326 [19:28<11:57:02, 19.00s/it]\n",
      "Train:   3%|▎         | 63/2326 [19:47<11:50:33, 18.84s/it]\n",
      "Train:   3%|▎         | 64/2326 [20:05<11:43:10, 18.65s/it]\n",
      "Train:   3%|▎         | 65/2326 [20:24<11:41:45, 18.62s/it]\n",
      "                                                           \n",
      "\n",
      "Train:   3%|▎         | 65/2326 [20:24<11:41:45, 18.62s/it]\n",
      "Train:   3%|▎         | 65/2326 [20:24<11:41:45, 18.62s/it]\n",
      "Train:   3%|▎         | 66/2326 [20:42<11:35:04, 18.45s/it]\n",
      "Train:   3%|▎         | 67/2326 [21:00<11:33:36, 18.42s/it]\n",
      "Train:   3%|▎         | 68/2326 [21:18<11:30:46, 18.36s/it]\n",
      "Train:   3%|▎         | 69/2326 [21:38<11:46:51, 18.79s/it]\n",
      "Train:   3%|▎         | 70/2326 [21:57<11:44:31, 18.74s/it]\n",
      "                                                           \n",
      "\n",
      "Train:   3%|▎         | 70/2326 [21:57<11:44:31, 18.74s/it]\n",
      "Train:   3%|▎         | 70/2326 [21:57<11:44:31, 18.74s/it]\n",
      "Train:   3%|▎         | 71/2326 [22:15<11:43:15, 18.71s/it]\n",
      "Train:   3%|▎         | 72/2326 [22:33<11:35:27, 18.51s/it]\n",
      "Train:   3%|▎         | 73/2326 [22:52<11:32:08, 18.43s/it]\n",
      "Train:   3%|▎         | 74/2326 [23:10<11:33:32, 18.48s/it]\n",
      "Train:   3%|▎         | 75/2326 [23:30<11:48:54, 18.90s/it]\n",
      "                                                           \n",
      "\n",
      "Train:   3%|▎         | 75/2326 [23:30<11:48:54, 18.90s/it]\n",
      "Train:   3%|▎         | 75/2326 [23:30<11:48:54, 18.90s/it]\n",
      "Train:   3%|▎         | 76/2326 [23:48<11:38:34, 18.63s/it]\n",
      "Train:   3%|▎         | 77/2326 [24:06<11:26:44, 18.32s/it]\n",
      "Train:   3%|▎         | 78/2326 [24:24<11:26:59, 18.34s/it]\n",
      "Train:   3%|▎         | 79/2326 [24:43<11:29:18, 18.41s/it]\n",
      "Train:   3%|▎         | 80/2326 [25:01<11:27:02, 18.35s/it]\n",
      "                                                           \n",
      "\n",
      "Train:   3%|▎         | 80/2326 [25:01<11:27:02, 18.35s/it]\n",
      "Train:   3%|▎         | 80/2326 [25:01<11:27:02, 18.35s/it]\n",
      "Train:   3%|▎         | 81/2326 [25:22<11:58:00, 19.19s/it]\n",
      "Train:   4%|▎         | 82/2326 [25:42<12:03:39, 19.35s/it]\n",
      "Train:   4%|▎         | 83/2326 [26:00<11:55:30, 19.14s/it]\n",
      "Train:   4%|▎         | 84/2326 [26:19<11:51:09, 19.03s/it]\n",
      "Train:   4%|▎         | 85/2326 [26:37<11:41:34, 18.78s/it]\n",
      "                                                           \n",
      "\n",
      "Train:   4%|▎         | 85/2326 [26:37<11:41:34, 18.78s/it]\n",
      "Train:   4%|▎         | 85/2326 [26:37<11:41:34, 18.78s/it]\n",
      "Train:   4%|▎         | 86/2326 [26:56<11:42:51, 18.83s/it]\n",
      "Train:   4%|▎         | 87/2326 [27:15<11:37:34, 18.69s/it]\n",
      "Train:   4%|▍         | 88/2326 [27:33<11:36:11, 18.66s/it]\n",
      "Train:   4%|▍         | 89/2326 [27:52<11:35:03, 18.64s/it]\n",
      "Train:   4%|▍         | 90/2326 [28:10<11:31:19, 18.55s/it]\n",
      "                                                           \n",
      "\n",
      "Train:   4%|▍         | 90/2326 [28:10<11:31:19, 18.55s/it]\n",
      "Train:   4%|▍         | 90/2326 [28:10<11:31:19, 18.55s/it]\n",
      "Train:   4%|▍         | 91/2326 [28:29<11:34:43, 18.65s/it]\n",
      "Train:   4%|▍         | 92/2326 [28:47<11:30:56, 18.56s/it]\n",
      "Train:   4%|▍         | 93/2326 [29:06<11:31:17, 18.57s/it]\n",
      "Train:   4%|▍         | 94/2326 [29:24<11:29:47, 18.54s/it]\n",
      "Train:   4%|▍         | 95/2326 [29:42<11:21:23, 18.33s/it]\n",
      "                                                           \n",
      "\n",
      "Train:   4%|▍         | 95/2326 [29:42<11:21:23, 18.33s/it]\n",
      "Train:   4%|▍         | 95/2326 [29:42<11:21:23, 18.33s/it]\n",
      "Train:   4%|▍         | 96/2326 [30:01<11:27:17, 18.49s/it]\n",
      "Train:   4%|▍         | 97/2326 [30:20<11:30:51, 18.60s/it]\n",
      "Train:   4%|▍         | 98/2326 [30:38<11:27:54, 18.53s/it]\n",
      "Train:   4%|▍         | 99/2326 [30:57<11:31:32, 18.63s/it]\n",
      "Train:   4%|▍         | 100/2326 [31:16<11:31:46, 18.65s/it]\n",
      "                                                            \n",
      "\n",
      "Train:   4%|▍         | 100/2326 [31:16<11:31:46, 18.65s/it]\n",
      "Train:   4%|▍         | 100/2326 [31:16<11:31:46, 18.65s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v10-20250927-234036/checkpoint-100\n",
      "\n",
      "Train:   4%|▍         | 101/2326 [31:35<11:38:37, 18.84s/it]\n",
      "Train:   4%|▍         | 102/2326 [31:54<11:35:50, 18.77s/it]\n",
      "Train:   4%|▍         | 103/2326 [32:12<11:31:14, 18.66s/it]\n",
      "Train:   4%|▍         | 104/2326 [32:31<11:32:11, 18.69s/it]\n",
      "Train:   5%|▍         | 105/2326 [32:49<11:24:10, 18.48s/it]\n",
      "                                                            \n",
      "\n",
      "Train:   5%|▍         | 105/2326 [32:49<11:24:10, 18.48s/it]\n",
      "Train:   5%|▍         | 105/2326 [32:49<11:24:10, 18.48s/it]\n",
      "Train:   5%|▍         | 106/2326 [33:07<11:23:18, 18.47s/it]\n",
      "Train:   5%|▍         | 107/2326 [33:26<11:28:19, 18.61s/it]\n",
      "Train:   5%|▍         | 108/2326 [33:45<11:26:05, 18.56s/it]\n",
      "Train:   5%|▍         | 109/2326 [34:03<11:22:10, 18.46s/it]\n",
      "Train:   5%|▍         | 110/2326 [34:23<11:39:04, 18.93s/it]\n",
      "                                                            \n",
      "\n",
      "Train:   5%|▍         | 110/2326 [34:23<11:39:04, 18.93s/it]\n",
      "Train:   5%|▍         | 110/2326 [34:23<11:39:04, 18.93s/it]\n",
      "Train:   5%|▍         | 111/2326 [34:42<11:38:55, 18.93s/it]\n",
      "Train:   5%|▍         | 112/2326 [35:00<11:31:00, 18.73s/it]\n",
      "Train:   5%|▍         | 113/2326 [35:19<11:29:00, 18.68s/it]\n",
      "Train:   5%|▍         | 114/2326 [35:38<11:37:51, 18.93s/it]\n",
      "Train:   5%|▍         | 115/2326 [35:57<11:37:08, 18.92s/it]\n",
      "                                                            \n",
      "\n",
      "Train:   5%|▍         | 115/2326 [35:57<11:37:08, 18.92s/it]\n",
      "Train:   5%|▍         | 115/2326 [35:57<11:37:08, 18.92s/it]\n",
      "Train:   5%|▍         | 116/2326 [36:16<11:31:05, 18.76s/it]\n",
      "Train:   5%|▌         | 117/2326 [36:35<11:35:38, 18.89s/it]\n",
      "Train:   5%|▌         | 118/2326 [36:53<11:29:22, 18.73s/it]\n",
      "Train:   5%|▌         | 119/2326 [37:13<11:38:50, 19.00s/it]\n",
      "Train:   5%|▌         | 120/2326 [37:32<11:39:35, 19.03s/it]\n",
      "                                                            \n",
      "\n",
      "Train:   5%|▌         | 120/2326 [37:32<11:39:35, 19.03s/it]\n",
      "Train:   5%|▌         | 120/2326 [37:32<11:39:35, 19.03s/it]\n",
      "Train:   5%|▌         | 121/2326 [37:50<11:32:22, 18.84s/it]\n",
      "Train:   5%|▌         | 122/2326 [38:09<11:29:02, 18.76s/it]\n",
      "Train:   5%|▌         | 123/2326 [38:28<11:29:02, 18.77s/it]\n",
      "Train:   5%|▌         | 124/2326 [38:46<11:23:20, 18.62s/it]\n",
      "Train:   5%|▌         | 125/2326 [39:05<11:23:53, 18.64s/it]\n",
      "                                                            \n",
      "\n",
      "Train:   5%|▌         | 125/2326 [39:05<11:23:53, 18.64s/it]\n",
      "Train:   5%|▌         | 125/2326 [39:05<11:23:53, 18.64s/it]\n",
      "Train:   5%|▌         | 126/2326 [39:23<11:18:14, 18.50s/it]\n",
      "Train:   5%|▌         | 127/2326 [39:40<11:08:23, 18.24s/it]\n",
      "Train:   6%|▌         | 128/2326 [39:59<11:08:33, 18.25s/it]\n",
      "Train:   6%|▌         | 129/2326 [40:17<11:10:50, 18.32s/it]\n",
      "Train:   6%|▌         | 130/2326 [40:36<11:11:45, 18.35s/it]\n",
      "                                                            \n",
      "\n",
      "Train:   6%|▌         | 130/2326 [40:36<11:11:45, 18.35s/it]\n",
      "Train:   6%|▌         | 130/2326 [40:36<11:11:45, 18.35s/it]\n",
      "Train:   6%|▌         | 131/2326 [40:55<11:18:26, 18.55s/it]\n",
      "Train:   6%|▌         | 132/2326 [41:13<11:12:13, 18.38s/it]\n",
      "Train:   6%|▌         | 133/2326 [41:31<11:16:58, 18.52s/it]\n",
      "Train:   6%|▌         | 134/2326 [41:50<11:11:23, 18.38s/it]\n",
      "Train:   6%|▌         | 135/2326 [42:07<11:04:29, 18.20s/it]\n",
      "                                                            \n",
      "\n",
      "Train:   6%|▌         | 135/2326 [42:07<11:04:29, 18.20s/it]\n",
      "Train:   6%|▌         | 135/2326 [42:07<11:04:29, 18.20s/it]\n",
      "Train:   6%|▌         | 136/2326 [42:28<11:36:59, 19.10s/it]\n",
      "Train:   6%|▌         | 137/2326 [42:48<11:38:07, 19.14s/it]\n",
      "Train:   6%|▌         | 138/2326 [43:07<11:35:15, 19.07s/it]\n",
      "Train:   6%|▌         | 139/2326 [43:25<11:30:05, 18.93s/it]\n",
      "Train:   6%|▌         | 140/2326 [43:43<11:19:39, 18.65s/it]\n",
      "                                                            \n",
      "{'loss': 2.74990797, 'token_acc': 0.46405553, 'grad_norm': 1.98719764, 'learning_rate': 8.5e-07, 'memory(GiB)': 12.28, 'train_speed(iter/s)': 0.048405, 'epoch': 0.0, 'global_step/max_steps': '1/2326', 'percentage': '0.04%', 'elapsed_time': '20s', 'remaining_time': '13h 11m 17s'}\n",
      "{'loss': 2.65041637, 'token_acc': 0.50205263, 'grad_norm': 2.33975625, 'learning_rate': 4.27e-06, 'memory(GiB)': 14.38, 'train_speed(iter/s)': 0.052273, 'epoch': 0.0, 'global_step/max_steps': '5/2326', 'percentage': '0.21%', 'elapsed_time': '1m 35s', 'remaining_time': '12h 18m 11s'}\n",
      "{'loss': 2.7518095, 'token_acc': 0.47776584, 'grad_norm': 2.21315455, 'learning_rate': 8.55e-06, 'memory(GiB)': 14.38, 'train_speed(iter/s)': 0.052534, 'epoch': 0.01, 'global_step/max_steps': '10/2326', 'percentage': '0.43%', 'elapsed_time': '3m 10s', 'remaining_time': '12h 13m 55s'}\n",
      "{'loss': 2.77283592, 'token_acc': 0.47406949, 'grad_norm': 2.25839329, 'learning_rate': 1.282e-05, 'memory(GiB)': 19.21, 'train_speed(iter/s)': 0.052381, 'epoch': 0.01, 'global_step/max_steps': '15/2326', 'percentage': '0.64%', 'elapsed_time': '4m 46s', 'remaining_time': '12h 14m 40s'}\n",
      "{'loss': 2.64194107, 'token_acc': 0.48652239, 'grad_norm': 2.0184691, 'learning_rate': 1.709e-05, 'memory(GiB)': 19.21, 'train_speed(iter/s)': 0.052599, 'epoch': 0.02, 'global_step/max_steps': '20/2326', 'percentage': '0.86%', 'elapsed_time': '6m 20s', 'remaining_time': '12h 10m 19s'}\n",
      "{'loss': 2.54986057, 'token_acc': 0.49643233, 'grad_norm': 1.11045647, 'learning_rate': 2.137e-05, 'memory(GiB)': 19.21, 'train_speed(iter/s)': 0.052821, 'epoch': 0.02, 'global_step/max_steps': '25/2326', 'percentage': '1.07%', 'elapsed_time': '7m 53s', 'remaining_time': '12h 5m 39s'}\n",
      "{'loss': 2.30566196, 'token_acc': 0.52311972, 'grad_norm': 0.62651604, 'learning_rate': 2.564e-05, 'memory(GiB)': 19.21, 'train_speed(iter/s)': 0.0526, 'epoch': 0.03, 'global_step/max_steps': '30/2326', 'percentage': '1.29%', 'elapsed_time': '9m 30s', 'remaining_time': '12h 7m 12s'}\n",
      "{'loss': 2.29855747, 'token_acc': 0.52355533, 'grad_norm': 0.69859415, 'learning_rate': 2.991e-05, 'memory(GiB)': 19.21, 'train_speed(iter/s)': 0.052961, 'epoch': 0.03, 'global_step/max_steps': '35/2326', 'percentage': '1.50%', 'elapsed_time': '11m 0s', 'remaining_time': '12h 0m 43s'}\n",
      "{'loss': 2.24285641, 'token_acc': 0.53321604, 'grad_norm': 0.67786181, 'learning_rate': 3.419e-05, 'memory(GiB)': 19.21, 'train_speed(iter/s)': 0.052922, 'epoch': 0.03, 'global_step/max_steps': '40/2326', 'percentage': '1.72%', 'elapsed_time': '12m 35s', 'remaining_time': '11h 59m 46s'}\n",
      "{'loss': 2.21846561, 'token_acc': 0.53031815, 'grad_norm': 0.66814798, 'learning_rate': 3.846e-05, 'memory(GiB)': 19.21, 'train_speed(iter/s)': 0.052939, 'epoch': 0.04, 'global_step/max_steps': '45/2326', 'percentage': '1.93%', 'elapsed_time': '14m 9s', 'remaining_time': '11h 57m 55s'}\n",
      "{'loss': 2.27530365, 'token_acc': 0.52018014, 'grad_norm': 0.78518891, 'learning_rate': 4.274e-05, 'memory(GiB)': 19.21, 'train_speed(iter/s)': 0.052996, 'epoch': 0.04, 'global_step/max_steps': '50/2326', 'percentage': '2.15%', 'elapsed_time': '15m 43s', 'remaining_time': '11h 55m 36s'}\n",
      "{'loss': 2.30655499, 'token_acc': 0.5148828, 'grad_norm': 0.58079892, 'learning_rate': 4.701e-05, 'memory(GiB)': 19.21, 'train_speed(iter/s)': 0.053047, 'epoch': 0.05, 'global_step/max_steps': '55/2326', 'percentage': '2.36%', 'elapsed_time': '17m 16s', 'remaining_time': '11h 53m 21s'}\n",
      "{'loss': 2.33985481, 'token_acc': 0.50772579, 'grad_norm': 0.61061931, 'learning_rate': 5.128e-05, 'memory(GiB)': 19.21, 'train_speed(iter/s)': 0.053064, 'epoch': 0.05, 'global_step/max_steps': '60/2326', 'percentage': '2.58%', 'elapsed_time': '18m 50s', 'remaining_time': '11h 51m 35s'}\n",
      "{'loss': 2.10374813, 'token_acc': 0.55721499, 'grad_norm': 0.6445685, 'learning_rate': 5.556e-05, 'memory(GiB)': 21.3, 'train_speed(iter/s)': 0.053086, 'epoch': 0.06, 'global_step/max_steps': '65/2326', 'percentage': '2.79%', 'elapsed_time': '20m 24s', 'remaining_time': '11h 49m 43s'}\n",
      "{'loss': 2.19006653, 'token_acc': 0.52908557, 'grad_norm': 0.71448451, 'learning_rate': 5.983e-05, 'memory(GiB)': 21.3, 'train_speed(iter/s)': 0.053133, 'epoch': 0.06, 'global_step/max_steps': '70/2326', 'percentage': '3.01%', 'elapsed_time': '21m 57s', 'remaining_time': '11h 47m 31s'}\n",
      "{'loss': 2.1288044, 'token_acc': 0.54510404, 'grad_norm': 0.62073606, 'learning_rate': 6.41e-05, 'memory(GiB)': 21.3, 'train_speed(iter/s)': 0.053159, 'epoch': 0.06, 'global_step/max_steps': '75/2326', 'percentage': '3.22%', 'elapsed_time': '23m 30s', 'remaining_time': '11h 45m 37s'}\n",
      "{'loss': 2.16403484, 'token_acc': 0.53721436, 'grad_norm': 0.74976611, 'learning_rate': 6.838e-05, 'memory(GiB)': 21.3, 'train_speed(iter/s)': 0.053275, 'epoch': 0.07, 'global_step/max_steps': '80/2326', 'percentage': '3.44%', 'elapsed_time': '25m 1s', 'remaining_time': '11h 42m 32s'}\n",
      "{'loss': 2.15340462, 'token_acc': 0.54174659, 'grad_norm': 0.70575976, 'learning_rate': 7.265e-05, 'memory(GiB)': 21.3, 'train_speed(iter/s)': 0.053187, 'epoch': 0.07, 'global_step/max_steps': '85/2326', 'percentage': '3.65%', 'elapsed_time': '26m 37s', 'remaining_time': '11h 42m 8s'}\n",
      "{'loss': 2.24128494, 'token_acc': 0.52525582, 'grad_norm': 0.64690626, 'learning_rate': 7.692e-05, 'memory(GiB)': 21.3, 'train_speed(iter/s)': 0.053224, 'epoch': 0.08, 'global_step/max_steps': '90/2326', 'percentage': '3.87%', 'elapsed_time': '28m 10s', 'remaining_time': '11h 40m 5s'}\n",
      "{'loss': 2.1318882, 'token_acc': 0.54385866, 'grad_norm': 0.85712522, 'learning_rate': 8.12e-05, 'memory(GiB)': 21.3, 'train_speed(iter/s)': 0.053278, 'epoch': 0.08, 'global_step/max_steps': '95/2326', 'percentage': '4.08%', 'elapsed_time': '29m 42s', 'remaining_time': '11h 37m 50s'}\n",
      "{'loss': 2.18384323, 'token_acc': 0.54461321, 'grad_norm': 0.94304395, 'learning_rate': 8.547e-05, 'memory(GiB)': 21.3, 'train_speed(iter/s)': 0.053284, 'epoch': 0.09, 'global_step/max_steps': '100/2326', 'percentage': '4.30%', 'elapsed_time': '31m 16s', 'remaining_time': '11h 36m 13s'}\n",
      "{'loss': 2.30297909, 'token_acc': 0.51399689, 'grad_norm': 0.86600399, 'learning_rate': 8.974e-05, 'memory(GiB)': 21.3, 'train_speed(iter/s)': 0.053305, 'epoch': 0.09, 'global_step/max_steps': '105/2326', 'percentage': '4.51%', 'elapsed_time': '32m 49s', 'remaining_time': '11h 34m 21s'}\n",
      "{'loss': 2.24295769, 'token_acc': 0.52785924, 'grad_norm': 0.72986764, 'learning_rate': 9.402e-05, 'memory(GiB)': 21.3, 'train_speed(iter/s)': 0.053298, 'epoch': 0.09, 'global_step/max_steps': '110/2326', 'percentage': '4.73%', 'elapsed_time': '34m 23s', 'remaining_time': '11h 32m 53s'}\n",
      "{'loss': 2.13007908, 'token_acc': 0.54839068, 'grad_norm': 0.88053548, 'learning_rate': 9.829e-05, 'memory(GiB)': 21.3, 'train_speed(iter/s)': 0.053289, 'epoch': 0.1, 'global_step/max_steps': '115/2326', 'percentage': '4.94%', 'elapsed_time': '35m 57s', 'remaining_time': '11h 31m 26s'}\n",
      "{'loss': 2.17111664, 'token_acc': 0.54255263, 'grad_norm': 0.85790682, 'learning_rate': 0.0001, 'memory(GiB)': 21.3, 'train_speed(iter/s)': 0.053269, 'epoch': 0.1, 'global_step/max_steps': '120/2326', 'percentage': '5.16%', 'elapsed_time': '37m 32s', 'remaining_time': '11h 30m 7s'}\n",
      "{'loss': 2.13772221, 'token_acc': 0.5462283, 'grad_norm': 0.93865544, 'learning_rate': 0.0001, 'memory(GiB)': 21.3, 'train_speed(iter/s)': 0.053295, 'epoch': 0.11, 'global_step/max_steps': '125/2326', 'percentage': '5.37%', 'elapsed_time': '39m 5s', 'remaining_time': '11h 28m 14s'}\n",
      "{'loss': 2.16889019, 'token_acc': 0.53991931, 'grad_norm': 0.94492465, 'learning_rate': 9.999e-05, 'memory(GiB)': 21.3, 'train_speed(iter/s)': 0.053357, 'epoch': 0.11, 'global_step/max_steps': '130/2326', 'percentage': '5.59%', 'elapsed_time': '40m 36s', 'remaining_time': '11h 25m 54s'}\n",
      "{'loss': 2.12635231, 'token_acc': 0.545945, 'grad_norm': 0.92547327, 'learning_rate': 9.998e-05, 'memory(GiB)': 21.3, 'train_speed(iter/s)': 0.0534, 'epoch': 0.12, 'global_step/max_steps': '135/2326', 'percentage': '5.80%', 'elapsed_time': '42m 7s', 'remaining_time': '11h 23m 45s'}\n",
      "{'loss': 2.21260242, 'token_acc': 0.53093885, 'grad_norm': 0.95080084, 'learning_rate': 9.997e-05, 'memory(GiB)': 21.3, 'train_speed(iter/s)': 0.053353, 'epoch': 0.12, 'global_step/max_steps': '140/2326', 'percentage': '6.02%', 'elapsed_time': '43m 43s', 'remaining_time': '11h 22m 48s'}\n",
      "Train:   6%|▌         | 140/2326 [43:43<11:19:39, 18.65s/it]\n",
      "Train:   6%|▌         | 140/2326 [43:43<11:19:39, 18.65s/it]\n",
      "Train:   6%|▌         | 141/2326 [44:03<11:36:21, 19.12s/it]\n",
      "Train:   6%|▌         | 142/2326 [44:22<11:25:45, 18.84s/it]\n",
      "Train:   6%|▌         | 143/2326 [44:40<11:24:38, 18.82s/it]\n",
      "Train:   6%|▌         | 144/2326 [44:59<11:19:30, 18.68s/it]\n",
      "Train:   6%|▌         | 145/2326 [45:17<11:10:48, 18.45s/it]\n",
      "                                                            \n",
      "\n",
      "Train:   6%|▌         | 145/2326 [45:17<11:10:48, 18.45s/it]\n",
      "Train:   6%|▌         | 145/2326 [45:17<11:10:48, 18.45s/it]\n",
      "Train:   6%|▋         | 146/2326 [45:35<11:10:05, 18.44s/it]\n",
      "Train:   6%|▋         | 147/2326 [45:55<11:24:02, 18.84s/it]\n",
      "Train:   6%|▋         | 148/2326 [46:15<11:33:33, 19.11s/it]\n",
      "Train:   6%|▋         | 149/2326 [46:33<11:29:56, 19.02s/it]\n",
      "Train:   6%|▋         | 150/2326 [46:53<11:33:23, 19.12s/it]\n",
      "                                                            \n",
      "\n",
      "Train:   6%|▋         | 150/2326 [46:53<11:33:23, 19.12s/it]\n",
      "Train:   6%|▋         | 150/2326 [46:53<11:33:23, 19.12s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v10-20250927-234036/checkpoint-150\n",
      "\n",
      "Train:   6%|▋         | 151/2326 [47:12<11:34:21, 19.15s/it]\n",
      "Train:   7%|▋         | 152/2326 [47:31<11:27:28, 18.97s/it]\n",
      "Train:   7%|▋         | 153/2326 [47:50<11:35:56, 19.22s/it]\n",
      "Train:   7%|▋         | 154/2326 [48:10<11:44:24, 19.46s/it]\n",
      "Train:   7%|▋         | 155/2326 [48:29<11:32:23, 19.14s/it]\n",
      "                                                            \n",
      "\n",
      "Train:   7%|▋         | 155/2326 [48:29<11:32:23, 19.14s/it]\n",
      "Train:   7%|▋         | 155/2326 [48:29<11:32:23, 19.14s/it]\n",
      "Train:   7%|▋         | 156/2326 [48:48<11:31:27, 19.12s/it]\n",
      "Train:   7%|▋         | 157/2326 [49:07<11:35:07, 19.23s/it]\n",
      "Train:   7%|▋         | 158/2326 [49:27<11:34:27, 19.22s/it]\n",
      "Train:   7%|▋         | 159/2326 [49:46<11:40:32, 19.40s/it]\n",
      "Train:   7%|▋         | 160/2326 [50:05<11:28:26, 19.07s/it]\n",
      "                                                            \n",
      "\n",
      "Train:   7%|▋         | 160/2326 [50:05<11:28:26, 19.07s/it]\n",
      "Train:   7%|▋         | 160/2326 [50:05<11:28:26, 19.07s/it]\n",
      "Train:   7%|▋         | 161/2326 [50:23<11:25:53, 19.01s/it]\n",
      "Train:   7%|▋         | 162/2326 [50:42<11:19:15, 18.83s/it]\n",
      "Train:   7%|▋         | 163/2326 [51:01<11:16:16, 18.76s/it]\n",
      "Train:   7%|▋         | 164/2326 [51:20<11:19:34, 18.86s/it]\n",
      "Train:   7%|▋         | 165/2326 [51:38<11:14:41, 18.73s/it]\n",
      "                                                            \n",
      "\n",
      "Train:   7%|▋         | 165/2326 [51:38<11:14:41, 18.73s/it]\n",
      "Train:   7%|▋         | 165/2326 [51:38<11:14:41, 18.73s/it]\n",
      "Train:   7%|▋         | 166/2326 [51:57<11:13:01, 18.70s/it]\n",
      "Train:   7%|▋         | 167/2326 [52:17<11:25:28, 19.05s/it]\n",
      "Train:   7%|▋         | 168/2326 [52:35<11:20:03, 18.91s/it]\n",
      "Train:   7%|▋         | 169/2326 [52:53<11:07:42, 18.57s/it]\n",
      "Train:   7%|▋         | 170/2326 [53:12<11:08:06, 18.59s/it]\n",
      "                                                            \n",
      "\n",
      "Train:   7%|▋         | 170/2326 [53:12<11:08:06, 18.59s/it]\n",
      "Train:   7%|▋         | 170/2326 [53:12<11:08:06, 18.59s/it]\n",
      "Train:   7%|▋         | 171/2326 [53:29<10:59:53, 18.37s/it]\n",
      "Train:   7%|▋         | 172/2326 [53:50<11:24:33, 19.07s/it]\n",
      "Train:   7%|▋         | 173/2326 [54:10<11:28:30, 19.19s/it]\n",
      "Train:   7%|▋         | 174/2326 [54:28<11:21:00, 18.99s/it]\n",
      "Train:   8%|▊         | 175/2326 [54:46<11:13:14, 18.78s/it]\n",
      "                                                            \n",
      "\n",
      "Train:   8%|▊         | 175/2326 [54:46<11:13:14, 18.78s/it]\n",
      "Train:   8%|▊         | 175/2326 [54:46<11:13:14, 18.78s/it]\n",
      "Train:   8%|▊         | 176/2326 [55:05<11:09:51, 18.69s/it]\n",
      "Train:   8%|▊         | 177/2326 [55:23<10:59:40, 18.42s/it]\n",
      "Train:   8%|▊         | 178/2326 [55:42<11:08:58, 18.69s/it]\n",
      "Train:   8%|▊         | 179/2326 [56:00<11:04:10, 18.56s/it]\n",
      "Train:   8%|▊         | 180/2326 [56:19<11:06:41, 18.64s/it]\n",
      "                                                            \n",
      "\n",
      "Train:   8%|▊         | 180/2326 [56:19<11:06:41, 18.64s/it]\n",
      "Train:   8%|▊         | 180/2326 [56:19<11:06:41, 18.64s/it]\n",
      "Train:   8%|▊         | 181/2326 [56:38<11:11:38, 18.79s/it]\n",
      "Train:   8%|▊         | 182/2326 [56:56<11:06:22, 18.65s/it]\n",
      "Train:   8%|▊         | 183/2326 [57:14<10:56:32, 18.38s/it]\n",
      "Train:   8%|▊         | 184/2326 [57:32<10:54:49, 18.34s/it]\n",
      "Train:   8%|▊         | 185/2326 [57:51<11:00:15, 18.50s/it]\n",
      "                                                            \n",
      "\n",
      "Train:   8%|▊         | 185/2326 [57:51<11:00:15, 18.50s/it]\n",
      "Train:   8%|▊         | 185/2326 [57:51<11:00:15, 18.50s/it]\n",
      "Train:   8%|▊         | 186/2326 [58:10<11:00:47, 18.53s/it]\n",
      "Train:   8%|▊         | 187/2326 [58:29<11:04:09, 18.63s/it]\n",
      "Train:   8%|▊         | 188/2326 [58:47<11:04:04, 18.64s/it]\n",
      "Train:   8%|▊         | 189/2326 [59:06<10:59:10, 18.51s/it]\n",
      "Train:   8%|▊         | 190/2326 [59:24<11:01:12, 18.57s/it]\n",
      "                                                            \n",
      "\n",
      "Train:   8%|▊         | 190/2326 [59:24<11:01:12, 18.57s/it]\n",
      "Train:   8%|▊         | 190/2326 [59:24<11:01:12, 18.57s/it]\n",
      "Train:   8%|▊         | 191/2326 [59:45<11:19:36, 19.10s/it]\n",
      "Train:   8%|▊         | 192/2326 [1:00:03<11:12:23, 18.91s/it]\n",
      "Train:   8%|▊         | 193/2326 [1:00:21<11:01:07, 18.60s/it]\n",
      "Train:   8%|▊         | 194/2326 [1:00:40<11:07:52, 18.80s/it]\n",
      "Train:   8%|▊         | 195/2326 [1:00:59<11:05:51, 18.75s/it]\n",
      "                                                              \n",
      "\n",
      "Train:   8%|▊         | 195/2326 [1:00:59<11:05:51, 18.75s/it]\n",
      "Train:   8%|▊         | 195/2326 [1:00:59<11:05:51, 18.75s/it]\n",
      "Train:   8%|▊         | 196/2326 [1:01:18<11:04:44, 18.72s/it]\n",
      "Train:   8%|▊         | 197/2326 [1:01:36<11:01:18, 18.64s/it]\n",
      "Train:   9%|▊         | 198/2326 [1:01:54<10:55:55, 18.49s/it]\n",
      "Train:   9%|▊         | 199/2326 [1:02:13<10:57:29, 18.55s/it]\n",
      "Train:   9%|▊         | 200/2326 [1:02:31<10:50:36, 18.36s/it]\n",
      "                                                              \n",
      "\n",
      "Train:   9%|▊         | 200/2326 [1:02:31<10:50:36, 18.36s/it]\n",
      "Train:   9%|▊         | 200/2326 [1:02:31<10:50:36, 18.36s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v10-20250927-234036/checkpoint-200\n",
      "\n",
      "Train:   9%|▊         | 201/2326 [1:02:50<11:01:57, 18.69s/it]\n",
      "Train:   9%|▊         | 202/2326 [1:03:09<11:01:23, 18.68s/it]\n",
      "Train:   9%|▊         | 203/2326 [1:03:27<10:55:58, 18.54s/it]\n",
      "Train:   9%|▉         | 204/2326 [1:03:45<10:52:46, 18.46s/it]\n",
      "Train:   9%|▉         | 205/2326 [1:04:04<10:50:36, 18.40s/it]\n",
      "                                                              \n",
      "\n",
      "Train:   9%|▉         | 205/2326 [1:04:04<10:50:36, 18.40s/it]\n",
      "Train:   9%|▉         | 205/2326 [1:04:04<10:50:36, 18.40s/it]\n",
      "Train:   9%|▉         | 206/2326 [1:04:22<10:48:27, 18.35s/it]\n",
      "Train:   9%|▉         | 207/2326 [1:04:40<10:48:34, 18.36s/it]\n",
      "Train:   9%|▉         | 208/2326 [1:04:59<10:49:11, 18.39s/it]\n",
      "Train:   9%|▉         | 209/2326 [1:05:19<11:05:57, 18.87s/it]\n",
      "Train:   9%|▉         | 210/2326 [1:05:38<11:05:12, 18.86s/it]\n",
      "                                                              \n",
      "\n",
      "Train:   9%|▉         | 210/2326 [1:05:38<11:05:12, 18.86s/it]\n",
      "Train:   9%|▉         | 210/2326 [1:05:38<11:05:12, 18.86s/it]\n",
      "Train:   9%|▉         | 211/2326 [1:05:56<10:55:43, 18.60s/it]\n",
      "Train:   9%|▉         | 212/2326 [1:06:13<10:46:17, 18.34s/it]\n",
      "Train:   9%|▉         | 213/2326 [1:06:31<10:38:08, 18.12s/it]\n",
      "Train:   9%|▉         | 214/2326 [1:06:49<10:37:09, 18.10s/it]\n",
      "Train:   9%|▉         | 215/2326 [1:07:10<11:05:53, 18.93s/it]\n",
      "                                                              \n",
      "\n",
      "Train:   9%|▉         | 215/2326 [1:07:10<11:05:53, 18.93s/it]\n",
      "Train:   9%|▉         | 215/2326 [1:07:10<11:05:53, 18.93s/it]\n",
      "Train:   9%|▉         | 216/2326 [1:07:29<11:09:59, 19.05s/it]\n",
      "Train:   9%|▉         | 217/2326 [1:07:48<11:06:22, 18.96s/it]\n",
      "Train:   9%|▉         | 218/2326 [1:08:06<10:57:51, 18.72s/it]\n",
      "Train:   9%|▉         | 219/2326 [1:08:26<11:06:56, 18.99s/it]\n",
      "Train:   9%|▉         | 220/2326 [1:08:43<10:52:53, 18.60s/it]\n",
      "                                                              \n",
      "\n",
      "Train:   9%|▉         | 220/2326 [1:08:43<10:52:53, 18.60s/it]\n",
      "Train:   9%|▉         | 220/2326 [1:08:43<10:52:53, 18.60s/it]\n",
      "Train:  10%|▉         | 221/2326 [1:09:02<10:51:27, 18.57s/it]\n",
      "Train:  10%|▉         | 222/2326 [1:09:21<10:58:10, 18.77s/it]\n",
      "Train:  10%|▉         | 223/2326 [1:09:40<11:01:35, 18.88s/it]\n",
      "Train:  10%|▉         | 224/2326 [1:10:00<11:06:00, 19.01s/it]\n",
      "Train:  10%|▉         | 225/2326 [1:10:19<11:14:05, 19.25s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  10%|▉         | 225/2326 [1:10:19<11:14:05, 19.25s/it]\n",
      "Train:  10%|▉         | 225/2326 [1:10:19<11:14:05, 19.25s/it]\n",
      "Train:  10%|▉         | 226/2326 [1:10:39<11:20:25, 19.44s/it]\n",
      "Train:  10%|▉         | 227/2326 [1:10:58<11:09:39, 19.14s/it]\n",
      "Train:  10%|▉         | 228/2326 [1:11:15<10:53:47, 18.70s/it]\n",
      "Train:  10%|▉         | 229/2326 [1:11:33<10:46:45, 18.51s/it]\n",
      "Train:  10%|▉         | 230/2326 [1:11:52<10:46:48, 18.52s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  10%|▉         | 230/2326 [1:11:52<10:46:48, 18.52s/it]\n",
      "Train:  10%|▉         | 230/2326 [1:11:52<10:46:48, 18.52s/it]\n",
      "Train:  10%|▉         | 231/2326 [1:12:13<11:16:23, 19.37s/it]\n",
      "Train:  10%|▉         | 232/2326 [1:12:32<11:11:41, 19.25s/it]\n",
      "Train:  10%|█         | 233/2326 [1:12:51<11:03:00, 19.01s/it]\n",
      "Train:  10%|█         | 234/2326 [1:13:09<10:51:34, 18.69s/it]\n",
      "Train:  10%|█         | 235/2326 [1:13:27<10:51:30, 18.69s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  10%|█         | 235/2326 [1:13:27<10:51:30, 18.69s/it]\n",
      "Train:  10%|█         | 235/2326 [1:13:27<10:51:30, 18.69s/it]\n",
      "Train:  10%|█         | 236/2326 [1:13:46<10:52:45, 18.74s/it]\n",
      "Train:  10%|█         | 237/2326 [1:14:04<10:46:36, 18.57s/it]\n",
      "Train:  10%|█         | 238/2326 [1:14:23<10:50:45, 18.70s/it]\n",
      "Train:  10%|█         | 239/2326 [1:14:42<10:45:00, 18.54s/it]\n",
      "Train:  10%|█         | 240/2326 [1:15:00<10:46:47, 18.60s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  10%|█         | 240/2326 [1:15:00<10:46:47, 18.60s/it]\n",
      "Train:  10%|█         | 240/2326 [1:15:00<10:46:47, 18.60s/it]\n",
      "Train:  10%|█         | 241/2326 [1:15:22<11:23:01, 19.66s/it]\n",
      "Train:  10%|█         | 242/2326 [1:15:41<11:11:44, 19.34s/it]\n",
      "Train:  10%|█         | 243/2326 [1:15:59<10:57:03, 18.93s/it]\n",
      "Train:  10%|█         | 244/2326 [1:16:17<10:44:45, 18.58s/it]\n",
      "Train:  11%|█         | 245/2326 [1:16:35<10:37:40, 18.39s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  11%|█         | 245/2326 [1:16:35<10:37:40, 18.39s/it]\n",
      "Train:  11%|█         | 245/2326 [1:16:35<10:37:40, 18.39s/it]\n",
      "Train:  11%|█         | 246/2326 [1:16:55<10:52:42, 18.83s/it]\n",
      "Train:  11%|█         | 247/2326 [1:17:14<10:55:18, 18.91s/it]\n",
      "Train:  11%|█         | 248/2326 [1:17:32<10:52:56, 18.85s/it]\n",
      "Train:  11%|█         | 249/2326 [1:17:51<10:52:59, 18.86s/it]\n",
      "Train:  11%|█         | 250/2326 [1:18:10<10:50:20, 18.80s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  11%|█         | 250/2326 [1:18:10<10:50:20, 18.80s/it]\n",
      "Train:  11%|█         | 250/2326 [1:18:10<10:50:20, 18.80s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v10-20250927-234036/checkpoint-250\n",
      "\n",
      "Train:  11%|█         | 251/2326 [1:18:29<10:56:42, 18.99s/it]\n",
      "Train:  11%|█         | 252/2326 [1:18:48<10:51:05, 18.84s/it]\n",
      "Train:  11%|█         | 253/2326 [1:19:05<10:36:40, 18.43s/it]\n",
      "Train:  11%|█         | 254/2326 [1:19:25<10:48:15, 18.77s/it]\n",
      "Train:  11%|█         | 255/2326 [1:19:43<10:35:50, 18.42s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  11%|█         | 255/2326 [1:19:43<10:35:50, 18.42s/it]\n",
      "Train:  11%|█         | 255/2326 [1:19:43<10:35:50, 18.42s/it]\n",
      "Train:  11%|█         | 256/2326 [1:20:01<10:35:02, 18.41s/it]\n",
      "Train:  11%|█         | 257/2326 [1:20:19<10:36:03, 18.45s/it]\n",
      "Train:  11%|█         | 258/2326 [1:20:39<10:42:16, 18.63s/it]\n",
      "Train:  11%|█         | 259/2326 [1:20:58<10:47:22, 18.79s/it]\n",
      "Train:  11%|█         | 260/2326 [1:21:17<10:50:18, 18.89s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  11%|█         | 260/2326 [1:21:17<10:50:18, 18.89s/it]\n",
      "Train:  11%|█         | 260/2326 [1:21:17<10:50:18, 18.89s/it]\n",
      "Train:  11%|█         | 261/2326 [1:21:35<10:41:02, 18.63s/it]\n",
      "Train:  11%|█▏        | 262/2326 [1:21:57<11:13:24, 19.58s/it]\n",
      "Train:  11%|█▏        | 263/2326 [1:22:15<11:04:29, 19.33s/it]\n",
      "Train:  11%|█▏        | 264/2326 [1:22:34<10:57:58, 19.15s/it]\n",
      "Train:  11%|█▏        | 265/2326 [1:22:54<11:01:20, 19.25s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  11%|█▏        | 265/2326 [1:22:54<11:01:20, 19.25s/it]\n",
      "Train:  11%|█▏        | 265/2326 [1:22:54<11:01:20, 19.25s/it]\n",
      "Train:  11%|█▏        | 266/2326 [1:23:12<10:51:01, 18.96s/it]\n",
      "Train:  11%|█▏        | 267/2326 [1:23:30<10:41:41, 18.70s/it]\n",
      "Train:  12%|█▏        | 268/2326 [1:23:48<10:33:13, 18.46s/it]\n",
      "Train:  12%|█▏        | 269/2326 [1:24:07<10:39:40, 18.66s/it]\n",
      "Train:  12%|█▏        | 270/2326 [1:24:26<10:45:16, 18.83s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  12%|█▏        | 270/2326 [1:24:26<10:45:16, 18.83s/it]\n",
      "Train:  12%|█▏        | 270/2326 [1:24:26<10:45:16, 18.83s/it]\n",
      "Train:  12%|█▏        | 271/2326 [1:24:46<10:59:09, 19.25s/it]\n",
      "Train:  12%|█▏        | 272/2326 [1:25:04<10:44:55, 18.84s/it]\n",
      "Train:  12%|█▏        | 273/2326 [1:25:23<10:47:54, 18.94s/it]\n",
      "Train:  12%|█▏        | 274/2326 [1:25:42<10:41:18, 18.75s/it]\n",
      "Train:  12%|█▏        | 275/2326 [1:26:00<10:35:50, 18.60s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  12%|█▏        | 275/2326 [1:26:00<10:35:50, 18.60s/it]\n",
      "Train:  12%|█▏        | 275/2326 [1:26:00<10:35:50, 18.60s/it]\n",
      "Train:  12%|█▏        | 276/2326 [1:26:19<10:37:18, 18.65s/it]\n",
      "Train:  12%|█▏        | 277/2326 [1:26:40<11:02:07, 19.39s/it]\n",
      "Train:  12%|█▏        | 278/2326 [1:26:59<10:54:50, 19.18s/it]\n",
      "Train:  12%|█▏        | 279/2326 [1:27:17<10:45:02, 18.91s/it]\n",
      "Train:  12%|█▏        | 280/2326 [1:27:36<10:42:34, 18.84s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  12%|█▏        | 280/2326 [1:27:36<10:42:34, 18.84s/it]\n",
      "Train:  12%|█▏        | 280/2326 [1:27:36<10:42:34, 18.84s/it]\n",
      "Train:  12%|█▏        | 281/2326 [1:27:54<10:34:33, 18.62s/it]\n",
      "Train:  12%|█▏        | 282/2326 [1:28:14<10:47:00, 18.99s/it]\n",
      "Train:  12%|█▏        | 283/2326 [1:28:32<10:43:38, 18.90s/it]\n",
      "Train:  12%|█▏        | 284/2326 [1:28:52<10:49:56, 19.10s/it]\n",
      "Train:  12%|█▏        | 285/2326 [1:29:10<10:40:58, 18.84s/it]\n",
      "                                                              \n",
      "{'loss': 2.13659058, 'token_acc': 0.54936444, 'grad_norm': 1.01597083, 'learning_rate': 9.996e-05, 'memory(GiB)': 21.3, 'train_speed(iter/s)': 0.053358, 'epoch': 0.12, 'global_step/max_steps': '145/2326', 'percentage': '6.23%', 'elapsed_time': '45m 17s', 'remaining_time': '11h 21m 11s'}\n",
      "{'loss': 2.04869862, 'token_acc': 0.56445887, 'grad_norm': 0.83913201, 'learning_rate': 9.994e-05, 'memory(GiB)': 21.3, 'train_speed(iter/s)': 0.053313, 'epoch': 0.13, 'global_step/max_steps': '150/2326', 'percentage': '6.45%', 'elapsed_time': '46m 53s', 'remaining_time': '11h 20m 11s'}\n",
      "{'loss': 2.11502953, 'token_acc': 0.55125222, 'grad_norm': 0.96466696, 'learning_rate': 9.993e-05, 'memory(GiB)': 21.3, 'train_speed(iter/s)': 0.053273, 'epoch': 0.13, 'global_step/max_steps': '155/2326', 'percentage': '6.66%', 'elapsed_time': '48m 29s', 'remaining_time': '11h 19m 9s'}\n",
      "{'loss': 2.07468796, 'token_acc': 0.55230506, 'grad_norm': 1.0231334, 'learning_rate': 9.991e-05, 'memory(GiB)': 21.3, 'train_speed(iter/s)': 0.053237, 'epoch': 0.14, 'global_step/max_steps': '160/2326', 'percentage': '6.88%', 'elapsed_time': '50m 5s', 'remaining_time': '11h 18m 2s'}\n",
      "{'loss': 2.06063137, 'token_acc': 0.56274933, 'grad_norm': 0.94978577, 'learning_rate': 9.988e-05, 'memory(GiB)': 21.3, 'train_speed(iter/s)': 0.053246, 'epoch': 0.14, 'global_step/max_steps': '165/2326', 'percentage': '7.09%', 'elapsed_time': '51m 38s', 'remaining_time': '11h 16m 22s'}\n",
      "{'loss': 2.26380215, 'token_acc': 0.52120474, 'grad_norm': 0.9831838, 'learning_rate': 9.986e-05, 'memory(GiB)': 21.3, 'train_speed(iter/s)': 0.053253, 'epoch': 0.15, 'global_step/max_steps': '170/2326', 'percentage': '7.31%', 'elapsed_time': '53m 12s', 'remaining_time': '11h 14m 43s'}\n",
      "{'loss': 2.17412891, 'token_acc': 0.53081967, 'grad_norm': 0.92769092, 'learning_rate': 9.983e-05, 'memory(GiB)': 21.3, 'train_speed(iter/s)': 0.053238, 'epoch': 0.15, 'global_step/max_steps': '175/2326', 'percentage': '7.52%', 'elapsed_time': '54m 46s', 'remaining_time': '11h 13m 20s'}\n",
      "{'loss': 2.08872337, 'token_acc': 0.55977219, 'grad_norm': 1.07970202, 'learning_rate': 9.98e-05, 'memory(GiB)': 21.3, 'train_speed(iter/s)': 0.053257, 'epoch': 0.15, 'global_step/max_steps': '180/2326', 'percentage': '7.74%', 'elapsed_time': '56m 19s', 'remaining_time': '11h 11m 31s'}\n",
      "{'loss': 2.1433012, 'token_acc': 0.54696195, 'grad_norm': 1.04804528, 'learning_rate': 9.977e-05, 'memory(GiB)': 21.3, 'train_speed(iter/s)': 0.053281, 'epoch': 0.16, 'global_step/max_steps': '185/2326', 'percentage': '7.95%', 'elapsed_time': '57m 51s', 'remaining_time': '11h 9m 40s'}\n",
      "{'loss': 2.01246872, 'token_acc': 0.57564413, 'grad_norm': 0.98817819, 'learning_rate': 9.973e-05, 'memory(GiB)': 21.3, 'train_speed(iter/s)': 0.053293, 'epoch': 0.16, 'global_step/max_steps': '190/2326', 'percentage': '8.17%', 'elapsed_time': '59m 24s', 'remaining_time': '11h 7m 57s'}\n",
      "{'loss': 2.1579113, 'token_acc': 0.53497326, 'grad_norm': 1.06788051, 'learning_rate': 9.969e-05, 'memory(GiB)': 21.3, 'train_speed(iter/s)': 0.053282, 'epoch': 0.17, 'global_step/max_steps': '195/2326', 'percentage': '8.38%', 'elapsed_time': '1h 0m 59s', 'remaining_time': '11h 6m 31s'}\n",
      "{'loss': 2.24264069, 'token_acc': 0.52387688, 'grad_norm': 1.03776515, 'learning_rate': 9.965e-05, 'memory(GiB)': 21.3, 'train_speed(iter/s)': 0.05331, 'epoch': 0.17, 'global_step/max_steps': '200/2326', 'percentage': '8.60%', 'elapsed_time': '1h 2m 31s', 'remaining_time': '11h 4m 37s'}\n",
      "{'loss': 2.13820343, 'token_acc': 0.54348602, 'grad_norm': 0.98213518, 'learning_rate': 9.961e-05, 'memory(GiB)': 21.3, 'train_speed(iter/s)': 0.053323, 'epoch': 0.18, 'global_step/max_steps': '205/2326', 'percentage': '8.81%', 'elapsed_time': '1h 4m 4s', 'remaining_time': '11h 2m 54s'}\n",
      "{'loss': 2.15551891, 'token_acc': 0.54111914, 'grad_norm': 0.90092587, 'learning_rate': 9.956e-05, 'memory(GiB)': 21.3, 'train_speed(iter/s)': 0.053321, 'epoch': 0.18, 'global_step/max_steps': '210/2326', 'percentage': '9.03%', 'elapsed_time': '1h 5m 38s', 'remaining_time': '11h 1m 21s'}\n",
      "{'loss': 2.1464592, 'token_acc': 0.54259961, 'grad_norm': 0.85310179, 'learning_rate': 9.952e-05, 'memory(GiB)': 21.3, 'train_speed(iter/s)': 0.053341, 'epoch': 0.19, 'global_step/max_steps': '215/2326', 'percentage': '9.24%', 'elapsed_time': '1h 7m 10s', 'remaining_time': '10h 59m 32s'}\n",
      "{'loss': 2.0106617, 'token_acc': 0.57358956, 'grad_norm': 1.15534365, 'learning_rate': 9.946e-05, 'memory(GiB)': 21.3, 'train_speed(iter/s)': 0.053344, 'epoch': 0.19, 'global_step/max_steps': '220/2326', 'percentage': '9.46%', 'elapsed_time': '1h 8m 43s', 'remaining_time': '10h 57m 57s'}\n",
      "{'loss': 2.05804005, 'token_acc': 0.56091308, 'grad_norm': 1.12192118, 'learning_rate': 9.941e-05, 'memory(GiB)': 21.3, 'train_speed(iter/s)': 0.053315, 'epoch': 0.19, 'global_step/max_steps': '225/2326', 'percentage': '9.67%', 'elapsed_time': '1h 10m 19s', 'remaining_time': '10h 56m 45s'}\n",
      "{'loss': 2.15878544, 'token_acc': 0.53544289, 'grad_norm': 1.10610199, 'learning_rate': 9.936e-05, 'memory(GiB)': 21.3, 'train_speed(iter/s)': 0.05333, 'epoch': 0.2, 'global_step/max_steps': '230/2326', 'percentage': '9.89%', 'elapsed_time': '1h 11m 52s', 'remaining_time': '10h 55m 0s'}\n",
      "{'loss': 2.08140202, 'token_acc': 0.55297733, 'grad_norm': 1.0828073, 'learning_rate': 9.93e-05, 'memory(GiB)': 21.3, 'train_speed(iter/s)': 0.05331, 'epoch': 0.2, 'global_step/max_steps': '235/2326', 'percentage': '10.10%', 'elapsed_time': '1h 13m 27s', 'remaining_time': '10h 53m 41s'}\n",
      "{'loss': 2.03267899, 'token_acc': 0.57307142, 'grad_norm': 0.97819787, 'learning_rate': 9.924e-05, 'memory(GiB)': 21.3, 'train_speed(iter/s)': 0.05332, 'epoch': 0.21, 'global_step/max_steps': '240/2326', 'percentage': '10.32%', 'elapsed_time': '1h 15m 0s', 'remaining_time': '10h 52m 0s'}\n",
      "{'loss': 2.11862278, 'token_acc': 0.55441271, 'grad_norm': 1.09755147, 'learning_rate': 9.917e-05, 'memory(GiB)': 21.3, 'train_speed(iter/s)': 0.053313, 'epoch': 0.21, 'global_step/max_steps': '245/2326', 'percentage': '10.53%', 'elapsed_time': '1h 16m 35s', 'remaining_time': '10h 50m 32s'}\n",
      "{'loss': 2.08345108, 'token_acc': 0.55449706, 'grad_norm': 1.13511753, 'learning_rate': 9.911e-05, 'memory(GiB)': 21.3, 'train_speed(iter/s)': 0.053296, 'epoch': 0.22, 'global_step/max_steps': '250/2326', 'percentage': '10.75%', 'elapsed_time': '1h 18m 10s', 'remaining_time': '10h 49m 10s'}\n",
      "{'loss': 2.10857563, 'token_acc': 0.54992404, 'grad_norm': 1.03640211, 'learning_rate': 9.904e-05, 'memory(GiB)': 21.3, 'train_speed(iter/s)': 0.05331, 'epoch': 0.22, 'global_step/max_steps': '255/2326', 'percentage': '10.96%', 'elapsed_time': '1h 19m 43s', 'remaining_time': '10h 47m 26s'}\n",
      "{'loss': 2.12102222, 'token_acc': 0.54470005, 'grad_norm': 1.12057769, 'learning_rate': 9.897e-05, 'memory(GiB)': 21.3, 'train_speed(iter/s)': 0.053305, 'epoch': 0.22, 'global_step/max_steps': '260/2326', 'percentage': '11.18%', 'elapsed_time': '1h 21m 17s', 'remaining_time': '10h 45m 56s'}\n",
      "{'loss': 2.12322826, 'token_acc': 0.5409546, 'grad_norm': 0.94225979, 'learning_rate': 9.89e-05, 'memory(GiB)': 21.3, 'train_speed(iter/s)': 0.053273, 'epoch': 0.23, 'global_step/max_steps': '265/2326', 'percentage': '11.39%', 'elapsed_time': '1h 22m 54s', 'remaining_time': '10h 44m 45s'}\n",
      "{'loss': 2.04425011, 'token_acc': 0.57012416, 'grad_norm': 0.99843752, 'learning_rate': 9.882e-05, 'memory(GiB)': 21.3, 'train_speed(iter/s)': 0.053286, 'epoch': 0.23, 'global_step/max_steps': '270/2326', 'percentage': '11.61%', 'elapsed_time': '1h 24m 26s', 'remaining_time': '10h 43m 2s'}\n",
      "{'loss': 2.00021839, 'token_acc': 0.57199936, 'grad_norm': 1.05645585, 'learning_rate': 9.874e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053286, 'epoch': 0.24, 'global_step/max_steps': '275/2326', 'percentage': '11.82%', 'elapsed_time': '1h 26m 0s', 'remaining_time': '10h 41m 28s'}\n",
      "{'loss': 2.00813942, 'token_acc': 0.56920048, 'grad_norm': 1.16644943, 'learning_rate': 9.866e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053269, 'epoch': 0.24, 'global_step/max_steps': '280/2326', 'percentage': '12.04%', 'elapsed_time': '1h 27m 36s', 'remaining_time': '10h 40m 8s'}\n",
      "{'loss': 2.01567383, 'token_acc': 0.56893248, 'grad_norm': 1.22240162, 'learning_rate': 9.858e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053263, 'epoch': 0.25, 'global_step/max_steps': '285/2326', 'percentage': '12.25%', 'elapsed_time': '1h 29m 10s', 'remaining_time': '10h 38m 37s'}\n",
      "Train:  12%|█▏        | 285/2326 [1:29:10<10:40:58, 18.84s/it]\n",
      "Train:  12%|█▏        | 285/2326 [1:29:10<10:40:58, 18.84s/it]\n",
      "Train:  12%|█▏        | 286/2326 [1:29:29<10:37:07, 18.74s/it]\n",
      "Train:  12%|█▏        | 287/2326 [1:29:47<10:37:14, 18.75s/it]\n",
      "Train:  12%|█▏        | 288/2326 [1:30:07<10:41:44, 18.89s/it]\n",
      "Train:  12%|█▏        | 289/2326 [1:30:27<10:56:38, 19.34s/it]\n",
      "Train:  12%|█▏        | 290/2326 [1:30:45<10:47:52, 19.09s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  12%|█▏        | 290/2326 [1:30:45<10:47:52, 19.09s/it]\n",
      "Train:  12%|█▏        | 290/2326 [1:30:45<10:47:52, 19.09s/it]\n",
      "Train:  13%|█▎        | 291/2326 [1:31:04<10:42:30, 18.94s/it]\n",
      "Train:  13%|█▎        | 292/2326 [1:31:23<10:39:05, 18.85s/it]\n",
      "Train:  13%|█▎        | 293/2326 [1:31:41<10:34:07, 18.71s/it]\n",
      "Train:  13%|█▎        | 294/2326 [1:32:00<10:36:32, 18.80s/it]\n",
      "Train:  13%|█▎        | 295/2326 [1:32:19<10:35:34, 18.78s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  13%|█▎        | 295/2326 [1:32:19<10:35:34, 18.78s/it]\n",
      "Train:  13%|█▎        | 295/2326 [1:32:19<10:35:34, 18.78s/it]\n",
      "Train:  13%|█▎        | 296/2326 [1:32:39<10:47:45, 19.15s/it]\n",
      "Train:  13%|█▎        | 297/2326 [1:32:57<10:40:04, 18.93s/it]\n",
      "Train:  13%|█▎        | 298/2326 [1:33:15<10:31:52, 18.69s/it]\n",
      "Train:  13%|█▎        | 299/2326 [1:33:34<10:26:15, 18.54s/it]\n",
      "Train:  13%|█▎        | 300/2326 [1:33:52<10:26:56, 18.57s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  13%|█▎        | 300/2326 [1:33:52<10:26:56, 18.57s/it]\n",
      "Train:  13%|█▎        | 300/2326 [1:33:52<10:26:56, 18.57s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v10-20250927-234036/checkpoint-300\n",
      "\n",
      "Train:  13%|█▎        | 301/2326 [1:34:12<10:36:37, 18.86s/it]\n",
      "Train:  13%|█▎        | 302/2326 [1:34:31<10:41:22, 19.01s/it]\n",
      "Train:  13%|█▎        | 303/2326 [1:34:49<10:33:13, 18.78s/it]\n",
      "Train:  13%|█▎        | 304/2326 [1:35:08<10:32:50, 18.78s/it]\n",
      "Train:  13%|█▎        | 305/2326 [1:35:27<10:29:42, 18.70s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  13%|█▎        | 305/2326 [1:35:27<10:29:42, 18.70s/it]\n",
      "Train:  13%|█▎        | 305/2326 [1:35:27<10:29:42, 18.70s/it]\n",
      "Train:  13%|█▎        | 306/2326 [1:35:45<10:27:59, 18.65s/it]\n",
      "Train:  13%|█▎        | 307/2326 [1:36:04<10:30:48, 18.75s/it]\n",
      "Train:  13%|█▎        | 308/2326 [1:36:23<10:34:33, 18.87s/it]\n",
      "Train:  13%|█▎        | 309/2326 [1:36:43<10:44:28, 19.17s/it]\n",
      "Train:  13%|█▎        | 310/2326 [1:37:02<10:39:01, 19.02s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  13%|█▎        | 310/2326 [1:37:02<10:39:01, 19.02s/it]\n",
      "Train:  13%|█▎        | 310/2326 [1:37:02<10:39:01, 19.02s/it]\n",
      "Train:  13%|█▎        | 311/2326 [1:37:20<10:34:14, 18.89s/it]\n",
      "Train:  13%|█▎        | 312/2326 [1:37:39<10:34:00, 18.89s/it]\n",
      "Train:  13%|█▎        | 313/2326 [1:37:58<10:34:22, 18.91s/it]\n",
      "Train:  13%|█▎        | 314/2326 [1:38:17<10:30:39, 18.81s/it]\n",
      "Train:  14%|█▎        | 315/2326 [1:38:35<10:29:01, 18.77s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  14%|█▎        | 315/2326 [1:38:36<10:29:01, 18.77s/it]\n",
      "Train:  14%|█▎        | 315/2326 [1:38:36<10:29:01, 18.77s/it]\n",
      "Train:  14%|█▎        | 316/2326 [1:38:54<10:23:00, 18.60s/it]\n",
      "Train:  14%|█▎        | 317/2326 [1:39:12<10:20:19, 18.53s/it]\n",
      "Train:  14%|█▎        | 318/2326 [1:39:30<10:19:13, 18.50s/it]\n",
      "Train:  14%|█▎        | 319/2326 [1:39:49<10:18:50, 18.50s/it]\n",
      "Train:  14%|█▍        | 320/2326 [1:40:07<10:15:31, 18.41s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  14%|█▍        | 320/2326 [1:40:07<10:15:31, 18.41s/it]\n",
      "Train:  14%|█▍        | 320/2326 [1:40:07<10:15:31, 18.41s/it]\n",
      "Train:  14%|█▍        | 321/2326 [1:40:26<10:16:11, 18.44s/it]\n",
      "Train:  14%|█▍        | 322/2326 [1:40:45<10:19:51, 18.56s/it]\n",
      "Train:  14%|█▍        | 323/2326 [1:41:03<10:22:47, 18.66s/it]\n",
      "Train:  14%|█▍        | 324/2326 [1:41:22<10:25:53, 18.76s/it]\n",
      "Train:  14%|█▍        | 325/2326 [1:41:41<10:23:28, 18.70s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  14%|█▍        | 325/2326 [1:41:41<10:23:28, 18.70s/it]\n",
      "Train:  14%|█▍        | 325/2326 [1:41:41<10:23:28, 18.70s/it]\n",
      "Train:  14%|█▍        | 326/2326 [1:42:01<10:40:03, 19.20s/it]\n",
      "Train:  14%|█▍        | 327/2326 [1:42:19<10:26:52, 18.82s/it]\n",
      "Train:  14%|█▍        | 328/2326 [1:42:38<10:25:41, 18.79s/it]\n",
      "Train:  14%|█▍        | 329/2326 [1:43:00<10:57:02, 19.74s/it]\n",
      "Train:  14%|█▍        | 330/2326 [1:43:19<10:47:13, 19.46s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  14%|█▍        | 330/2326 [1:43:19<10:47:13, 19.46s/it]\n",
      "Train:  14%|█▍        | 330/2326 [1:43:19<10:47:13, 19.46s/it]\n",
      "Train:  14%|█▍        | 331/2326 [1:43:37<10:39:57, 19.25s/it]\n",
      "Train:  14%|█▍        | 332/2326 [1:43:56<10:30:44, 18.98s/it]\n",
      "Train:  14%|█▍        | 333/2326 [1:44:14<10:19:49, 18.66s/it]\n",
      "Train:  14%|█▍        | 334/2326 [1:44:32<10:12:52, 18.46s/it]\n",
      "Train:  14%|█▍        | 335/2326 [1:44:50<10:13:02, 18.47s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  14%|█▍        | 335/2326 [1:44:50<10:13:02, 18.47s/it]\n",
      "Train:  14%|█▍        | 335/2326 [1:44:50<10:13:02, 18.47s/it]\n",
      "Train:  14%|█▍        | 336/2326 [1:45:10<10:23:36, 18.80s/it]\n",
      "Train:  14%|█▍        | 337/2326 [1:45:28<10:21:56, 18.76s/it]\n",
      "Train:  15%|█▍        | 338/2326 [1:45:48<10:34:02, 19.14s/it]\n",
      "Train:  15%|█▍        | 339/2326 [1:46:07<10:23:16, 18.82s/it]\n",
      "Train:  15%|█▍        | 340/2326 [1:46:25<10:18:17, 18.68s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  15%|█▍        | 340/2326 [1:46:25<10:18:17, 18.68s/it]\n",
      "Train:  15%|█▍        | 340/2326 [1:46:25<10:18:17, 18.68s/it]\n",
      "Train:  15%|█▍        | 341/2326 [1:46:44<10:20:06, 18.74s/it]\n",
      "Train:  15%|█▍        | 342/2326 [1:47:02<10:12:39, 18.53s/it]\n",
      "Train:  15%|█▍        | 343/2326 [1:47:21<10:16:16, 18.65s/it]\n",
      "Train:  15%|█▍        | 344/2326 [1:47:39<10:16:11, 18.65s/it]\n",
      "Train:  15%|█▍        | 345/2326 [1:48:00<10:30:36, 19.10s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  15%|█▍        | 345/2326 [1:48:00<10:30:36, 19.10s/it]\n",
      "Train:  15%|█▍        | 345/2326 [1:48:00<10:30:36, 19.10s/it]\n",
      "Train:  15%|█▍        | 346/2326 [1:48:19<10:33:58, 19.21s/it]\n",
      "Train:  15%|█▍        | 347/2326 [1:48:39<10:38:09, 19.35s/it]\n",
      "Train:  15%|█▍        | 348/2326 [1:48:56<10:21:06, 18.84s/it]\n",
      "Train:  15%|█▌        | 349/2326 [1:49:16<10:27:21, 19.04s/it]\n",
      "Train:  15%|█▌        | 350/2326 [1:49:35<10:22:59, 18.92s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  15%|█▌        | 350/2326 [1:49:35<10:22:59, 18.92s/it]\n",
      "Train:  15%|█▌        | 350/2326 [1:49:35<10:22:59, 18.92s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v10-20250927-234036/checkpoint-350\n",
      "\n",
      "Train:  15%|█▌        | 351/2326 [1:49:55<10:33:59, 19.26s/it]\n",
      "Train:  15%|█▌        | 352/2326 [1:50:13<10:23:21, 18.95s/it]\n",
      "Train:  15%|█▌        | 353/2326 [1:50:31<10:17:16, 18.77s/it]\n",
      "Train:  15%|█▌        | 354/2326 [1:50:50<10:19:08, 18.84s/it]\n",
      "Train:  15%|█▌        | 355/2326 [1:51:08<10:11:39, 18.62s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  15%|█▌        | 355/2326 [1:51:08<10:11:39, 18.62s/it]\n",
      "Train:  15%|█▌        | 355/2326 [1:51:08<10:11:39, 18.62s/it]\n",
      "Train:  15%|█▌        | 356/2326 [1:51:27<10:09:23, 18.56s/it]\n",
      "Train:  15%|█▌        | 357/2326 [1:51:45<10:04:57, 18.43s/it]\n",
      "Train:  15%|█▌        | 358/2326 [1:52:03<9:59:46, 18.29s/it] \n",
      "Train:  15%|█▌        | 359/2326 [1:52:21<9:55:39, 18.17s/it]\n",
      "Train:  15%|█▌        | 360/2326 [1:52:39<9:56:14, 18.20s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  15%|█▌        | 360/2326 [1:52:39<9:56:14, 18.20s/it]\n",
      "Train:  15%|█▌        | 360/2326 [1:52:39<9:56:14, 18.20s/it]\n",
      "Train:  16%|█▌        | 361/2326 [1:52:58<10:00:20, 18.33s/it]\n",
      "Train:  16%|█▌        | 362/2326 [1:53:16<10:01:29, 18.38s/it]\n",
      "Train:  16%|█▌        | 363/2326 [1:53:37<10:22:18, 19.02s/it]\n",
      "Train:  16%|█▌        | 364/2326 [1:53:55<10:20:50, 18.99s/it]\n",
      "Train:  16%|█▌        | 365/2326 [1:54:14<10:17:38, 18.90s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  16%|█▌        | 365/2326 [1:54:14<10:17:38, 18.90s/it]\n",
      "Train:  16%|█▌        | 365/2326 [1:54:14<10:17:38, 18.90s/it]\n",
      "Train:  16%|█▌        | 366/2326 [1:54:32<10:08:14, 18.62s/it]\n",
      "Train:  16%|█▌        | 367/2326 [1:54:50<9:58:43, 18.34s/it] \n",
      "Train:  16%|█▌        | 368/2326 [1:55:09<10:03:23, 18.49s/it]\n",
      "Train:  16%|█▌        | 369/2326 [1:55:28<10:13:14, 18.80s/it]\n",
      "Train:  16%|█▌        | 370/2326 [1:55:47<10:12:33, 18.79s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  16%|█▌        | 370/2326 [1:55:47<10:12:33, 18.79s/it]\n",
      "Train:  16%|█▌        | 370/2326 [1:55:47<10:12:33, 18.79s/it]\n",
      "Train:  16%|█▌        | 371/2326 [1:56:06<10:10:41, 18.74s/it]\n",
      "Train:  16%|█▌        | 372/2326 [1:56:24<10:03:57, 18.55s/it]\n",
      "Train:  16%|█▌        | 373/2326 [1:56:42<9:57:51, 18.37s/it] \n",
      "Train:  16%|█▌        | 374/2326 [1:57:01<10:03:39, 18.56s/it]\n",
      "Train:  16%|█▌        | 375/2326 [1:57:19<9:59:18, 18.43s/it] \n",
      "                                                             \n",
      "\n",
      "Train:  16%|█▌        | 375/2326 [1:57:19<9:59:18, 18.43s/it]\n",
      "Train:  16%|█▌        | 375/2326 [1:57:19<9:59:18, 18.43s/it]\n",
      "Train:  16%|█▌        | 376/2326 [1:57:38<10:05:48, 18.64s/it]\n",
      "Train:  16%|█▌        | 377/2326 [1:57:57<10:09:41, 18.77s/it]\n",
      "Train:  16%|█▋        | 378/2326 [1:58:16<10:16:06, 18.98s/it]\n",
      "Train:  16%|█▋        | 379/2326 [1:58:36<10:22:49, 19.19s/it]\n",
      "Train:  16%|█▋        | 380/2326 [1:58:55<10:17:42, 19.05s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  16%|█▋        | 380/2326 [1:58:55<10:17:42, 19.05s/it]\n",
      "Train:  16%|█▋        | 380/2326 [1:58:55<10:17:42, 19.05s/it]\n",
      "Train:  16%|█▋        | 381/2326 [1:59:13<10:06:57, 18.72s/it]\n",
      "Train:  16%|█▋        | 382/2326 [1:59:33<10:19:32, 19.12s/it]\n",
      "Train:  16%|█▋        | 383/2326 [1:59:53<10:30:31, 19.47s/it]\n",
      "Train:  17%|█▋        | 384/2326 [2:00:11<10:16:08, 19.04s/it]\n",
      "Train:  17%|█▋        | 385/2326 [2:00:31<10:20:51, 19.19s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  17%|█▋        | 385/2326 [2:00:31<10:20:51, 19.19s/it]\n",
      "Train:  17%|█▋        | 385/2326 [2:00:31<10:20:51, 19.19s/it]\n",
      "Train:  17%|█▋        | 386/2326 [2:00:50<10:22:03, 19.24s/it]\n",
      "Train:  17%|█▋        | 387/2326 [2:01:08<10:11:52, 18.93s/it]\n",
      "Train:  17%|█▋        | 388/2326 [2:01:27<10:06:49, 18.79s/it]\n",
      "Train:  17%|█▋        | 389/2326 [2:01:45<10:03:18, 18.69s/it]\n",
      "Train:  17%|█▋        | 390/2326 [2:02:03<9:54:31, 18.43s/it] \n",
      "                                                             \n",
      "\n",
      "Train:  17%|█▋        | 390/2326 [2:02:03<9:54:31, 18.43s/it]\n",
      "Train:  17%|█▋        | 390/2326 [2:02:03<9:54:31, 18.43s/it]\n",
      "Train:  17%|█▋        | 391/2326 [2:02:21<9:50:08, 18.30s/it]\n",
      "Train:  17%|█▋        | 392/2326 [2:02:39<9:49:17, 18.28s/it]\n",
      "Train:  17%|█▋        | 393/2326 [2:02:57<9:47:21, 18.23s/it]\n",
      "Train:  17%|█▋        | 394/2326 [2:03:15<9:44:51, 18.16s/it]\n",
      "Train:  17%|█▋        | 395/2326 [2:03:34<9:52:41, 18.42s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  17%|█▋        | 395/2326 [2:03:34<9:52:41, 18.42s/it]\n",
      "Train:  17%|█▋        | 395/2326 [2:03:34<9:52:41, 18.42s/it]\n",
      "Train:  17%|█▋        | 396/2326 [2:03:52<9:49:35, 18.33s/it]\n",
      "Train:  17%|█▋        | 397/2326 [2:04:11<9:55:40, 18.53s/it]\n",
      "Train:  17%|█▋        | 398/2326 [2:04:30<9:54:54, 18.51s/it]\n",
      "Train:  17%|█▋        | 399/2326 [2:04:49<9:58:15, 18.63s/it]\n",
      "Train:  17%|█▋        | 400/2326 [2:05:07<9:56:04, 18.57s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  17%|█▋        | 400/2326 [2:05:07<9:56:04, 18.57s/it]\n",
      "Train:  17%|█▋        | 400/2326 [2:05:07<9:56:04, 18.57s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v10-20250927-234036/checkpoint-400\n",
      "\n",
      "Train:  17%|█▋        | 401/2326 [2:05:28<10:16:28, 19.22s/it]\n",
      "Train:  17%|█▋        | 402/2326 [2:05:46<10:06:06, 18.90s/it]\n",
      "Train:  17%|█▋        | 403/2326 [2:06:05<10:04:48, 18.87s/it]\n",
      "Train:  17%|█▋        | 404/2326 [2:06:25<10:11:15, 19.08s/it]\n",
      "Train:  17%|█▋        | 405/2326 [2:06:43<10:05:55, 18.93s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  17%|█▋        | 405/2326 [2:06:43<10:05:55, 18.93s/it]\n",
      "Train:  17%|█▋        | 405/2326 [2:06:43<10:05:55, 18.93s/it]\n",
      "Train:  17%|█▋        | 406/2326 [2:07:02<10:04:08, 18.88s/it]\n",
      "Train:  17%|█▋        | 407/2326 [2:07:21<10:03:03, 18.86s/it]\n",
      "Train:  18%|█▊        | 408/2326 [2:07:41<10:13:10, 19.18s/it]\n",
      "Train:  18%|█▊        | 409/2326 [2:08:00<10:16:01, 19.28s/it]\n",
      "Train:  18%|█▊        | 410/2326 [2:08:18<10:05:07, 18.95s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  18%|█▊        | 410/2326 [2:08:18<10:05:07, 18.95s/it]\n",
      "Train:  18%|█▊        | 410/2326 [2:08:18<10:05:07, 18.95s/it]\n",
      "Train:  18%|█▊        | 411/2326 [2:08:36<9:56:41, 18.70s/it] \n",
      "Train:  18%|█▊        | 412/2326 [2:08:56<10:04:00, 18.93s/it]\n",
      "Train:  18%|█▊        | 413/2326 [2:09:15<10:00:40, 18.84s/it]\n",
      "Train:  18%|█▊        | 414/2326 [2:09:34<10:05:20, 19.00s/it]\n",
      "Train:  18%|█▊        | 415/2326 [2:09:52<9:59:04, 18.81s/it] \n",
      "                                                             \n",
      "\n",
      "Train:  18%|█▊        | 415/2326 [2:09:52<9:59:04, 18.81s/it]\n",
      "Train:  18%|█▊        | 415/2326 [2:09:52<9:59:04, 18.81s/it]\n",
      "Train:  18%|█▊        | 416/2326 [2:10:13<10:15:51, 19.35s/it]\n",
      "Train:  18%|█▊        | 417/2326 [2:10:30<9:58:23, 18.81s/it] \n",
      "Train:  18%|█▊        | 418/2326 [2:10:48<9:50:14, 18.56s/it]\n",
      "Train:  18%|█▊        | 419/2326 [2:11:07<9:53:47, 18.68s/it]\n",
      "Train:  18%|█▊        | 420/2326 [2:11:26<9:54:07, 18.70s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  18%|█▊        | 420/2326 [2:11:26<9:54:07, 18.70s/it]\n",
      "Train:  18%|█▊        | 420/2326 [2:11:26<9:54:07, 18.70s/it]\n",
      "Train:  18%|█▊        | 421/2326 [2:11:45<9:54:39, 18.73s/it]\n",
      "Train:  18%|█▊        | 422/2326 [2:12:05<10:04:22, 19.05s/it]\n",
      "Train:  18%|█▊        | 423/2326 [2:12:23<9:56:25, 18.81s/it] \n",
      "Train:  18%|█▊        | 424/2326 [2:12:41<9:49:50, 18.61s/it]\n",
      "Train:  18%|█▊        | 425/2326 [2:13:00<9:52:03, 18.69s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  18%|█▊        | 425/2326 [2:13:00<9:52:03, 18.69s/it]\n",
      "Train:  18%|█▊        | 425/2326 [2:13:00<9:52:03, 18.69s/it]\n",
      "Train:  18%|█▊        | 426/2326 [2:13:18<9:50:03, 18.63s/it]\n",
      "Train:  18%|█▊        | 427/2326 [2:13:37<9:50:49, 18.67s/it]\n",
      "Train:  18%|█▊        | 428/2326 [2:13:55<9:45:31, 18.51s/it]\n",
      "Train:  18%|█▊        | 429/2326 [2:14:14<9:50:53, 18.69s/it]\n",
      "Train:  18%|█▊        | 430/2326 [2:14:33<9:45:12, 18.52s/it]\n",
      "                                                             \n",
      "{'loss': 2.17551346, 'token_acc': 0.54293051, 'grad_norm': 1.28242755, 'learning_rate': 9.849e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053248, 'epoch': 0.25, 'global_step/max_steps': '290/2326', 'percentage': '12.47%', 'elapsed_time': '1h 30m 45s', 'remaining_time': '10h 37m 14s'}\n",
      "{'loss': 2.00423107, 'token_acc': 0.57442508, 'grad_norm': 1.03709948, 'learning_rate': 9.841e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053253, 'epoch': 0.25, 'global_step/max_steps': '295/2326', 'percentage': '12.68%', 'elapsed_time': '1h 32m 19s', 'remaining_time': '10h 35m 37s'}\n",
      "{'loss': 2.13529854, 'token_acc': 0.54130547, 'grad_norm': 1.07670605, 'learning_rate': 9.832e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053258, 'epoch': 0.26, 'global_step/max_steps': '300/2326', 'percentage': '12.90%', 'elapsed_time': '1h 33m 52s', 'remaining_time': '10h 33m 59s'}\n",
      "{'loss': 2.11206245, 'token_acc': 0.55008701, 'grad_norm': 0.93585962, 'learning_rate': 9.822e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053253, 'epoch': 0.26, 'global_step/max_steps': '305/2326', 'percentage': '13.11%', 'elapsed_time': '1h 35m 27s', 'remaining_time': '10h 32m 29s'}\n",
      "{'loss': 2.15524273, 'token_acc': 0.54381388, 'grad_norm': 1.25197494, 'learning_rate': 9.813e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053241, 'epoch': 0.27, 'global_step/max_steps': '310/2326', 'percentage': '13.33%', 'elapsed_time': '1h 37m 2s', 'remaining_time': '10h 31m 4s'}\n",
      "{'loss': 2.02463512, 'token_acc': 0.56785295, 'grad_norm': 1.25350296, 'learning_rate': 9.803e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053243, 'epoch': 0.27, 'global_step/max_steps': '315/2326', 'percentage': '13.54%', 'elapsed_time': '1h 38m 36s', 'remaining_time': '10h 29m 28s'}\n",
      "{'loss': 2.10346184, 'token_acc': 0.55468705, 'grad_norm': 1.09992898, 'learning_rate': 9.793e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053263, 'epoch': 0.28, 'global_step/max_steps': '320/2326', 'percentage': '13.76%', 'elapsed_time': '1h 40m 7s', 'remaining_time': '10h 27m 40s'}\n",
      "{'loss': 2.03080063, 'token_acc': 0.56637762, 'grad_norm': 1.26210451, 'learning_rate': 9.783e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053264, 'epoch': 0.28, 'global_step/max_steps': '325/2326', 'percentage': '13.97%', 'elapsed_time': '1h 41m 41s', 'remaining_time': '10h 26m 6s'}\n",
      "{'loss': 2.23476658, 'token_acc': 0.53564317, 'grad_norm': 1.22772133, 'learning_rate': 9.772e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.05323, 'epoch': 0.28, 'global_step/max_steps': '330/2326', 'percentage': '14.19%', 'elapsed_time': '1h 43m 19s', 'remaining_time': '10h 24m 56s'}\n",
      "{'loss': 1.91435566, 'token_acc': 0.58830495, 'grad_norm': 1.14948285, 'learning_rate': 9.762e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.05325, 'epoch': 0.29, 'global_step/max_steps': '335/2326', 'percentage': '14.40%', 'elapsed_time': '1h 44m 50s', 'remaining_time': '10h 23m 7s'}\n",
      "{'loss': 2.11954384, 'token_acc': 0.54766286, 'grad_norm': 1.15646231, 'learning_rate': 9.751e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053244, 'epoch': 0.29, 'global_step/max_steps': '340/2326', 'percentage': '14.62%', 'elapsed_time': '1h 46m 25s', 'remaining_time': '10h 21m 38s'}\n",
      "{'loss': 1.98464184, 'token_acc': 0.57359819, 'grad_norm': 1.01124835, 'learning_rate': 9.739e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053238, 'epoch': 0.3, 'global_step/max_steps': '345/2326', 'percentage': '14.83%', 'elapsed_time': '1h 48m 0s', 'remaining_time': '10h 20m 9s'}\n",
      "{'loss': 2.07697067, 'token_acc': 0.55423123, 'grad_norm': 1.09832728, 'learning_rate': 9.728e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.05323, 'epoch': 0.3, 'global_step/max_steps': '350/2326', 'percentage': '15.05%', 'elapsed_time': '1h 49m 35s', 'remaining_time': '10h 18m 40s'}\n",
      "{'loss': 2.1024353, 'token_acc': 0.5571509, 'grad_norm': 1.3681221, 'learning_rate': 9.716e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053231, 'epoch': 0.31, 'global_step/max_steps': '355/2326', 'percentage': '15.26%', 'elapsed_time': '1h 51m 8s', 'remaining_time': '10h 17m 5s'}\n",
      "{'loss': 1.94386883, 'token_acc': 0.58466678, 'grad_norm': 1.05283344, 'learning_rate': 9.704e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053257, 'epoch': 0.31, 'global_step/max_steps': '360/2326', 'percentage': '15.48%', 'elapsed_time': '1h 52m 39s', 'remaining_time': '10h 15m 14s'}\n",
      "{'loss': 1.98451843, 'token_acc': 0.57487442, 'grad_norm': 1.05637431, 'learning_rate': 9.692e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053246, 'epoch': 0.31, 'global_step/max_steps': '365/2326', 'percentage': '15.69%', 'elapsed_time': '1h 54m 14s', 'remaining_time': '10h 13m 47s'}\n",
      "{'loss': 1.98054504, 'token_acc': 0.56929546, 'grad_norm': 1.13408279, 'learning_rate': 9.68e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053255, 'epoch': 0.32, 'global_step/max_steps': '370/2326', 'percentage': '15.91%', 'elapsed_time': '1h 55m 47s', 'remaining_time': '10h 12m 7s'}\n",
      "{'loss': 2.05018787, 'token_acc': 0.56511057, 'grad_norm': 1.15372789, 'learning_rate': 9.667e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053271, 'epoch': 0.32, 'global_step/max_steps': '375/2326', 'percentage': '16.12%', 'elapsed_time': '1h 57m 19s', 'remaining_time': '10h 10m 23s'}\n",
      "{'loss': 1.98234444, 'token_acc': 0.57668345, 'grad_norm': 0.95754272, 'learning_rate': 9.654e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053254, 'epoch': 0.33, 'global_step/max_steps': '380/2326', 'percentage': '16.34%', 'elapsed_time': '1h 58m 55s', 'remaining_time': '10h 9m 0s'}\n",
      "{'loss': 2.06187267, 'token_acc': 0.55880146, 'grad_norm': 0.95822453, 'learning_rate': 9.641e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053239, 'epoch': 0.33, 'global_step/max_steps': '385/2326', 'percentage': '16.55%', 'elapsed_time': '2h 0m 31s', 'remaining_time': '10h 7m 36s'}\n",
      "{'loss': 1.98009682, 'token_acc': 0.5761759, 'grad_norm': 1.24464631, 'learning_rate': 9.628e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053251, 'epoch': 0.34, 'global_step/max_steps': '390/2326', 'percentage': '16.77%', 'elapsed_time': '2h 2m 3s', 'remaining_time': '10h 5m 54s'}\n",
      "{'loss': 2.02838726, 'token_acc': 0.56920101, 'grad_norm': 1.14111376, 'learning_rate': 9.614e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053269, 'epoch': 0.34, 'global_step/max_steps': '395/2326', 'percentage': '16.98%', 'elapsed_time': '2h 3m 34s', 'remaining_time': '10h 4m 8s'}\n",
      "{'loss': 2.02592297, 'token_acc': 0.56966911, 'grad_norm': 1.18652344, 'learning_rate': 9.6e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053276, 'epoch': 0.34, 'global_step/max_steps': '400/2326', 'percentage': '17.20%', 'elapsed_time': '2h 5m 7s', 'remaining_time': '10h 2m 30s'}\n",
      "{'loss': 2.03230152, 'token_acc': 0.56344605, 'grad_norm': 1.09478593, 'learning_rate': 9.586e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053262, 'epoch': 0.35, 'global_step/max_steps': '405/2326', 'percentage': '17.41%', 'elapsed_time': '2h 6m 43s', 'remaining_time': '10h 1m 6s'}\n",
      "{'loss': 2.04552021, 'token_acc': 0.56080234, 'grad_norm': 1.34141994, 'learning_rate': 9.572e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053253, 'epoch': 0.35, 'global_step/max_steps': '410/2326', 'percentage': '17.63%', 'elapsed_time': '2h 8m 18s', 'remaining_time': '9h 59m 38s'}\n",
      "{'loss': 2.08077621, 'token_acc': 0.55464828, 'grad_norm': 1.20712543, 'learning_rate': 9.558e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053253, 'epoch': 0.36, 'global_step/max_steps': '415/2326', 'percentage': '17.84%', 'elapsed_time': '2h 9m 52s', 'remaining_time': '9h 58m 4s'}\n",
      "{'loss': 2.06405659, 'token_acc': 0.55789706, 'grad_norm': 1.15100491, 'learning_rate': 9.543e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053253, 'epoch': 0.36, 'global_step/max_steps': '420/2326', 'percentage': '18.06%', 'elapsed_time': '2h 11m 26s', 'remaining_time': '9h 56m 30s'}\n",
      "{'loss': 2.00262432, 'token_acc': 0.56477632, 'grad_norm': 1.43242931, 'learning_rate': 9.528e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053253, 'epoch': 0.37, 'global_step/max_steps': '425/2326', 'percentage': '18.27%', 'elapsed_time': '2h 13m 0s', 'remaining_time': '9h 54m 56s'}\n",
      "{'loss': 1.99282722, 'token_acc': 0.56716502, 'grad_norm': 1.23605132, 'learning_rate': 9.513e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053262, 'epoch': 0.37, 'global_step/max_steps': '430/2326', 'percentage': '18.49%', 'elapsed_time': '2h 14m 33s', 'remaining_time': '9h 53m 16s'}\n",
      "Train:  18%|█▊        | 430/2326 [2:14:33<9:45:12, 18.52s/it]\n",
      "Train:  18%|█▊        | 430/2326 [2:14:33<9:45:12, 18.52s/it]\n",
      "Train:  19%|█▊        | 431/2326 [2:14:51<9:44:48, 18.52s/it]\n",
      "Train:  19%|█▊        | 432/2326 [2:15:10<9:48:05, 18.63s/it]\n",
      "Train:  19%|█▊        | 433/2326 [2:15:28<9:46:32, 18.59s/it]\n",
      "Train:  19%|█▊        | 434/2326 [2:15:47<9:47:02, 18.62s/it]\n",
      "Train:  19%|█▊        | 435/2326 [2:16:06<9:49:31, 18.71s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  19%|█▊        | 435/2326 [2:16:06<9:49:31, 18.71s/it]\n",
      "Train:  19%|█▊        | 435/2326 [2:16:06<9:49:31, 18.71s/it]\n",
      "Train:  19%|█▊        | 436/2326 [2:16:25<9:55:25, 18.90s/it]\n",
      "Train:  19%|█▉        | 437/2326 [2:16:43<9:44:51, 18.58s/it]\n",
      "Train:  19%|█▉        | 438/2326 [2:17:02<9:50:22, 18.76s/it]\n",
      "Train:  19%|█▉        | 439/2326 [2:17:21<9:49:54, 18.76s/it]\n",
      "Train:  19%|█▉        | 440/2326 [2:17:39<9:43:05, 18.55s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  19%|█▉        | 440/2326 [2:17:39<9:43:05, 18.55s/it]\n",
      "Train:  19%|█▉        | 440/2326 [2:17:39<9:43:05, 18.55s/it]\n",
      "Train:  19%|█▉        | 441/2326 [2:17:58<9:43:43, 18.58s/it]\n",
      "Train:  19%|█▉        | 442/2326 [2:18:16<9:35:20, 18.32s/it]\n",
      "Train:  19%|█▉        | 443/2326 [2:18:35<9:49:00, 18.77s/it]\n",
      "Train:  19%|█▉        | 444/2326 [2:18:55<9:51:31, 18.86s/it]\n",
      "Train:  19%|█▉        | 445/2326 [2:19:14<10:01:32, 19.19s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  19%|█▉        | 445/2326 [2:19:15<10:01:32, 19.19s/it]\n",
      "Train:  19%|█▉        | 445/2326 [2:19:15<10:01:32, 19.19s/it]\n",
      "Train:  19%|█▉        | 446/2326 [2:19:34<10:01:16, 19.19s/it]\n",
      "Train:  19%|█▉        | 447/2326 [2:19:52<9:52:20, 18.91s/it] \n",
      "Train:  19%|█▉        | 448/2326 [2:20:10<9:48:33, 18.80s/it]\n",
      "Train:  19%|█▉        | 449/2326 [2:20:30<9:52:11, 18.93s/it]\n",
      "Train:  19%|█▉        | 450/2326 [2:20:48<9:47:31, 18.79s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  19%|█▉        | 450/2326 [2:20:48<9:47:31, 18.79s/it]\n",
      "Train:  19%|█▉        | 450/2326 [2:20:48<9:47:31, 18.79s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v10-20250927-234036/checkpoint-450\n",
      "\n",
      "Train:  19%|█▉        | 451/2326 [2:21:08<9:58:23, 19.15s/it]\n",
      "Train:  19%|█▉        | 452/2326 [2:21:28<10:08:06, 19.47s/it]\n",
      "Train:  19%|█▉        | 453/2326 [2:21:47<9:58:08, 19.16s/it] \n",
      "Train:  20%|█▉        | 454/2326 [2:22:05<9:52:44, 19.00s/it]\n",
      "Train:  20%|█▉        | 455/2326 [2:22:26<10:04:40, 19.39s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  20%|█▉        | 455/2326 [2:22:26<10:04:40, 19.39s/it]\n",
      "Train:  20%|█▉        | 455/2326 [2:22:26<10:04:40, 19.39s/it]\n",
      "Train:  20%|█▉        | 456/2326 [2:22:45<10:01:21, 19.30s/it]\n",
      "Train:  20%|█▉        | 457/2326 [2:23:06<10:19:44, 19.90s/it]\n",
      "Train:  20%|█▉        | 458/2326 [2:23:24<10:05:27, 19.45s/it]\n",
      "Train:  20%|█▉        | 459/2326 [2:23:43<9:56:30, 19.17s/it] \n",
      "Train:  20%|█▉        | 460/2326 [2:24:01<9:45:32, 18.83s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  20%|█▉        | 460/2326 [2:24:01<9:45:32, 18.83s/it]\n",
      "Train:  20%|█▉        | 460/2326 [2:24:01<9:45:32, 18.83s/it]\n",
      "Train:  20%|█▉        | 461/2326 [2:24:20<9:46:37, 18.87s/it]\n",
      "Train:  20%|█▉        | 462/2326 [2:24:39<9:42:56, 18.76s/it]\n",
      "Train:  20%|█▉        | 463/2326 [2:24:59<9:58:02, 19.26s/it]\n",
      "Train:  20%|█▉        | 464/2326 [2:25:17<9:45:56, 18.88s/it]\n",
      "Train:  20%|█▉        | 465/2326 [2:25:36<9:47:08, 18.93s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  20%|█▉        | 465/2326 [2:25:36<9:47:08, 18.93s/it]\n",
      "Train:  20%|█▉        | 465/2326 [2:25:36<9:47:08, 18.93s/it]\n",
      "Train:  20%|██        | 466/2326 [2:25:54<9:39:37, 18.70s/it]\n",
      "Train:  20%|██        | 467/2326 [2:26:12<9:30:22, 18.41s/it]\n",
      "Train:  20%|██        | 468/2326 [2:26:29<9:18:19, 18.03s/it]\n",
      "Train:  20%|██        | 469/2326 [2:26:50<9:46:01, 18.93s/it]\n",
      "Train:  20%|██        | 470/2326 [2:27:08<9:33:29, 18.54s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  20%|██        | 470/2326 [2:27:08<9:33:29, 18.54s/it]\n",
      "Train:  20%|██        | 470/2326 [2:27:08<9:33:29, 18.54s/it]\n",
      "Train:  20%|██        | 471/2326 [2:27:31<10:17:09, 19.96s/it]\n",
      "Train:  20%|██        | 472/2326 [2:27:49<9:58:44, 19.38s/it] \n",
      "Train:  20%|██        | 473/2326 [2:28:08<9:54:48, 19.26s/it]\n",
      "Train:  20%|██        | 474/2326 [2:28:28<10:02:27, 19.52s/it]\n",
      "Train:  20%|██        | 475/2326 [2:28:47<9:56:21, 19.33s/it] \n",
      "                                                             \n",
      "\n",
      "Train:  20%|██        | 475/2326 [2:28:47<9:56:21, 19.33s/it]\n",
      "Train:  20%|██        | 475/2326 [2:28:47<9:56:21, 19.33s/it]\n",
      "Train:  20%|██        | 476/2326 [2:29:07<10:05:09, 19.63s/it]\n",
      "Train:  21%|██        | 477/2326 [2:29:26<9:56:53, 19.37s/it] \n",
      "Train:  21%|██        | 478/2326 [2:29:45<9:56:23, 19.36s/it]\n",
      "Train:  21%|██        | 479/2326 [2:30:04<9:46:59, 19.07s/it]\n",
      "Train:  21%|██        | 480/2326 [2:30:23<9:49:12, 19.15s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  21%|██        | 480/2326 [2:30:23<9:49:12, 19.15s/it]\n",
      "Train:  21%|██        | 480/2326 [2:30:23<9:49:12, 19.15s/it]\n",
      "Train:  21%|██        | 481/2326 [2:30:41<9:37:40, 18.79s/it]\n",
      "Train:  21%|██        | 482/2326 [2:30:59<9:28:42, 18.50s/it]\n",
      "Train:  21%|██        | 483/2326 [2:31:18<9:32:10, 18.63s/it]\n",
      "Train:  21%|██        | 484/2326 [2:31:36<9:28:38, 18.52s/it]\n",
      "Train:  21%|██        | 485/2326 [2:31:54<9:21:48, 18.31s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  21%|██        | 485/2326 [2:31:54<9:21:48, 18.31s/it]\n",
      "Train:  21%|██        | 485/2326 [2:31:54<9:21:48, 18.31s/it]\n",
      "Train:  21%|██        | 486/2326 [2:32:12<9:21:30, 18.31s/it]\n",
      "Train:  21%|██        | 487/2326 [2:32:31<9:29:10, 18.57s/it]\n",
      "Train:  21%|██        | 488/2326 [2:32:50<9:32:26, 18.69s/it]\n",
      "Train:  21%|██        | 489/2326 [2:33:08<9:26:16, 18.50s/it]\n",
      "Train:  21%|██        | 490/2326 [2:33:27<9:22:34, 18.38s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  21%|██        | 490/2326 [2:33:27<9:22:34, 18.38s/it]\n",
      "Train:  21%|██        | 490/2326 [2:33:27<9:22:34, 18.38s/it]\n",
      "Train:  21%|██        | 491/2326 [2:33:45<9:20:44, 18.33s/it]\n",
      "Train:  21%|██        | 492/2326 [2:34:03<9:22:53, 18.42s/it]\n",
      "Train:  21%|██        | 493/2326 [2:34:22<9:21:23, 18.38s/it]\n",
      "Train:  21%|██        | 494/2326 [2:34:40<9:25:17, 18.51s/it]\n",
      "Train:  21%|██▏       | 495/2326 [2:35:00<9:30:56, 18.71s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  21%|██▏       | 495/2326 [2:35:00<9:30:56, 18.71s/it]\n",
      "Train:  21%|██▏       | 495/2326 [2:35:00<9:30:56, 18.71s/it]\n",
      "Train:  21%|██▏       | 496/2326 [2:35:18<9:31:46, 18.75s/it]\n",
      "Train:  21%|██▏       | 497/2326 [2:35:37<9:31:03, 18.73s/it]\n",
      "Train:  21%|██▏       | 498/2326 [2:35:57<9:43:23, 19.15s/it]\n",
      "Train:  21%|██▏       | 499/2326 [2:36:18<9:52:31, 19.46s/it]\n",
      "Train:  21%|██▏       | 500/2326 [2:36:36<9:40:16, 19.07s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  21%|██▏       | 500/2326 [2:36:36<9:40:16, 19.07s/it]\n",
      "Train:  21%|██▏       | 500/2326 [2:36:36<9:40:16, 19.07s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v10-20250927-234036/checkpoint-500\n",
      "\n",
      "Train:  22%|██▏       | 501/2326 [2:36:56<9:53:00, 19.50s/it]\n",
      "Train:  22%|██▏       | 502/2326 [2:37:14<9:39:24, 19.06s/it]\n",
      "Train:  22%|██▏       | 503/2326 [2:37:33<9:32:34, 18.84s/it]\n",
      "Train:  22%|██▏       | 504/2326 [2:37:52<9:37:04, 19.00s/it]\n",
      "Train:  22%|██▏       | 505/2326 [2:38:10<9:29:32, 18.77s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  22%|██▏       | 505/2326 [2:38:10<9:29:32, 18.77s/it]\n",
      "Train:  22%|██▏       | 505/2326 [2:38:10<9:29:32, 18.77s/it]\n",
      "Train:  22%|██▏       | 506/2326 [2:38:31<9:47:34, 19.37s/it]\n",
      "Train:  22%|██▏       | 507/2326 [2:38:50<9:44:50, 19.29s/it]\n",
      "Train:  22%|██▏       | 508/2326 [2:39:10<9:49:38, 19.46s/it]\n",
      "Train:  22%|██▏       | 509/2326 [2:39:28<9:37:19, 19.06s/it]\n",
      "Train:  22%|██▏       | 510/2326 [2:39:46<9:31:50, 18.89s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  22%|██▏       | 510/2326 [2:39:47<9:31:50, 18.89s/it]\n",
      "Train:  22%|██▏       | 510/2326 [2:39:47<9:31:50, 18.89s/it]\n",
      "Train:  22%|██▏       | 511/2326 [2:40:05<9:24:06, 18.65s/it]\n",
      "Train:  22%|██▏       | 512/2326 [2:40:23<9:25:37, 18.71s/it]\n",
      "Train:  22%|██▏       | 513/2326 [2:40:42<9:26:23, 18.74s/it]\n",
      "Train:  22%|██▏       | 514/2326 [2:41:02<9:36:17, 19.08s/it]\n",
      "Train:  22%|██▏       | 515/2326 [2:41:23<9:52:27, 19.63s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  22%|██▏       | 515/2326 [2:41:23<9:52:27, 19.63s/it]\n",
      "Train:  22%|██▏       | 515/2326 [2:41:23<9:52:27, 19.63s/it]\n",
      "Train:  22%|██▏       | 516/2326 [2:41:42<9:46:47, 19.45s/it]\n",
      "Train:  22%|██▏       | 517/2326 [2:42:01<9:43:27, 19.35s/it]\n",
      "Train:  22%|██▏       | 518/2326 [2:42:20<9:37:25, 19.16s/it]\n",
      "Train:  22%|██▏       | 519/2326 [2:42:39<9:33:42, 19.05s/it]\n",
      "Train:  22%|██▏       | 520/2326 [2:42:58<9:32:40, 19.03s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  22%|██▏       | 520/2326 [2:42:58<9:32:40, 19.03s/it]\n",
      "Train:  22%|██▏       | 520/2326 [2:42:58<9:32:40, 19.03s/it]\n",
      "Train:  22%|██▏       | 521/2326 [2:43:16<9:25:55, 18.81s/it]\n",
      "Train:  22%|██▏       | 522/2326 [2:43:35<9:26:00, 18.83s/it]\n",
      "Train:  22%|██▏       | 523/2326 [2:43:55<9:37:36, 19.22s/it]\n",
      "Train:  23%|██▎       | 524/2326 [2:44:14<9:37:42, 19.24s/it]\n",
      "Train:  23%|██▎       | 525/2326 [2:44:33<9:32:00, 19.06s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  23%|██▎       | 525/2326 [2:44:33<9:32:00, 19.06s/it]\n",
      "Train:  23%|██▎       | 525/2326 [2:44:33<9:32:00, 19.06s/it]\n",
      "Train:  23%|██▎       | 526/2326 [2:44:51<9:20:41, 18.69s/it]\n",
      "Train:  23%|██▎       | 527/2326 [2:45:09<9:16:56, 18.58s/it]\n",
      "Train:  23%|██▎       | 528/2326 [2:45:27<9:10:48, 18.38s/it]\n",
      "Train:  23%|██▎       | 529/2326 [2:45:48<9:33:12, 19.14s/it]\n",
      "Train:  23%|██▎       | 530/2326 [2:46:06<9:23:24, 18.82s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  23%|██▎       | 530/2326 [2:46:06<9:23:24, 18.82s/it]\n",
      "Train:  23%|██▎       | 530/2326 [2:46:06<9:23:24, 18.82s/it]\n",
      "Train:  23%|██▎       | 531/2326 [2:46:25<9:27:54, 18.98s/it]\n",
      "Train:  23%|██▎       | 532/2326 [2:46:44<9:21:20, 18.77s/it]\n",
      "Train:  23%|██▎       | 533/2326 [2:47:03<9:29:51, 19.07s/it]\n",
      "Train:  23%|██▎       | 534/2326 [2:47:22<9:22:03, 18.82s/it]\n",
      "Train:  23%|██▎       | 535/2326 [2:47:40<9:16:27, 18.64s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  23%|██▎       | 535/2326 [2:47:40<9:16:27, 18.64s/it]\n",
      "Train:  23%|██▎       | 535/2326 [2:47:40<9:16:27, 18.64s/it]\n",
      "Train:  23%|██▎       | 536/2326 [2:47:59<9:23:28, 18.89s/it]\n",
      "Train:  23%|██▎       | 537/2326 [2:48:17<9:17:12, 18.69s/it]\n",
      "Train:  23%|██▎       | 538/2326 [2:48:36<9:12:56, 18.55s/it]\n",
      "Train:  23%|██▎       | 539/2326 [2:48:54<9:05:44, 18.32s/it]\n",
      "Train:  23%|██▎       | 540/2326 [2:49:11<9:01:39, 18.20s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  23%|██▎       | 540/2326 [2:49:11<9:01:39, 18.20s/it]\n",
      "Train:  23%|██▎       | 540/2326 [2:49:11<9:01:39, 18.20s/it]\n",
      "Train:  23%|██▎       | 541/2326 [2:49:31<9:10:00, 18.49s/it]\n",
      "Train:  23%|██▎       | 542/2326 [2:49:50<9:14:38, 18.65s/it]\n",
      "Train:  23%|██▎       | 543/2326 [2:50:08<9:10:38, 18.53s/it]\n",
      "Train:  23%|██▎       | 544/2326 [2:50:26<9:09:52, 18.51s/it]\n",
      "Train:  23%|██▎       | 545/2326 [2:50:46<9:17:17, 18.77s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  23%|██▎       | 545/2326 [2:50:46<9:17:17, 18.77s/it]\n",
      "Train:  23%|██▎       | 545/2326 [2:50:46<9:17:17, 18.77s/it]\n",
      "Train:  23%|██▎       | 546/2326 [2:51:04<9:12:09, 18.61s/it]\n",
      "Train:  24%|██▎       | 547/2326 [2:51:22<9:07:05, 18.45s/it]\n",
      "Train:  24%|██▎       | 548/2326 [2:51:40<9:03:15, 18.33s/it]\n",
      "Train:  24%|██▎       | 549/2326 [2:51:58<9:01:50, 18.30s/it]\n",
      "Train:  24%|██▎       | 550/2326 [2:52:17<9:03:47, 18.37s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  24%|██▎       | 550/2326 [2:52:17<9:03:47, 18.37s/it]\n",
      "Train:  24%|██▎       | 550/2326 [2:52:17<9:03:47, 18.37s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v10-20250927-234036/checkpoint-550\n",
      "\n",
      "Train:  24%|██▎       | 551/2326 [2:52:37<9:15:07, 18.77s/it]\n",
      "Train:  24%|██▎       | 552/2326 [2:52:55<9:13:03, 18.71s/it]\n",
      "Train:  24%|██▍       | 553/2326 [2:53:14<9:16:40, 18.84s/it]\n",
      "Train:  24%|██▍       | 554/2326 [2:53:33<9:13:37, 18.75s/it]\n",
      "Train:  24%|██▍       | 555/2326 [2:53:51<9:10:55, 18.67s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  24%|██▍       | 555/2326 [2:53:51<9:10:55, 18.67s/it]\n",
      "Train:  24%|██▍       | 555/2326 [2:53:51<9:10:55, 18.67s/it]\n",
      "Train:  24%|██▍       | 556/2326 [2:54:12<9:33:26, 19.44s/it]\n",
      "Train:  24%|██▍       | 557/2326 [2:54:31<9:25:51, 19.19s/it]\n",
      "Train:  24%|██▍       | 558/2326 [2:54:50<9:22:32, 19.09s/it]\n",
      "Train:  24%|██▍       | 559/2326 [2:55:09<9:24:48, 19.18s/it]\n",
      "Train:  24%|██▍       | 560/2326 [2:55:28<9:22:55, 19.13s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  24%|██▍       | 560/2326 [2:55:28<9:22:55, 19.13s/it]\n",
      "Train:  24%|██▍       | 560/2326 [2:55:28<9:22:55, 19.13s/it]\n",
      "Train:  24%|██▍       | 561/2326 [2:55:48<9:30:58, 19.41s/it]\n",
      "Train:  24%|██▍       | 562/2326 [2:56:08<9:32:28, 19.47s/it]\n",
      "Train:  24%|██▍       | 563/2326 [2:56:27<9:26:01, 19.26s/it]\n",
      "Train:  24%|██▍       | 564/2326 [2:56:45<9:17:09, 18.97s/it]\n",
      "Train:  24%|██▍       | 565/2326 [2:57:04<9:18:00, 19.01s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  24%|██▍       | 565/2326 [2:57:04<9:18:00, 19.01s/it]\n",
      "Train:  24%|██▍       | 565/2326 [2:57:04<9:18:00, 19.01s/it]\n",
      "Train:  24%|██▍       | 566/2326 [2:57:23<9:14:26, 18.90s/it]\n",
      "Train:  24%|██▍       | 567/2326 [2:57:41<9:09:49, 18.75s/it]\n",
      "Train:  24%|██▍       | 568/2326 [2:57:59<9:01:43, 18.49s/it]\n",
      "Train:  24%|██▍       | 569/2326 [2:58:18<9:01:23, 18.49s/it]\n",
      "Train:  25%|██▍       | 570/2326 [2:58:36<8:58:29, 18.40s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  25%|██▍       | 570/2326 [2:58:36<8:58:29, 18.40s/it]\n",
      "Train:  25%|██▍       | 570/2326 [2:58:36<8:58:29, 18.40s/it]\n",
      "Train:  25%|██▍       | 571/2326 [2:58:54<8:57:47, 18.39s/it]\n",
      "Train:  25%|██▍       | 572/2326 [2:59:13<8:57:24, 18.38s/it]\n",
      "Train:  25%|██▍       | 573/2326 [2:59:31<8:56:18, 18.36s/it]\n",
      "Train:  25%|██▍       | 574/2326 [2:59:50<9:02:49, 18.59s/it]\n",
      "Train:  25%|██▍       | 575/2326 [3:00:08<8:58:31, 18.45s/it]\n",
      "                                                             \n",
      "{'loss': 1.99058342, 'token_acc': 0.57028698, 'grad_norm': 1.36140382, 'learning_rate': 9.497e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053264, 'epoch': 0.37, 'global_step/max_steps': '435/2326', 'percentage': '18.70%', 'elapsed_time': '2h 16m 6s', 'remaining_time': '9h 51m 41s'}\n",
      "{'loss': 1.87340164, 'token_acc': 0.58968236, 'grad_norm': 1.10509741, 'learning_rate': 9.482e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053269, 'epoch': 0.38, 'global_step/max_steps': '440/2326', 'percentage': '18.92%', 'elapsed_time': '2h 17m 39s', 'remaining_time': '9h 50m 4s'}\n",
      "{'loss': 2.04492645, 'token_acc': 0.56573917, 'grad_norm': 0.92104143, 'learning_rate': 9.466e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.05326, 'epoch': 0.38, 'global_step/max_steps': '445/2326', 'percentage': '19.13%', 'elapsed_time': '2h 19m 15s', 'remaining_time': '9h 48m 36s'}\n",
      "{'loss': 1.95107727, 'token_acc': 0.57805392, 'grad_norm': 1.27779746, 'learning_rate': 9.45e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053261, 'epoch': 0.39, 'global_step/max_steps': '450/2326', 'percentage': '19.35%', 'elapsed_time': '2h 20m 48s', 'remaining_time': '9h 47m 1s'}\n",
      "{'loss': 2.00186939, 'token_acc': 0.57637006, 'grad_norm': 1.06847823, 'learning_rate': 9.433e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053238, 'epoch': 0.39, 'global_step/max_steps': '455/2326', 'percentage': '19.56%', 'elapsed_time': '2h 22m 26s', 'remaining_time': '9h 45m 43s'}\n",
      "{'loss': 1.88806667, 'token_acc': 0.59224124, 'grad_norm': 1.29238605, 'learning_rate': 9.417e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053229, 'epoch': 0.4, 'global_step/max_steps': '460/2326', 'percentage': '19.78%', 'elapsed_time': '2h 24m 1s', 'remaining_time': '9h 44m 14s'}\n",
      "{'loss': 1.93642883, 'token_acc': 0.58243376, 'grad_norm': 1.15401232, 'learning_rate': 9.4e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053223, 'epoch': 0.4, 'global_step/max_steps': '465/2326', 'percentage': '19.99%', 'elapsed_time': '2h 25m 36s', 'remaining_time': '9h 42m 45s'}\n",
      "{'loss': 1.99971981, 'token_acc': 0.56871275, 'grad_norm': 1.35186899, 'learning_rate': 9.383e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053237, 'epoch': 0.4, 'global_step/max_steps': '470/2326', 'percentage': '20.21%', 'elapsed_time': '2h 27m 8s', 'remaining_time': '9h 41m 2s'}\n",
      "{'loss': 1.93635349, 'token_acc': 0.5844417, 'grad_norm': 1.27750409, 'learning_rate': 9.366e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053205, 'epoch': 0.41, 'global_step/max_steps': '475/2326', 'percentage': '20.42%', 'elapsed_time': '2h 28m 47s', 'remaining_time': '9h 39m 49s'}\n",
      "{'loss': 2.04538994, 'token_acc': 0.55976422, 'grad_norm': 1.14329302, 'learning_rate': 9.348e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053192, 'epoch': 0.41, 'global_step/max_steps': '480/2326', 'percentage': '20.64%', 'elapsed_time': '2h 30m 23s', 'remaining_time': '9h 38m 23s'}\n",
      "{'loss': 1.95190048, 'token_acc': 0.58452273, 'grad_norm': 1.21135795, 'learning_rate': 9.331e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053211, 'epoch': 0.42, 'global_step/max_steps': '485/2326', 'percentage': '20.85%', 'elapsed_time': '2h 31m 54s', 'remaining_time': '9h 36m 37s'}\n",
      "{'loss': 1.96014519, 'token_acc': 0.5817338, 'grad_norm': 1.12388206, 'learning_rate': 9.313e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053218, 'epoch': 0.42, 'global_step/max_steps': '490/2326', 'percentage': '21.07%', 'elapsed_time': '2h 33m 27s', 'remaining_time': '9h 34m 58s'}\n",
      "{'loss': 1.962113, 'token_acc': 0.58163207, 'grad_norm': 1.21624517, 'learning_rate': 9.295e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053223, 'epoch': 0.43, 'global_step/max_steps': '495/2326', 'percentage': '21.28%', 'elapsed_time': '2h 35m 0s', 'remaining_time': '9h 33m 21s'}\n",
      "{'loss': 1.96786385, 'token_acc': 0.58124648, 'grad_norm': 1.37186611, 'learning_rate': 9.276e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053212, 'epoch': 0.43, 'global_step/max_steps': '500/2326', 'percentage': '21.50%', 'elapsed_time': '2h 36m 36s', 'remaining_time': '9h 31m 54s'}\n",
      "{'loss': 1.98603344, 'token_acc': 0.566409, 'grad_norm': 1.13705623, 'learning_rate': 9.258e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053209, 'epoch': 0.43, 'global_step/max_steps': '505/2326', 'percentage': '21.71%', 'elapsed_time': '2h 38m 10s', 'remaining_time': '9h 30m 22s'}\n",
      "{'loss': 2.06410809, 'token_acc': 0.55454861, 'grad_norm': 1.04292905, 'learning_rate': 9.239e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053195, 'epoch': 0.44, 'global_step/max_steps': '510/2326', 'percentage': '21.93%', 'elapsed_time': '2h 39m 47s', 'remaining_time': '9h 28m 57s'}\n",
      "{'loss': 1.96691723, 'token_acc': 0.57409417, 'grad_norm': 1.13606393, 'learning_rate': 9.22e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053182, 'epoch': 0.44, 'global_step/max_steps': '515/2326', 'percentage': '22.14%', 'elapsed_time': '2h 41m 23s', 'remaining_time': '9h 27m 32s'}\n",
      "{'loss': 1.86326332, 'token_acc': 0.59396668, 'grad_norm': 1.3145318, 'learning_rate': 9.201e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053178, 'epoch': 0.45, 'global_step/max_steps': '520/2326', 'percentage': '22.36%', 'elapsed_time': '2h 42m 58s', 'remaining_time': '9h 26m 0s'}\n",
      "{'loss': 1.93955555, 'token_acc': 0.58507068, 'grad_norm': 1.16305828, 'learning_rate': 9.182e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053172, 'epoch': 0.45, 'global_step/max_steps': '525/2326', 'percentage': '22.57%', 'elapsed_time': '2h 44m 33s', 'remaining_time': '9h 24m 30s'}\n",
      "{'loss': 1.95678062, 'token_acc': 0.58919534, 'grad_norm': 1.24846613, 'learning_rate': 9.162e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053177, 'epoch': 0.46, 'global_step/max_steps': '530/2326', 'percentage': '22.79%', 'elapsed_time': '2h 46m 6s', 'remaining_time': '9h 22m 53s'}\n",
      "{'loss': 1.95609035, 'token_acc': 0.57968874, 'grad_norm': 1.33775282, 'learning_rate': 9.142e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053178, 'epoch': 0.46, 'global_step/max_steps': '535/2326', 'percentage': '23.00%', 'elapsed_time': '2h 47m 40s', 'remaining_time': '9h 21m 18s'}\n",
      "{'loss': 2.03100529, 'token_acc': 0.56606455, 'grad_norm': 1.24498129, 'learning_rate': 9.122e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.05319, 'epoch': 0.46, 'global_step/max_steps': '540/2326', 'percentage': '23.22%', 'elapsed_time': '2h 49m 11s', 'remaining_time': '9h 19m 36s'}\n",
      "{'loss': 2.12374153, 'token_acc': 0.5476266, 'grad_norm': 1.08935952, 'learning_rate': 9.102e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053189, 'epoch': 0.47, 'global_step/max_steps': '545/2326', 'percentage': '23.43%', 'elapsed_time': '2h 50m 46s', 'remaining_time': '9h 18m 3s'}\n",
      "{'loss': 1.84351654, 'token_acc': 0.60554954, 'grad_norm': 1.26754355, 'learning_rate': 9.082e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053204, 'epoch': 0.47, 'global_step/max_steps': '550/2326', 'percentage': '23.65%', 'elapsed_time': '2h 52m 17s', 'remaining_time': '9h 16m 20s'}\n",
      "{'loss': 1.98727036, 'token_acc': 0.57653555, 'grad_norm': 1.38619208, 'learning_rate': 9.061e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053201, 'epoch': 0.48, 'global_step/max_steps': '555/2326', 'percentage': '23.86%', 'elapsed_time': '2h 53m 51s', 'remaining_time': '9h 14m 47s'}\n",
      "{'loss': 2.03468285, 'token_acc': 0.56700571, 'grad_norm': 1.18758798, 'learning_rate': 9.04e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053186, 'epoch': 0.48, 'global_step/max_steps': '560/2326', 'percentage': '24.08%', 'elapsed_time': '2h 55m 28s', 'remaining_time': '9h 13m 23s'}\n",
      "{'loss': 2.12553082, 'token_acc': 0.54590326, 'grad_norm': 1.0806694, 'learning_rate': 9.019e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053176, 'epoch': 0.49, 'global_step/max_steps': '565/2326', 'percentage': '24.29%', 'elapsed_time': '2h 57m 4s', 'remaining_time': '9h 11m 55s'}\n",
      "{'loss': 1.96285324, 'token_acc': 0.57820883, 'grad_norm': 1.48667431, 'learning_rate': 8.998e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053188, 'epoch': 0.49, 'global_step/max_steps': '570/2326', 'percentage': '24.51%', 'elapsed_time': '2h 58m 36s', 'remaining_time': '9h 10m 14s'}\n",
      "{'loss': 1.93050747, 'token_acc': 0.58480495, 'grad_norm': 1.3717339, 'learning_rate': 8.976e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053197, 'epoch': 0.49, 'global_step/max_steps': '575/2326', 'percentage': '24.72%', 'elapsed_time': '3h 0m 8s', 'remaining_time': '9h 8m 34s'}\n",
      "Train:  25%|██▍       | 575/2326 [3:00:08<8:58:31, 18.45s/it]\n",
      "Train:  25%|██▍       | 575/2326 [3:00:08<8:58:31, 18.45s/it]\n",
      "Train:  25%|██▍       | 576/2326 [3:00:27<9:01:44, 18.57s/it]\n",
      "Train:  25%|██▍       | 577/2326 [3:00:45<8:54:16, 18.33s/it]\n",
      "Train:  25%|██▍       | 578/2326 [3:01:04<8:59:19, 18.51s/it]\n",
      "Train:  25%|██▍       | 579/2326 [3:01:22<8:57:59, 18.48s/it]\n",
      "Train:  25%|██▍       | 580/2326 [3:01:42<9:07:19, 18.81s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  25%|██▍       | 580/2326 [3:01:42<9:07:19, 18.81s/it]\n",
      "Train:  25%|██▍       | 580/2326 [3:01:42<9:07:19, 18.81s/it]\n",
      "Train:  25%|██▍       | 581/2326 [3:02:01<9:11:36, 18.97s/it]\n",
      "Train:  25%|██▌       | 582/2326 [3:02:19<9:06:43, 18.81s/it]\n",
      "Train:  25%|██▌       | 583/2326 [3:02:38<9:02:47, 18.68s/it]\n",
      "Train:  25%|██▌       | 584/2326 [3:02:56<9:02:06, 18.67s/it]\n",
      "Train:  25%|██▌       | 585/2326 [3:03:14<8:55:20, 18.45s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  25%|██▌       | 585/2326 [3:03:14<8:55:20, 18.45s/it]\n",
      "Train:  25%|██▌       | 585/2326 [3:03:14<8:55:20, 18.45s/it]\n",
      "Train:  25%|██▌       | 586/2326 [3:03:33<8:54:05, 18.42s/it]\n",
      "Train:  25%|██▌       | 587/2326 [3:03:53<9:05:59, 18.84s/it]\n",
      "Train:  25%|██▌       | 588/2326 [3:04:11<8:58:54, 18.60s/it]\n",
      "Train:  25%|██▌       | 589/2326 [3:04:29<8:54:06, 18.45s/it]\n",
      "Train:  25%|██▌       | 590/2326 [3:04:47<8:54:47, 18.48s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  25%|██▌       | 590/2326 [3:04:47<8:54:47, 18.48s/it]\n",
      "Train:  25%|██▌       | 590/2326 [3:04:47<8:54:47, 18.48s/it]\n",
      "Train:  25%|██▌       | 591/2326 [3:05:07<9:01:01, 18.71s/it]\n",
      "Train:  25%|██▌       | 592/2326 [3:05:26<9:05:05, 18.86s/it]\n",
      "Train:  25%|██▌       | 593/2326 [3:05:44<8:56:54, 18.59s/it]\n",
      "Train:  26%|██▌       | 594/2326 [3:06:02<8:53:38, 18.49s/it]\n",
      "Train:  26%|██▌       | 595/2326 [3:06:22<9:09:28, 19.05s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  26%|██▌       | 595/2326 [3:06:22<9:09:28, 19.05s/it]\n",
      "Train:  26%|██▌       | 595/2326 [3:06:22<9:09:28, 19.05s/it]\n",
      "Train:  26%|██▌       | 596/2326 [3:06:41<9:05:30, 18.92s/it]\n",
      "Train:  26%|██▌       | 597/2326 [3:06:59<8:59:58, 18.74s/it]\n",
      "Train:  26%|██▌       | 598/2326 [3:07:17<8:51:22, 18.45s/it]\n",
      "Train:  26%|██▌       | 599/2326 [3:07:36<8:56:37, 18.64s/it]\n",
      "Train:  26%|██▌       | 600/2326 [3:07:54<8:51:31, 18.48s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  26%|██▌       | 600/2326 [3:07:54<8:51:31, 18.48s/it]\n",
      "Train:  26%|██▌       | 600/2326 [3:07:54<8:51:31, 18.48s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v10-20250927-234036/checkpoint-600\n",
      "\n",
      "Train:  26%|██▌       | 601/2326 [3:08:15<9:10:37, 19.15s/it]\n",
      "Train:  26%|██▌       | 602/2326 [3:08:33<9:03:20, 18.91s/it]\n",
      "Train:  26%|██▌       | 603/2326 [3:08:53<9:07:11, 19.05s/it]\n",
      "Train:  26%|██▌       | 604/2326 [3:09:13<9:16:25, 19.39s/it]\n",
      "Train:  26%|██▌       | 605/2326 [3:09:31<9:05:01, 19.00s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  26%|██▌       | 605/2326 [3:09:31<9:05:01, 19.00s/it]\n",
      "Train:  26%|██▌       | 605/2326 [3:09:31<9:05:01, 19.00s/it]\n",
      "Train:  26%|██▌       | 606/2326 [3:09:49<8:58:48, 18.80s/it]\n",
      "Train:  26%|██▌       | 607/2326 [3:10:08<8:55:50, 18.70s/it]\n",
      "Train:  26%|██▌       | 608/2326 [3:10:26<8:53:51, 18.64s/it]\n",
      "Train:  26%|██▌       | 609/2326 [3:10:45<8:54:55, 18.69s/it]\n",
      "Train:  26%|██▌       | 610/2326 [3:11:05<9:03:04, 18.99s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  26%|██▌       | 610/2326 [3:11:05<9:03:04, 18.99s/it]\n",
      "Train:  26%|██▌       | 610/2326 [3:11:05<9:03:04, 18.99s/it]\n",
      "Train:  26%|██▋       | 611/2326 [3:11:23<8:56:26, 18.77s/it]\n",
      "Train:  26%|██▋       | 612/2326 [3:11:42<8:55:54, 18.76s/it]\n",
      "Train:  26%|██▋       | 613/2326 [3:12:00<8:48:29, 18.51s/it]\n",
      "Train:  26%|██▋       | 614/2326 [3:12:20<9:04:05, 19.07s/it]\n",
      "Train:  26%|██▋       | 615/2326 [3:12:39<9:07:12, 19.19s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  26%|██▋       | 615/2326 [3:12:40<9:07:12, 19.19s/it]\n",
      "Train:  26%|██▋       | 615/2326 [3:12:40<9:07:12, 19.19s/it]\n",
      "Train:  26%|██▋       | 616/2326 [3:12:58<9:00:16, 18.96s/it]\n",
      "Train:  27%|██▋       | 617/2326 [3:13:18<9:07:03, 19.21s/it]\n",
      "Train:  27%|██▋       | 618/2326 [3:13:36<9:01:53, 19.04s/it]\n",
      "Train:  27%|██▋       | 619/2326 [3:13:55<8:57:05, 18.88s/it]\n",
      "Train:  27%|██▋       | 620/2326 [3:14:13<8:51:03, 18.68s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  27%|██▋       | 620/2326 [3:14:13<8:51:03, 18.68s/it]\n",
      "Train:  27%|██▋       | 620/2326 [3:14:13<8:51:03, 18.68s/it]\n",
      "Train:  27%|██▋       | 621/2326 [3:14:31<8:45:15, 18.48s/it]\n",
      "Train:  27%|██▋       | 622/2326 [3:14:49<8:44:12, 18.46s/it]\n",
      "Train:  27%|██▋       | 623/2326 [3:15:08<8:43:44, 18.45s/it]\n",
      "Train:  27%|██▋       | 624/2326 [3:15:26<8:42:33, 18.42s/it]\n",
      "Train:  27%|██▋       | 625/2326 [3:15:45<8:45:59, 18.55s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  27%|██▋       | 625/2326 [3:15:45<8:45:59, 18.55s/it]\n",
      "Train:  27%|██▋       | 625/2326 [3:15:45<8:45:59, 18.55s/it]\n",
      "Train:  27%|██▋       | 626/2326 [3:16:04<8:45:52, 18.56s/it]\n",
      "Train:  27%|██▋       | 627/2326 [3:16:22<8:43:50, 18.50s/it]\n",
      "Train:  27%|██▋       | 628/2326 [3:16:40<8:41:59, 18.45s/it]\n",
      "Train:  27%|██▋       | 629/2326 [3:16:58<8:37:00, 18.28s/it]\n",
      "Train:  27%|██▋       | 630/2326 [3:17:17<8:37:09, 18.30s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  27%|██▋       | 630/2326 [3:17:17<8:37:09, 18.30s/it]\n",
      "Train:  27%|██▋       | 630/2326 [3:17:17<8:37:09, 18.30s/it]\n",
      "Train:  27%|██▋       | 631/2326 [3:17:36<8:49:08, 18.73s/it]\n",
      "Train:  27%|██▋       | 632/2326 [3:17:55<8:48:06, 18.71s/it]\n",
      "Train:  27%|██▋       | 633/2326 [3:18:15<9:00:57, 19.17s/it]\n",
      "Train:  27%|██▋       | 634/2326 [3:18:34<8:57:29, 19.06s/it]\n",
      "Train:  27%|██▋       | 635/2326 [3:18:52<8:50:17, 18.82s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  27%|██▋       | 635/2326 [3:18:52<8:50:17, 18.82s/it]\n",
      "Train:  27%|██▋       | 635/2326 [3:18:52<8:50:17, 18.82s/it]\n",
      "Train:  27%|██▋       | 636/2326 [3:19:11<8:48:52, 18.78s/it]\n",
      "Train:  27%|██▋       | 637/2326 [3:19:31<8:59:08, 19.15s/it]\n",
      "Train:  27%|██▋       | 638/2326 [3:19:50<8:53:42, 18.97s/it]\n",
      "Train:  27%|██▋       | 639/2326 [3:20:08<8:49:52, 18.85s/it]\n",
      "Train:  28%|██▊       | 640/2326 [3:20:27<8:51:13, 18.90s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  28%|██▊       | 640/2326 [3:20:27<8:51:13, 18.90s/it]\n",
      "Train:  28%|██▊       | 640/2326 [3:20:27<8:51:13, 18.90s/it]\n",
      "Train:  28%|██▊       | 641/2326 [3:20:45<8:44:48, 18.69s/it]\n",
      "Train:  28%|██▊       | 642/2326 [3:21:05<8:48:49, 18.84s/it]\n",
      "Train:  28%|██▊       | 643/2326 [3:21:24<8:55:13, 19.08s/it]\n",
      "Train:  28%|██▊       | 644/2326 [3:21:43<8:52:53, 19.01s/it]\n",
      "Train:  28%|██▊       | 645/2326 [3:22:01<8:41:45, 18.62s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  28%|██▊       | 645/2326 [3:22:01<8:41:45, 18.62s/it]\n",
      "Train:  28%|██▊       | 645/2326 [3:22:01<8:41:45, 18.62s/it]\n",
      "Train:  28%|██▊       | 646/2326 [3:22:19<8:42:44, 18.67s/it]\n",
      "Train:  28%|██▊       | 647/2326 [3:22:38<8:37:44, 18.50s/it]\n",
      "Train:  28%|██▊       | 648/2326 [3:22:56<8:36:25, 18.47s/it]\n",
      "Train:  28%|██▊       | 649/2326 [3:23:18<9:03:48, 19.46s/it]\n",
      "Train:  28%|██▊       | 650/2326 [3:23:38<9:12:18, 19.77s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  28%|██▊       | 650/2326 [3:23:38<9:12:18, 19.77s/it]\n",
      "Train:  28%|██▊       | 650/2326 [3:23:38<9:12:18, 19.77s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v10-20250927-234036/checkpoint-650\n",
      "\n",
      "Train:  28%|██▊       | 651/2326 [3:23:58<9:10:36, 19.72s/it]\n",
      "Train:  28%|██▊       | 652/2326 [3:24:17<9:02:16, 19.44s/it]\n",
      "Train:  28%|██▊       | 653/2326 [3:24:38<9:17:40, 20.00s/it]\n",
      "Train:  28%|██▊       | 654/2326 [3:24:56<9:02:17, 19.46s/it]\n",
      "Train:  28%|██▊       | 655/2326 [3:25:15<8:52:38, 19.13s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  28%|██▊       | 655/2326 [3:25:15<8:52:38, 19.13s/it]\n",
      "Train:  28%|██▊       | 655/2326 [3:25:15<8:52:38, 19.13s/it]\n",
      "Train:  28%|██▊       | 656/2326 [3:25:34<8:51:34, 19.10s/it]\n",
      "Train:  28%|██▊       | 657/2326 [3:25:53<8:50:22, 19.07s/it]\n",
      "Train:  28%|██▊       | 658/2326 [3:26:11<8:44:02, 18.85s/it]\n",
      "Train:  28%|██▊       | 659/2326 [3:26:29<8:35:20, 18.55s/it]\n",
      "Train:  28%|██▊       | 660/2326 [3:26:47<8:29:23, 18.35s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  28%|██▊       | 660/2326 [3:26:47<8:29:23, 18.35s/it]\n",
      "Train:  28%|██▊       | 660/2326 [3:26:47<8:29:23, 18.35s/it]\n",
      "Train:  28%|██▊       | 661/2326 [3:27:06<8:41:48, 18.80s/it]\n",
      "Train:  28%|██▊       | 662/2326 [3:27:25<8:36:29, 18.62s/it]\n",
      "Train:  29%|██▊       | 663/2326 [3:27:43<8:29:53, 18.40s/it]\n",
      "Train:  29%|██▊       | 664/2326 [3:28:01<8:29:30, 18.39s/it]\n",
      "Train:  29%|██▊       | 665/2326 [3:28:19<8:30:38, 18.45s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  29%|██▊       | 665/2326 [3:28:20<8:30:38, 18.45s/it]\n",
      "Train:  29%|██▊       | 665/2326 [3:28:20<8:30:38, 18.45s/it]\n",
      "Train:  29%|██▊       | 666/2326 [3:28:38<8:28:46, 18.39s/it]\n",
      "Train:  29%|██▊       | 667/2326 [3:28:57<8:38:15, 18.74s/it]\n",
      "Train:  29%|██▊       | 668/2326 [3:29:16<8:34:57, 18.64s/it]\n",
      "Train:  29%|██▉       | 669/2326 [3:29:36<8:44:30, 18.99s/it]\n",
      "Train:  29%|██▉       | 670/2326 [3:29:54<8:41:33, 18.90s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  29%|██▉       | 670/2326 [3:29:54<8:41:33, 18.90s/it]\n",
      "Train:  29%|██▉       | 670/2326 [3:29:54<8:41:33, 18.90s/it]\n",
      "Train:  29%|██▉       | 671/2326 [3:30:13<8:42:19, 18.94s/it]\n",
      "Train:  29%|██▉       | 672/2326 [3:30:32<8:40:03, 18.87s/it]\n",
      "Train:  29%|██▉       | 673/2326 [3:30:50<8:33:43, 18.65s/it]\n",
      "Train:  29%|██▉       | 674/2326 [3:31:08<8:27:11, 18.42s/it]\n",
      "Train:  29%|██▉       | 675/2326 [3:31:27<8:35:27, 18.73s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  29%|██▉       | 675/2326 [3:31:27<8:35:27, 18.73s/it]\n",
      "Train:  29%|██▉       | 675/2326 [3:31:27<8:35:27, 18.73s/it]\n",
      "Train:  29%|██▉       | 676/2326 [3:31:46<8:34:43, 18.72s/it]\n",
      "Train:  29%|██▉       | 677/2326 [3:32:05<8:35:17, 18.75s/it]\n",
      "Train:  29%|██▉       | 678/2326 [3:32:23<8:31:31, 18.62s/it]\n",
      "Train:  29%|██▉       | 679/2326 [3:32:42<8:31:03, 18.62s/it]\n",
      "Train:  29%|██▉       | 680/2326 [3:33:01<8:32:56, 18.70s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  29%|██▉       | 680/2326 [3:33:01<8:32:56, 18.70s/it]\n",
      "Train:  29%|██▉       | 680/2326 [3:33:01<8:32:56, 18.70s/it]\n",
      "Train:  29%|██▉       | 681/2326 [3:33:20<8:33:49, 18.74s/it]\n",
      "Train:  29%|██▉       | 682/2326 [3:33:39<8:40:05, 18.98s/it]\n",
      "Train:  29%|██▉       | 683/2326 [3:33:58<8:36:16, 18.85s/it]\n",
      "Train:  29%|██▉       | 684/2326 [3:34:17<8:38:28, 18.95s/it]\n",
      "Train:  29%|██▉       | 685/2326 [3:34:35<8:28:44, 18.60s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  29%|██▉       | 685/2326 [3:34:35<8:28:44, 18.60s/it]\n",
      "Train:  29%|██▉       | 685/2326 [3:34:35<8:28:44, 18.60s/it]\n",
      "Train:  29%|██▉       | 686/2326 [3:34:53<8:29:21, 18.64s/it]\n",
      "Train:  30%|██▉       | 687/2326 [3:35:11<8:22:12, 18.38s/it]\n",
      "Train:  30%|██▉       | 688/2326 [3:35:31<8:34:57, 18.86s/it]\n",
      "Train:  30%|██▉       | 689/2326 [3:35:50<8:32:17, 18.78s/it]\n",
      "Train:  30%|██▉       | 690/2326 [3:36:09<8:37:10, 18.97s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  30%|██▉       | 690/2326 [3:36:09<8:37:10, 18.97s/it]\n",
      "Train:  30%|██▉       | 690/2326 [3:36:09<8:37:10, 18.97s/it]\n",
      "Train:  30%|██▉       | 691/2326 [3:36:27<8:31:32, 18.77s/it]\n",
      "Train:  30%|██▉       | 692/2326 [3:36:46<8:28:23, 18.67s/it]\n",
      "Train:  30%|██▉       | 693/2326 [3:37:04<8:26:12, 18.60s/it]\n",
      "Train:  30%|██▉       | 694/2326 [3:37:22<8:21:02, 18.42s/it]\n",
      "Train:  30%|██▉       | 695/2326 [3:37:41<8:24:55, 18.57s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  30%|██▉       | 695/2326 [3:37:41<8:24:55, 18.57s/it]\n",
      "Train:  30%|██▉       | 695/2326 [3:37:41<8:24:55, 18.57s/it]\n",
      "Train:  30%|██▉       | 696/2326 [3:38:02<8:41:31, 19.20s/it]\n",
      "Train:  30%|██▉       | 697/2326 [3:38:20<8:36:07, 19.01s/it]\n",
      "Train:  30%|███       | 698/2326 [3:38:40<8:36:43, 19.04s/it]\n",
      "Train:  30%|███       | 699/2326 [3:38:58<8:28:48, 18.76s/it]\n",
      "Train:  30%|███       | 700/2326 [3:39:19<8:49:37, 19.54s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  30%|███       | 700/2326 [3:39:19<8:49:37, 19.54s/it]\n",
      "Train:  30%|███       | 700/2326 [3:39:19<8:49:37, 19.54s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v10-20250927-234036/checkpoint-700\n",
      "\n",
      "Train:  30%|███       | 701/2326 [3:39:39<8:50:32, 19.59s/it]\n",
      "Train:  30%|███       | 702/2326 [3:39:57<8:36:55, 19.10s/it]\n",
      "Train:  30%|███       | 703/2326 [3:40:15<8:28:34, 18.80s/it]\n",
      "Train:  30%|███       | 704/2326 [3:40:33<8:20:03, 18.50s/it]\n",
      "Train:  30%|███       | 705/2326 [3:40:51<8:20:56, 18.54s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  30%|███       | 705/2326 [3:40:51<8:20:56, 18.54s/it]\n",
      "Train:  30%|███       | 705/2326 [3:40:51<8:20:56, 18.54s/it]\n",
      "Train:  30%|███       | 706/2326 [3:41:10<8:19:53, 18.51s/it]\n",
      "Train:  30%|███       | 707/2326 [3:41:28<8:15:18, 18.36s/it]\n",
      "Train:  30%|███       | 708/2326 [3:41:47<8:23:58, 18.69s/it]\n",
      "Train:  30%|███       | 709/2326 [3:42:06<8:24:57, 18.74s/it]\n",
      "Train:  31%|███       | 710/2326 [3:42:24<8:21:58, 18.64s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  31%|███       | 710/2326 [3:42:24<8:21:58, 18.64s/it]\n",
      "Train:  31%|███       | 710/2326 [3:42:24<8:21:58, 18.64s/it]\n",
      "Train:  31%|███       | 711/2326 [3:42:42<8:17:03, 18.47s/it]\n",
      "Train:  31%|███       | 712/2326 [3:43:01<8:15:53, 18.43s/it]\n",
      "Train:  31%|███       | 713/2326 [3:43:21<8:25:30, 18.80s/it]\n",
      "Train:  31%|███       | 714/2326 [3:43:39<8:24:19, 18.77s/it]\n",
      "Train:  31%|███       | 715/2326 [3:44:00<8:39:06, 19.33s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  31%|███       | 715/2326 [3:44:00<8:39:06, 19.33s/it]\n",
      "Train:  31%|███       | 715/2326 [3:44:00<8:39:06, 19.33s/it]\n",
      "Train:  31%|███       | 716/2326 [3:44:19<8:35:31, 19.21s/it]\n",
      "Train:  31%|███       | 717/2326 [3:44:37<8:29:03, 18.98s/it]\n",
      "Train:  31%|███       | 718/2326 [3:44:57<8:34:58, 19.22s/it]\n",
      "Train:  31%|███       | 719/2326 [3:45:16<8:29:59, 19.04s/it]\n",
      "Train:  31%|███       | 720/2326 [3:45:34<8:22:51, 18.79s/it]\n",
      "                                                             \n",
      "{'loss': 2.0026226, 'token_acc': 0.56694243, 'grad_norm': 1.09299231, 'learning_rate': 8.955e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053199, 'epoch': 0.5, 'global_step/max_steps': '580/2326', 'percentage': '24.94%', 'elapsed_time': '3h 1m 42s', 'remaining_time': '9h 6m 59s'}\n",
      "{'loss': 2.09170418, 'token_acc': 0.55597767, 'grad_norm': 1.29841566, 'learning_rate': 8.933e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053205, 'epoch': 0.5, 'global_step/max_steps': '585/2326', 'percentage': '25.15%', 'elapsed_time': '3h 3m 14s', 'remaining_time': '9h 5m 21s'}\n",
      "{'loss': 1.97272758, 'token_acc': 0.57395717, 'grad_norm': 1.12070441, 'learning_rate': 8.911e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.05321, 'epoch': 0.51, 'global_step/max_steps': '590/2326', 'percentage': '25.37%', 'elapsed_time': '3h 4m 47s', 'remaining_time': '9h 3m 44s'}\n",
      "{'loss': 2.0803299, 'token_acc': 0.5519891, 'grad_norm': 0.96181196, 'learning_rate': 8.888e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053205, 'epoch': 0.51, 'global_step/max_steps': '595/2326', 'percentage': '25.58%', 'elapsed_time': '3h 6m 22s', 'remaining_time': '9h 2m 13s'}\n",
      "{'loss': 2.01252956, 'token_acc': 0.56899886, 'grad_norm': 1.43921423, 'learning_rate': 8.866e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053215, 'epoch': 0.52, 'global_step/max_steps': '600/2326', 'percentage': '25.80%', 'elapsed_time': '3h 7m 54s', 'remaining_time': '9h 0m 33s'}\n",
      "{'loss': 1.89092121, 'token_acc': 0.59641973, 'grad_norm': 1.14132428, 'learning_rate': 8.843e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053202, 'epoch': 0.52, 'global_step/max_steps': '605/2326', 'percentage': '26.01%', 'elapsed_time': '3h 9m 31s', 'remaining_time': '8h 59m 7s'}\n",
      "{'loss': 1.97046509, 'token_acc': 0.58422557, 'grad_norm': 1.15253413, 'learning_rate': 8.821e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053203, 'epoch': 0.52, 'global_step/max_steps': '610/2326', 'percentage': '26.23%', 'elapsed_time': '3h 11m 5s', 'remaining_time': '8h 57m 33s'}\n",
      "{'loss': 1.88886929, 'token_acc': 0.60027945, 'grad_norm': 1.17478275, 'learning_rate': 8.798e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.0532, 'epoch': 0.53, 'global_step/max_steps': '615/2326', 'percentage': '26.44%', 'elapsed_time': '3h 12m 40s', 'remaining_time': '8h 56m 1s'}\n",
      "{'loss': 1.92378731, 'token_acc': 0.5863071, 'grad_norm': 1.19349527, 'learning_rate': 8.774e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053201, 'epoch': 0.53, 'global_step/max_steps': '620/2326', 'percentage': '26.66%', 'elapsed_time': '3h 14m 13s', 'remaining_time': '8h 54m 26s'}\n",
      "{'loss': 1.96718311, 'token_acc': 0.58050499, 'grad_norm': 1.25454628, 'learning_rate': 8.751e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.05321, 'epoch': 0.54, 'global_step/max_steps': '625/2326', 'percentage': '26.87%', 'elapsed_time': '3h 15m 45s', 'remaining_time': '8h 52m 46s'}\n",
      "{'loss': 1.89872589, 'token_acc': 0.59122777, 'grad_norm': 1.22843397, 'learning_rate': 8.727e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053221, 'epoch': 0.54, 'global_step/max_steps': '630/2326', 'percentage': '27.09%', 'elapsed_time': '3h 17m 17s', 'remaining_time': '8h 51m 6s'}\n",
      "{'loss': 1.95173435, 'token_acc': 0.57583996, 'grad_norm': 1.20877922, 'learning_rate': 8.703e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053213, 'epoch': 0.55, 'global_step/max_steps': '635/2326', 'percentage': '27.30%', 'elapsed_time': '3h 18m 52s', 'remaining_time': '8h 49m 37s'}\n",
      "{'loss': 1.9814827, 'token_acc': 0.57570497, 'grad_norm': 1.17210507, 'learning_rate': 8.68e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.05321, 'epoch': 0.55, 'global_step/max_steps': '640/2326', 'percentage': '27.52%', 'elapsed_time': '3h 20m 27s', 'remaining_time': '8h 48m 5s'}\n",
      "{'loss': 2.04312553, 'token_acc': 0.56422898, 'grad_norm': 1.21228802, 'learning_rate': 8.655e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053211, 'epoch': 0.56, 'global_step/max_steps': '645/2326', 'percentage': '27.73%', 'elapsed_time': '3h 22m 1s', 'remaining_time': '8h 46m 30s'}\n",
      "{'loss': 2.0255352, 'token_acc': 0.56217981, 'grad_norm': 1.12285352, 'learning_rate': 8.631e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053196, 'epoch': 0.56, 'global_step/max_steps': '650/2326', 'percentage': '27.94%', 'elapsed_time': '3h 23m 38s', 'remaining_time': '8h 45m 5s'}\n",
      "{'loss': 1.98388214, 'token_acc': 0.5749154, 'grad_norm': 1.30745006, 'learning_rate': 8.606e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053186, 'epoch': 0.56, 'global_step/max_steps': '655/2326', 'percentage': '28.16%', 'elapsed_time': '3h 25m 15s', 'remaining_time': '8h 43m 37s'}\n",
      "{'loss': 1.98699093, 'token_acc': 0.56584207, 'grad_norm': 1.43696272, 'learning_rate': 8.582e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053194, 'epoch': 0.57, 'global_step/max_steps': '660/2326', 'percentage': '28.37%', 'elapsed_time': '3h 26m 47s', 'remaining_time': '8h 41m 58s'}\n",
      "{'loss': 1.88970585, 'token_acc': 0.59442399, 'grad_norm': 1.2002809, 'learning_rate': 8.557e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053199, 'epoch': 0.57, 'global_step/max_steps': '665/2326', 'percentage': '28.59%', 'elapsed_time': '3h 28m 20s', 'remaining_time': '8h 40m 21s'}\n",
      "{'loss': 1.85231323, 'token_acc': 0.59990345, 'grad_norm': 1.29562211, 'learning_rate': 8.532e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053196, 'epoch': 0.58, 'global_step/max_steps': '670/2326', 'percentage': '28.80%', 'elapsed_time': '3h 29m 54s', 'remaining_time': '8h 38m 49s'}\n",
      "{'loss': 2.03491135, 'token_acc': 0.56184544, 'grad_norm': 1.15504646, 'learning_rate': 8.507e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053199, 'epoch': 0.58, 'global_step/max_steps': '675/2326', 'percentage': '29.02%', 'elapsed_time': '3h 31m 27s', 'remaining_time': '8h 37m 13s'}\n",
      "{'loss': 1.91034718, 'token_acc': 0.59141433, 'grad_norm': 1.18190098, 'learning_rate': 8.481e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053202, 'epoch': 0.59, 'global_step/max_steps': '680/2326', 'percentage': '29.23%', 'elapsed_time': '3h 33m 1s', 'remaining_time': '8h 35m 38s'}\n",
      "{'loss': 1.91126537, 'token_acc': 0.58777682, 'grad_norm': 1.20894194, 'learning_rate': 8.455e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053202, 'epoch': 0.59, 'global_step/max_steps': '685/2326', 'percentage': '29.45%', 'elapsed_time': '3h 34m 35s', 'remaining_time': '8h 34m 4s'}\n",
      "{'loss': 1.86431599, 'token_acc': 0.59563398, 'grad_norm': 1.04459083, 'learning_rate': 8.43e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.0532, 'epoch': 0.59, 'global_step/max_steps': '690/2326', 'percentage': '29.66%', 'elapsed_time': '3h 36m 9s', 'remaining_time': '8h 32m 31s'}\n",
      "{'loss': 2.00211182, 'token_acc': 0.57179877, 'grad_norm': 1.16972232, 'learning_rate': 8.404e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053208, 'epoch': 0.6, 'global_step/max_steps': '695/2326', 'percentage': '29.88%', 'elapsed_time': '3h 37m 41s', 'remaining_time': '8h 30m 53s'}\n",
      "{'loss': 1.85874481, 'token_acc': 0.59994833, 'grad_norm': 1.06079614, 'learning_rate': 8.378e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053192, 'epoch': 0.6, 'global_step/max_steps': '700/2326', 'percentage': '30.09%', 'elapsed_time': '3h 39m 19s', 'remaining_time': '8h 29m 27s'}\n",
      "{'loss': 1.88837681, 'token_acc': 0.59305994, 'grad_norm': 1.20529294, 'learning_rate': 8.351e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053199, 'epoch': 0.61, 'global_step/max_steps': '705/2326', 'percentage': '30.31%', 'elapsed_time': '3h 40m 51s', 'remaining_time': '8h 27m 49s'}\n",
      "{'loss': 1.99840279, 'token_acc': 0.57164463, 'grad_norm': 1.13876057, 'learning_rate': 8.325e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053203, 'epoch': 0.61, 'global_step/max_steps': '710/2326', 'percentage': '30.52%', 'elapsed_time': '3h 42m 24s', 'remaining_time': '8h 26m 13s'}\n",
      "{'loss': 1.92704849, 'token_acc': 0.58328506, 'grad_norm': 0.95210636, 'learning_rate': 8.298e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053197, 'epoch': 0.62, 'global_step/max_steps': '715/2326', 'percentage': '30.74%', 'elapsed_time': '3h 44m 0s', 'remaining_time': '8h 24m 43s'}\n",
      "{'loss': 1.91255245, 'token_acc': 0.58813361, 'grad_norm': 1.2401433, 'learning_rate': 8.271e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053197, 'epoch': 0.62, 'global_step/max_steps': '720/2326', 'percentage': '30.95%', 'elapsed_time': '3h 45m 34s', 'remaining_time': '8h 23m 9s'}\n",
      "Train:  31%|███       | 720/2326 [3:45:34<8:22:51, 18.79s/it]\n",
      "Train:  31%|███       | 720/2326 [3:45:34<8:22:51, 18.79s/it]\n",
      "Train:  31%|███       | 721/2326 [3:45:53<8:26:43, 18.94s/it]\n",
      "Train:  31%|███       | 722/2326 [3:46:12<8:22:41, 18.80s/it]\n",
      "Train:  31%|███       | 723/2326 [3:46:30<8:18:01, 18.64s/it]\n",
      "Train:  31%|███       | 724/2326 [3:46:48<8:12:45, 18.46s/it]\n",
      "Train:  31%|███       | 725/2326 [3:47:06<8:12:59, 18.48s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  31%|███       | 725/2326 [3:47:06<8:12:59, 18.48s/it]\n",
      "Train:  31%|███       | 725/2326 [3:47:06<8:12:59, 18.48s/it]\n",
      "Train:  31%|███       | 726/2326 [3:47:25<8:15:16, 18.57s/it]\n",
      "Train:  31%|███▏      | 727/2326 [3:47:45<8:24:45, 18.94s/it]\n",
      "Train:  31%|███▏      | 728/2326 [3:48:03<8:19:09, 18.74s/it]\n",
      "Train:  31%|███▏      | 729/2326 [3:48:23<8:23:48, 18.93s/it]\n",
      "Train:  31%|███▏      | 730/2326 [3:48:41<8:22:50, 18.90s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  31%|███▏      | 730/2326 [3:48:42<8:22:50, 18.90s/it]\n",
      "Train:  31%|███▏      | 730/2326 [3:48:42<8:22:50, 18.90s/it]\n",
      "Train:  31%|███▏      | 731/2326 [3:48:59<8:14:06, 18.59s/it]\n",
      "Train:  31%|███▏      | 732/2326 [3:49:17<8:09:01, 18.41s/it]\n",
      "Train:  32%|███▏      | 733/2326 [3:49:36<8:11:27, 18.51s/it]\n",
      "Train:  32%|███▏      | 734/2326 [3:49:55<8:17:00, 18.73s/it]\n",
      "Train:  32%|███▏      | 735/2326 [3:50:14<8:13:06, 18.60s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  32%|███▏      | 735/2326 [3:50:14<8:13:06, 18.60s/it]\n",
      "Train:  32%|███▏      | 735/2326 [3:50:14<8:13:06, 18.60s/it]\n",
      "Train:  32%|███▏      | 736/2326 [3:50:33<8:15:39, 18.70s/it]\n",
      "Train:  32%|███▏      | 737/2326 [3:50:51<8:15:57, 18.73s/it]\n",
      "Train:  32%|███▏      | 738/2326 [3:51:10<8:13:30, 18.65s/it]\n",
      "Train:  32%|███▏      | 739/2326 [3:51:28<8:12:08, 18.61s/it]\n",
      "Train:  32%|███▏      | 740/2326 [3:51:48<8:16:47, 18.79s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  32%|███▏      | 740/2326 [3:51:48<8:16:47, 18.79s/it]\n",
      "Train:  32%|███▏      | 740/2326 [3:51:48<8:16:47, 18.79s/it]\n",
      "Train:  32%|███▏      | 741/2326 [3:52:07<8:18:51, 18.88s/it]\n",
      "Train:  32%|███▏      | 742/2326 [3:52:26<8:19:56, 18.94s/it]\n",
      "Train:  32%|███▏      | 743/2326 [3:52:45<8:20:24, 18.97s/it]\n",
      "Train:  32%|███▏      | 744/2326 [3:53:03<8:13:35, 18.72s/it]\n",
      "Train:  32%|███▏      | 745/2326 [3:53:22<8:13:03, 18.71s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  32%|███▏      | 745/2326 [3:53:22<8:13:03, 18.71s/it]\n",
      "Train:  32%|███▏      | 745/2326 [3:53:22<8:13:03, 18.71s/it]\n",
      "Train:  32%|███▏      | 746/2326 [3:53:39<8:04:18, 18.39s/it]\n",
      "Train:  32%|███▏      | 747/2326 [3:53:57<8:01:28, 18.30s/it]\n",
      "Train:  32%|███▏      | 748/2326 [3:54:15<8:00:04, 18.25s/it]\n",
      "Train:  32%|███▏      | 749/2326 [3:54:33<7:53:18, 18.01s/it]\n",
      "Train:  32%|███▏      | 750/2326 [3:54:51<7:53:48, 18.04s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  32%|███▏      | 750/2326 [3:54:51<7:53:48, 18.04s/it]\n",
      "Train:  32%|███▏      | 750/2326 [3:54:51<7:53:48, 18.04s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v10-20250927-234036/checkpoint-750\n",
      "\n",
      "Train:  32%|███▏      | 751/2326 [3:55:12<8:20:29, 19.07s/it]\n",
      "Train:  32%|███▏      | 752/2326 [3:55:31<8:18:28, 19.00s/it]\n",
      "Train:  32%|███▏      | 753/2326 [3:55:50<8:16:05, 18.92s/it]\n",
      "Train:  32%|███▏      | 754/2326 [3:56:09<8:14:09, 18.86s/it]\n",
      "Train:  32%|███▏      | 755/2326 [3:56:27<8:07:27, 18.62s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  32%|███▏      | 755/2326 [3:56:27<8:07:27, 18.62s/it]\n",
      "Train:  32%|███▏      | 755/2326 [3:56:27<8:07:27, 18.62s/it]\n",
      "Train:  33%|███▎      | 756/2326 [3:56:45<8:07:35, 18.63s/it]\n",
      "Train:  33%|███▎      | 757/2326 [3:57:03<8:01:41, 18.42s/it]\n",
      "Train:  33%|███▎      | 758/2326 [3:57:23<8:10:41, 18.78s/it]\n",
      "Train:  33%|███▎      | 759/2326 [3:57:42<8:09:27, 18.74s/it]\n",
      "Train:  33%|███▎      | 760/2326 [3:58:00<8:06:55, 18.66s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  33%|███▎      | 760/2326 [3:58:00<8:06:55, 18.66s/it]\n",
      "Train:  33%|███▎      | 760/2326 [3:58:00<8:06:55, 18.66s/it]\n",
      "Train:  33%|███▎      | 761/2326 [3:58:20<8:15:18, 18.99s/it]\n",
      "Train:  33%|███▎      | 762/2326 [3:58:41<8:28:18, 19.50s/it]\n",
      "Train:  33%|███▎      | 763/2326 [3:58:59<8:17:55, 19.11s/it]\n",
      "Train:  33%|███▎      | 764/2326 [3:59:17<8:12:55, 18.93s/it]\n",
      "Train:  33%|███▎      | 765/2326 [3:59:35<8:05:16, 18.65s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  33%|███▎      | 765/2326 [3:59:35<8:05:16, 18.65s/it]\n",
      "Train:  33%|███▎      | 765/2326 [3:59:35<8:05:16, 18.65s/it]\n",
      "Train:  33%|███▎      | 766/2326 [3:59:53<7:59:35, 18.45s/it]\n",
      "Train:  33%|███▎      | 767/2326 [4:00:13<8:09:20, 18.83s/it]\n",
      "Train:  33%|███▎      | 768/2326 [4:00:34<8:22:02, 19.33s/it]\n",
      "Train:  33%|███▎      | 769/2326 [4:00:52<8:14:39, 19.06s/it]\n",
      "Train:  33%|███▎      | 770/2326 [4:01:12<8:18:18, 19.21s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  33%|███▎      | 770/2326 [4:01:12<8:18:18, 19.21s/it]\n",
      "Train:  33%|███▎      | 770/2326 [4:01:12<8:18:18, 19.21s/it]\n",
      "Train:  33%|███▎      | 771/2326 [4:01:30<8:10:25, 18.92s/it]\n",
      "Train:  33%|███▎      | 772/2326 [4:01:49<8:12:48, 19.03s/it]\n",
      "Train:  33%|███▎      | 773/2326 [4:02:07<8:05:59, 18.78s/it]\n",
      "Train:  33%|███▎      | 774/2326 [4:02:26<8:02:24, 18.65s/it]\n",
      "Train:  33%|███▎      | 775/2326 [4:02:45<8:10:12, 18.96s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  33%|███▎      | 775/2326 [4:02:45<8:10:12, 18.96s/it]\n",
      "Train:  33%|███▎      | 775/2326 [4:02:45<8:10:12, 18.96s/it]\n",
      "Train:  33%|███▎      | 776/2326 [4:03:04<8:04:42, 18.76s/it]\n",
      "Train:  33%|███▎      | 777/2326 [4:03:23<8:08:46, 18.93s/it]\n",
      "Train:  33%|███▎      | 778/2326 [4:03:41<8:03:06, 18.73s/it]\n",
      "Train:  33%|███▎      | 779/2326 [4:03:59<7:59:36, 18.60s/it]\n",
      "Train:  34%|███▎      | 780/2326 [4:04:20<8:12:08, 19.10s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  34%|███▎      | 780/2326 [4:04:20<8:12:08, 19.10s/it]\n",
      "Train:  34%|███▎      | 780/2326 [4:04:20<8:12:08, 19.10s/it]\n",
      "Train:  34%|███▎      | 781/2326 [4:04:38<8:04:19, 18.81s/it]\n",
      "Train:  34%|███▎      | 782/2326 [4:04:57<8:06:03, 18.89s/it]\n",
      "Train:  34%|███▎      | 783/2326 [4:05:16<8:06:59, 18.94s/it]\n",
      "Train:  34%|███▎      | 784/2326 [4:05:35<8:09:17, 19.04s/it]\n",
      "Train:  34%|███▎      | 785/2326 [4:05:54<8:10:00, 19.08s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  34%|███▎      | 785/2326 [4:05:54<8:10:00, 19.08s/it]\n",
      "Train:  34%|███▎      | 785/2326 [4:05:54<8:10:00, 19.08s/it]\n",
      "Train:  34%|███▍      | 786/2326 [4:06:12<8:01:30, 18.76s/it]\n",
      "Train:  34%|███▍      | 787/2326 [4:06:30<7:51:40, 18.39s/it]\n",
      "Train:  34%|███▍      | 788/2326 [4:06:49<7:57:10, 18.62s/it]\n",
      "Train:  34%|███▍      | 789/2326 [4:07:08<7:58:35, 18.68s/it]\n",
      "Train:  34%|███▍      | 790/2326 [4:07:26<7:56:00, 18.59s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  34%|███▍      | 790/2326 [4:07:26<7:56:00, 18.59s/it]\n",
      "Train:  34%|███▍      | 790/2326 [4:07:26<7:56:00, 18.59s/it]\n",
      "Train:  34%|███▍      | 791/2326 [4:07:45<7:59:09, 18.73s/it]\n",
      "Train:  34%|███▍      | 792/2326 [4:08:04<7:55:49, 18.61s/it]\n",
      "Train:  34%|███▍      | 793/2326 [4:08:22<7:49:58, 18.39s/it]\n",
      "Train:  34%|███▍      | 794/2326 [4:08:40<7:51:43, 18.47s/it]\n",
      "Train:  34%|███▍      | 795/2326 [4:08:59<7:50:03, 18.42s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  34%|███▍      | 795/2326 [4:08:59<7:50:03, 18.42s/it]\n",
      "Train:  34%|███▍      | 795/2326 [4:08:59<7:50:03, 18.42s/it]\n",
      "Train:  34%|███▍      | 796/2326 [4:09:17<7:49:47, 18.42s/it]\n",
      "Train:  34%|███▍      | 797/2326 [4:09:36<7:50:24, 18.46s/it]\n",
      "Train:  34%|███▍      | 798/2326 [4:09:54<7:47:38, 18.36s/it]\n",
      "Train:  34%|███▍      | 799/2326 [4:10:12<7:48:07, 18.39s/it]\n",
      "Train:  34%|███▍      | 800/2326 [4:10:32<7:57:52, 18.79s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  34%|███▍      | 800/2326 [4:10:32<7:57:52, 18.79s/it]\n",
      "Train:  34%|███▍      | 800/2326 [4:10:32<7:57:52, 18.79s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v10-20250927-234036/checkpoint-800\n",
      "\n",
      "Train:  34%|███▍      | 801/2326 [4:10:51<8:02:25, 18.98s/it]\n",
      "Train:  34%|███▍      | 802/2326 [4:11:10<8:00:43, 18.93s/it]\n",
      "Train:  35%|███▍      | 803/2326 [4:11:29<7:57:46, 18.82s/it]\n",
      "Train:  35%|███▍      | 804/2326 [4:11:49<8:07:36, 19.22s/it]\n",
      "Train:  35%|███▍      | 805/2326 [4:12:08<8:03:57, 19.09s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  35%|███▍      | 805/2326 [4:12:08<8:03:57, 19.09s/it]\n",
      "Train:  35%|███▍      | 805/2326 [4:12:08<8:03:57, 19.09s/it]\n",
      "Train:  35%|███▍      | 806/2326 [4:12:26<8:02:13, 19.04s/it]\n",
      "Train:  35%|███▍      | 807/2326 [4:12:45<7:58:42, 18.91s/it]\n",
      "Train:  35%|███▍      | 808/2326 [4:13:04<8:01:28, 19.03s/it]\n",
      "Train:  35%|███▍      | 809/2326 [4:13:22<7:49:20, 18.56s/it]\n",
      "Train:  35%|███▍      | 810/2326 [4:13:40<7:47:56, 18.52s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  35%|███▍      | 810/2326 [4:13:40<7:47:56, 18.52s/it]\n",
      "Train:  35%|███▍      | 810/2326 [4:13:40<7:47:56, 18.52s/it]\n",
      "Train:  35%|███▍      | 811/2326 [4:13:59<7:49:40, 18.60s/it]\n",
      "Train:  35%|███▍      | 812/2326 [4:14:18<7:49:33, 18.61s/it]\n",
      "Train:  35%|███▍      | 813/2326 [4:14:36<7:47:34, 18.54s/it]\n",
      "Train:  35%|███▍      | 814/2326 [4:14:55<7:50:27, 18.67s/it]\n",
      "Train:  35%|███▌      | 815/2326 [4:15:13<7:47:54, 18.58s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  35%|███▌      | 815/2326 [4:15:13<7:47:54, 18.58s/it]\n",
      "Train:  35%|███▌      | 815/2326 [4:15:13<7:47:54, 18.58s/it]\n",
      "Train:  35%|███▌      | 816/2326 [4:15:33<7:55:43, 18.90s/it]\n",
      "Train:  35%|███▌      | 817/2326 [4:15:51<7:48:47, 18.64s/it]\n",
      "Train:  35%|███▌      | 818/2326 [4:16:10<7:53:07, 18.82s/it]\n",
      "Train:  35%|███▌      | 819/2326 [4:16:30<7:57:29, 19.01s/it]\n",
      "Train:  35%|███▌      | 820/2326 [4:16:48<7:48:22, 18.66s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  35%|███▌      | 820/2326 [4:16:48<7:48:22, 18.66s/it]\n",
      "Train:  35%|███▌      | 820/2326 [4:16:48<7:48:22, 18.66s/it]\n",
      "Train:  35%|███▌      | 821/2326 [4:17:06<7:42:23, 18.43s/it]\n",
      "Train:  35%|███▌      | 822/2326 [4:17:25<7:48:07, 18.68s/it]\n",
      "Train:  35%|███▌      | 823/2326 [4:17:44<7:51:20, 18.82s/it]\n",
      "Train:  35%|███▌      | 824/2326 [4:18:02<7:45:53, 18.61s/it]\n",
      "Train:  35%|███▌      | 825/2326 [4:18:21<7:46:36, 18.65s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  35%|███▌      | 825/2326 [4:18:21<7:46:36, 18.65s/it]\n",
      "Train:  35%|███▌      | 825/2326 [4:18:21<7:46:36, 18.65s/it]\n",
      "Train:  36%|███▌      | 826/2326 [4:18:39<7:45:25, 18.62s/it]\n",
      "Train:  36%|███▌      | 827/2326 [4:18:59<7:49:50, 18.81s/it]\n",
      "Train:  36%|███▌      | 828/2326 [4:19:18<7:56:18, 19.08s/it]\n",
      "Train:  36%|███▌      | 829/2326 [4:19:37<7:50:16, 18.85s/it]\n",
      "Train:  36%|███▌      | 830/2326 [4:19:56<7:51:25, 18.91s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  36%|███▌      | 830/2326 [4:19:56<7:51:25, 18.91s/it]\n",
      "Train:  36%|███▌      | 830/2326 [4:19:56<7:51:25, 18.91s/it]\n",
      "Train:  36%|███▌      | 831/2326 [4:20:14<7:49:00, 18.82s/it]\n",
      "Train:  36%|███▌      | 832/2326 [4:20:33<7:47:40, 18.78s/it]\n",
      "Train:  36%|███▌      | 833/2326 [4:20:51<7:42:55, 18.60s/it]\n",
      "Train:  36%|███▌      | 834/2326 [4:21:09<7:39:01, 18.46s/it]\n",
      "Train:  36%|███▌      | 835/2326 [4:21:28<7:41:57, 18.59s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  36%|███▌      | 835/2326 [4:21:28<7:41:57, 18.59s/it]\n",
      "Train:  36%|███▌      | 835/2326 [4:21:28<7:41:57, 18.59s/it]\n",
      "Train:  36%|███▌      | 836/2326 [4:21:47<7:44:09, 18.69s/it]\n",
      "Train:  36%|███▌      | 837/2326 [4:22:06<7:41:30, 18.60s/it]\n",
      "Train:  36%|███▌      | 838/2326 [4:22:25<7:49:32, 18.93s/it]\n",
      "Train:  36%|███▌      | 839/2326 [4:22:44<7:44:36, 18.75s/it]\n",
      "Train:  36%|███▌      | 840/2326 [4:23:02<7:44:36, 18.76s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  36%|███▌      | 840/2326 [4:23:02<7:44:36, 18.76s/it]\n",
      "Train:  36%|███▌      | 840/2326 [4:23:02<7:44:36, 18.76s/it]\n",
      "Train:  36%|███▌      | 841/2326 [4:23:21<7:41:09, 18.63s/it]\n",
      "Train:  36%|███▌      | 842/2326 [4:23:39<7:38:54, 18.55s/it]\n",
      "Train:  36%|███▌      | 843/2326 [4:23:58<7:44:15, 18.78s/it]\n",
      "Train:  36%|███▋      | 844/2326 [4:24:18<7:53:31, 19.17s/it]\n",
      "Train:  36%|███▋      | 845/2326 [4:24:36<7:43:35, 18.78s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  36%|███▋      | 845/2326 [4:24:36<7:43:35, 18.78s/it]\n",
      "Train:  36%|███▋      | 845/2326 [4:24:36<7:43:35, 18.78s/it]\n",
      "Train:  36%|███▋      | 846/2326 [4:24:55<7:41:36, 18.71s/it]\n",
      "Train:  36%|███▋      | 847/2326 [4:25:13<7:38:46, 18.61s/it]\n",
      "Train:  36%|███▋      | 848/2326 [4:25:32<7:39:59, 18.67s/it]\n",
      "Train:  37%|███▋      | 849/2326 [4:25:51<7:40:03, 18.69s/it]\n",
      "Train:  37%|███▋      | 850/2326 [4:26:09<7:34:14, 18.47s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  37%|███▋      | 850/2326 [4:26:09<7:34:14, 18.47s/it]\n",
      "Train:  37%|███▋      | 850/2326 [4:26:09<7:34:14, 18.47s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v10-20250927-234036/checkpoint-850\n",
      "\n",
      "Train:  37%|███▋      | 851/2326 [4:26:29<7:47:40, 19.02s/it]\n",
      "Train:  37%|███▋      | 852/2326 [4:26:47<7:42:17, 18.82s/it]\n",
      "Train:  37%|███▋      | 853/2326 [4:27:06<7:43:19, 18.87s/it]\n",
      "Train:  37%|███▋      | 854/2326 [4:27:25<7:41:11, 18.80s/it]\n",
      "Train:  37%|███▋      | 855/2326 [4:27:44<7:40:39, 18.79s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  37%|███▋      | 855/2326 [4:27:44<7:40:39, 18.79s/it]\n",
      "Train:  37%|███▋      | 855/2326 [4:27:44<7:40:39, 18.79s/it]\n",
      "Train:  37%|███▋      | 856/2326 [4:28:04<7:47:27, 19.08s/it]\n",
      "Train:  37%|███▋      | 857/2326 [4:28:21<7:38:23, 18.72s/it]\n",
      "Train:  37%|███▋      | 858/2326 [4:28:40<7:40:18, 18.81s/it]\n",
      "Train:  37%|███▋      | 859/2326 [4:28:58<7:34:15, 18.58s/it]\n",
      "Train:  37%|███▋      | 860/2326 [4:29:18<7:39:32, 18.81s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  37%|███▋      | 860/2326 [4:29:18<7:39:32, 18.81s/it]\n",
      "Train:  37%|███▋      | 860/2326 [4:29:18<7:39:32, 18.81s/it]\n",
      "Train:  37%|███▋      | 861/2326 [4:29:38<7:49:50, 19.24s/it]\n",
      "Train:  37%|███▋      | 862/2326 [4:29:57<7:46:12, 19.11s/it]\n",
      "Train:  37%|███▋      | 863/2326 [4:30:15<7:35:33, 18.68s/it]\n",
      "Train:  37%|███▋      | 864/2326 [4:30:34<7:37:12, 18.76s/it]\n",
      "Train:  37%|███▋      | 865/2326 [4:30:52<7:35:56, 18.72s/it]\n",
      "                                                             \n",
      "{'loss': 2.00643673, 'token_acc': 0.56610012, 'grad_norm': 1.28455603, 'learning_rate': 8.244e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053202, 'epoch': 0.62, 'global_step/max_steps': '725/2326', 'percentage': '31.17%', 'elapsed_time': '3h 47m 6s', 'remaining_time': '8h 21m 32s'}\n",
      "{'loss': 1.95084476, 'token_acc': 0.57709908, 'grad_norm': 1.14467084, 'learning_rate': 8.217e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053198, 'epoch': 0.63, 'global_step/max_steps': '730/2326', 'percentage': '31.38%', 'elapsed_time': '3h 48m 42s', 'remaining_time': '8h 20m 0s'}\n",
      "{'loss': 1.96535645, 'token_acc': 0.58423898, 'grad_norm': 1.31726539, 'learning_rate': 8.19e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053205, 'epoch': 0.63, 'global_step/max_steps': '735/2326', 'percentage': '31.60%', 'elapsed_time': '3h 50m 14s', 'remaining_time': '8h 18m 22s'}\n",
      "{'loss': 1.91326294, 'token_acc': 0.59398959, 'grad_norm': 1.18912566, 'learning_rate': 8.163e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053206, 'epoch': 0.64, 'global_step/max_steps': '740/2326', 'percentage': '31.81%', 'elapsed_time': '3h 51m 48s', 'remaining_time': '8h 16m 48s'}\n",
      "{'loss': 1.92440853, 'token_acc': 0.59277083, 'grad_norm': 1.12965012, 'learning_rate': 8.135e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053205, 'epoch': 0.64, 'global_step/max_steps': '745/2326', 'percentage': '32.03%', 'elapsed_time': '3h 53m 22s', 'remaining_time': '8h 15m 14s'}\n",
      "{'loss': 1.79563084, 'token_acc': 0.60967281, 'grad_norm': 1.27931368, 'learning_rate': 8.107e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053223, 'epoch': 0.65, 'global_step/max_steps': '750/2326', 'percentage': '32.24%', 'elapsed_time': '3h 54m 51s', 'remaining_time': '8h 13m 31s'}\n",
      "{'loss': 1.87404499, 'token_acc': 0.59614033, 'grad_norm': 1.22970891, 'learning_rate': 8.079e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053216, 'epoch': 0.65, 'global_step/max_steps': '755/2326', 'percentage': '32.46%', 'elapsed_time': '3h 56m 27s', 'remaining_time': '8h 12m 0s'}\n",
      "{'loss': 1.83151493, 'token_acc': 0.60818389, 'grad_norm': 1.19169343, 'learning_rate': 8.051e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053218, 'epoch': 0.65, 'global_step/max_steps': '760/2326', 'percentage': '32.67%', 'elapsed_time': '3h 58m 0s', 'remaining_time': '8h 10m 25s'}\n",
      "{'loss': 2.02936687, 'token_acc': 0.56423602, 'grad_norm': 1.61290061, 'learning_rate': 8.023e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053213, 'epoch': 0.66, 'global_step/max_steps': '765/2326', 'percentage': '32.89%', 'elapsed_time': '3h 59m 35s', 'remaining_time': '8h 8m 54s'}\n",
      "{'loss': 1.82826519, 'token_acc': 0.60797813, 'grad_norm': 1.27732134, 'learning_rate': 7.994e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053205, 'epoch': 0.66, 'global_step/max_steps': '770/2326', 'percentage': '33.10%', 'elapsed_time': '4h 1m 12s', 'remaining_time': '8h 7m 24s'}\n",
      "{'loss': 1.88769264, 'token_acc': 0.5957923, 'grad_norm': 1.236467, 'learning_rate': 7.966e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053206, 'epoch': 0.67, 'global_step/max_steps': '775/2326', 'percentage': '33.32%', 'elapsed_time': '4h 2m 45s', 'remaining_time': '8h 5m 50s'}\n",
      "{'loss': 1.94111977, 'token_acc': 0.58125923, 'grad_norm': 1.10317969, 'learning_rate': 7.937e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053204, 'epoch': 0.67, 'global_step/max_steps': '780/2326', 'percentage': '33.53%', 'elapsed_time': '4h 4m 20s', 'remaining_time': '8h 4m 17s'}\n",
      "{'loss': 1.90142479, 'token_acc': 0.59092139, 'grad_norm': 1.35964358, 'learning_rate': 7.908e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053202, 'epoch': 0.68, 'global_step/max_steps': '785/2326', 'percentage': '33.75%', 'elapsed_time': '4h 5m 54s', 'remaining_time': '8h 2m 44s'}\n",
      "{'loss': 1.86788559, 'token_acc': 0.60238054, 'grad_norm': 1.39244771, 'learning_rate': 7.879e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053209, 'epoch': 0.68, 'global_step/max_steps': '790/2326', 'percentage': '33.96%', 'elapsed_time': '4h 7m 26s', 'remaining_time': '8h 1m 6s'}\n",
      "{'loss': 1.98057766, 'token_acc': 0.57902139, 'grad_norm': 1.26349711, 'learning_rate': 7.85e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053215, 'epoch': 0.68, 'global_step/max_steps': '795/2326', 'percentage': '34.18%', 'elapsed_time': '4h 8m 59s', 'remaining_time': '7h 59m 29s'}\n",
      "{'loss': 1.86951046, 'token_acc': 0.59929199, 'grad_norm': 1.10566318, 'learning_rate': 7.821e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053218, 'epoch': 0.69, 'global_step/max_steps': '800/2326', 'percentage': '34.39%', 'elapsed_time': '4h 10m 32s', 'remaining_time': '7h 57m 54s'}\n",
      "{'loss': 1.93309402, 'token_acc': 0.58445449, 'grad_norm': 1.23583114, 'learning_rate': 7.792e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053211, 'epoch': 0.69, 'global_step/max_steps': '805/2326', 'percentage': '34.61%', 'elapsed_time': '4h 12m 8s', 'remaining_time': '7h 56m 23s'}\n",
      "{'loss': 1.77664948, 'token_acc': 0.62478544, 'grad_norm': 1.2795397, 'learning_rate': 7.762e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053216, 'epoch': 0.7, 'global_step/max_steps': '810/2326', 'percentage': '34.82%', 'elapsed_time': '4h 13m 40s', 'remaining_time': '7h 54m 47s'}\n",
      "{'loss': 1.84479198, 'token_acc': 0.59778436, 'grad_norm': 1.46902227, 'learning_rate': 7.732e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053218, 'epoch': 0.7, 'global_step/max_steps': '815/2326', 'percentage': '35.04%', 'elapsed_time': '4h 15m 13s', 'remaining_time': '7h 53m 11s'}\n",
      "{'loss': 1.92180233, 'token_acc': 0.58862352, 'grad_norm': 1.39971864, 'learning_rate': 7.702e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053218, 'epoch': 0.71, 'global_step/max_steps': '820/2326', 'percentage': '35.25%', 'elapsed_time': '4h 16m 48s', 'remaining_time': '7h 51m 38s'}\n",
      "{'loss': 1.88660011, 'token_acc': 0.59386292, 'grad_norm': 1.44842017, 'learning_rate': 7.672e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.05322, 'epoch': 0.71, 'global_step/max_steps': '825/2326', 'percentage': '35.47%', 'elapsed_time': '4h 18m 21s', 'remaining_time': '7h 50m 3s'}\n",
      "{'loss': 2.00328255, 'token_acc': 0.5650827, 'grad_norm': 1.2949791, 'learning_rate': 7.642e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053217, 'epoch': 0.71, 'global_step/max_steps': '830/2326', 'percentage': '35.68%', 'elapsed_time': '4h 19m 56s', 'remaining_time': '7h 48m 30s'}\n",
      "{'loss': 1.90965233, 'token_acc': 0.58925849, 'grad_norm': 1.4211005, 'learning_rate': 7.612e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053222, 'epoch': 0.72, 'global_step/max_steps': '835/2326', 'percentage': '35.90%', 'elapsed_time': '4h 21m 28s', 'remaining_time': '7h 46m 54s'}\n",
      "{'loss': 1.87526131, 'token_acc': 0.59883531, 'grad_norm': 1.14895952, 'learning_rate': 7.582e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053221, 'epoch': 0.72, 'global_step/max_steps': '840/2326', 'percentage': '36.11%', 'elapsed_time': '4h 23m 2s', 'remaining_time': '7h 45m 20s'}\n",
      "{'loss': 1.86068211, 'token_acc': 0.60016353, 'grad_norm': 1.26507115, 'learning_rate': 7.551e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053221, 'epoch': 0.73, 'global_step/max_steps': '845/2326', 'percentage': '36.33%', 'elapsed_time': '4h 24m 36s', 'remaining_time': '7h 43m 46s'}\n",
      "{'loss': 1.98215313, 'token_acc': 0.57609759, 'grad_norm': 1.2952069, 'learning_rate': 7.52e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053226, 'epoch': 0.73, 'global_step/max_steps': '850/2326', 'percentage': '36.54%', 'elapsed_time': '4h 26m 9s', 'remaining_time': '7h 42m 10s'}\n",
      "{'loss': 1.97304115, 'token_acc': 0.57338866, 'grad_norm': 1.34571159, 'learning_rate': 7.49e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053223, 'epoch': 0.74, 'global_step/max_steps': '855/2326', 'percentage': '36.76%', 'elapsed_time': '4h 27m 44s', 'remaining_time': '7h 40m 38s'}\n",
      "{'loss': 1.95791531, 'token_acc': 0.57724765, 'grad_norm': 1.43993104, 'learning_rate': 7.459e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053222, 'epoch': 0.74, 'global_step/max_steps': '860/2326', 'percentage': '36.97%', 'elapsed_time': '4h 29m 18s', 'remaining_time': '7h 39m 4s'}\n",
      "{'loss': 1.82227993, 'token_acc': 0.61014586, 'grad_norm': 1.38009083, 'learning_rate': 7.428e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053221, 'epoch': 0.74, 'global_step/max_steps': '865/2326', 'percentage': '37.19%', 'elapsed_time': '4h 30m 52s', 'remaining_time': '7h 37m 31s'}\n",
      "Train:  37%|███▋      | 865/2326 [4:30:52<7:35:56, 18.72s/it]\n",
      "Train:  37%|███▋      | 865/2326 [4:30:52<7:35:56, 18.72s/it]\n",
      "Train:  37%|███▋      | 866/2326 [4:31:12<7:46:02, 19.15s/it]\n",
      "Train:  37%|███▋      | 867/2326 [4:31:32<7:46:46, 19.20s/it]\n",
      "Train:  37%|███▋      | 868/2326 [4:31:50<7:41:18, 18.98s/it]\n",
      "Train:  37%|███▋      | 869/2326 [4:32:09<7:38:07, 18.87s/it]\n",
      "Train:  37%|███▋      | 870/2326 [4:32:27<7:33:51, 18.70s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  37%|███▋      | 870/2326 [4:32:27<7:33:51, 18.70s/it]\n",
      "Train:  37%|███▋      | 870/2326 [4:32:27<7:33:51, 18.70s/it]\n",
      "Train:  37%|███▋      | 871/2326 [4:32:46<7:33:36, 18.71s/it]\n",
      "Train:  37%|███▋      | 872/2326 [4:33:04<7:29:20, 18.54s/it]\n",
      "Train:  38%|███▊      | 873/2326 [4:33:23<7:34:22, 18.76s/it]\n",
      "Train:  38%|███▊      | 874/2326 [4:33:42<7:31:31, 18.66s/it]\n",
      "Train:  38%|███▊      | 875/2326 [4:34:01<7:36:33, 18.88s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  38%|███▊      | 875/2326 [4:34:01<7:36:33, 18.88s/it]\n",
      "Train:  38%|███▊      | 875/2326 [4:34:01<7:36:33, 18.88s/it]\n",
      "Train:  38%|███▊      | 876/2326 [4:34:19<7:32:21, 18.72s/it]\n",
      "Train:  38%|███▊      | 877/2326 [4:34:39<7:41:45, 19.12s/it]\n",
      "Train:  38%|███▊      | 878/2326 [4:34:58<7:41:02, 19.10s/it]\n",
      "Train:  38%|███▊      | 879/2326 [4:35:18<7:46:16, 19.33s/it]\n",
      "Train:  38%|███▊      | 880/2326 [4:35:40<7:59:56, 19.91s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  38%|███▊      | 880/2326 [4:35:40<7:59:56, 19.91s/it]\n",
      "Train:  38%|███▊      | 880/2326 [4:35:40<7:59:56, 19.91s/it]\n",
      "Train:  38%|███▊      | 881/2326 [4:35:58<7:52:21, 19.61s/it]\n",
      "Train:  38%|███▊      | 882/2326 [4:36:17<7:41:33, 19.18s/it]\n",
      "Train:  38%|███▊      | 883/2326 [4:36:35<7:36:32, 18.98s/it]\n",
      "Train:  38%|███▊      | 884/2326 [4:36:54<7:35:02, 18.93s/it]\n",
      "Train:  38%|███▊      | 885/2326 [4:37:14<7:43:26, 19.30s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  38%|███▊      | 885/2326 [4:37:14<7:43:26, 19.30s/it]\n",
      "Train:  38%|███▊      | 885/2326 [4:37:14<7:43:26, 19.30s/it]\n",
      "Train:  38%|███▊      | 886/2326 [4:37:33<7:37:53, 19.08s/it]\n",
      "Train:  38%|███▊      | 887/2326 [4:37:52<7:38:45, 19.13s/it]\n",
      "Train:  38%|███▊      | 888/2326 [4:38:10<7:31:15, 18.83s/it]\n",
      "Train:  38%|███▊      | 889/2326 [4:38:28<7:24:03, 18.54s/it]\n",
      "Train:  38%|███▊      | 890/2326 [4:38:48<7:31:09, 18.85s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  38%|███▊      | 890/2326 [4:38:48<7:31:09, 18.85s/it]\n",
      "Train:  38%|███▊      | 890/2326 [4:38:48<7:31:09, 18.85s/it]\n",
      "Train:  38%|███▊      | 891/2326 [4:39:06<7:28:52, 18.77s/it]\n",
      "Train:  38%|███▊      | 892/2326 [4:39:26<7:33:22, 18.97s/it]\n",
      "Train:  38%|███▊      | 893/2326 [4:39:44<7:27:57, 18.76s/it]\n",
      "Train:  38%|███▊      | 894/2326 [4:40:02<7:23:13, 18.57s/it]\n",
      "Train:  38%|███▊      | 895/2326 [4:40:19<7:14:18, 18.21s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  38%|███▊      | 895/2326 [4:40:19<7:14:18, 18.21s/it]\n",
      "Train:  38%|███▊      | 895/2326 [4:40:19<7:14:18, 18.21s/it]\n",
      "Train:  39%|███▊      | 896/2326 [4:40:38<7:20:51, 18.50s/it]\n",
      "Train:  39%|███▊      | 897/2326 [4:40:57<7:19:04, 18.44s/it]\n",
      "Train:  39%|███▊      | 898/2326 [4:41:15<7:13:54, 18.23s/it]\n",
      "Train:  39%|███▊      | 899/2326 [4:41:34<7:19:21, 18.47s/it]\n",
      "Train:  39%|███▊      | 900/2326 [4:41:52<7:16:54, 18.38s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  39%|███▊      | 900/2326 [4:41:52<7:16:54, 18.38s/it]\n",
      "Train:  39%|███▊      | 900/2326 [4:41:52<7:16:54, 18.38s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v10-20250927-234036/checkpoint-900\n",
      "\n",
      "Train:  39%|███▊      | 901/2326 [4:42:12<7:29:02, 18.91s/it]\n",
      "Train:  39%|███▉      | 902/2326 [4:42:32<7:37:23, 19.27s/it]\n",
      "Train:  39%|███▉      | 903/2326 [4:42:51<7:32:33, 19.08s/it]\n",
      "Train:  39%|███▉      | 904/2326 [4:43:10<7:32:34, 19.10s/it]\n",
      "Train:  39%|███▉      | 905/2326 [4:43:29<7:35:55, 19.25s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  39%|███▉      | 905/2326 [4:43:29<7:35:55, 19.25s/it]\n",
      "Train:  39%|███▉      | 905/2326 [4:43:29<7:35:55, 19.25s/it]\n",
      "Train:  39%|███▉      | 906/2326 [4:43:48<7:34:33, 19.21s/it]\n",
      "Train:  39%|███▉      | 907/2326 [4:44:07<7:32:31, 19.13s/it]\n",
      "Train:  39%|███▉      | 908/2326 [4:44:26<7:30:48, 19.08s/it]\n",
      "Train:  39%|███▉      | 909/2326 [4:44:45<7:29:11, 19.02s/it]\n",
      "Train:  39%|███▉      | 910/2326 [4:45:07<7:45:29, 19.72s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  39%|███▉      | 910/2326 [4:45:07<7:45:29, 19.72s/it]\n",
      "Train:  39%|███▉      | 910/2326 [4:45:07<7:45:29, 19.72s/it]\n",
      "Train:  39%|███▉      | 911/2326 [4:45:26<7:39:46, 19.50s/it]\n",
      "Train:  39%|███▉      | 912/2326 [4:45:44<7:32:29, 19.20s/it]\n",
      "Train:  39%|███▉      | 913/2326 [4:46:02<7:20:29, 18.70s/it]\n",
      "Train:  39%|███▉      | 914/2326 [4:46:21<7:22:56, 18.82s/it]\n",
      "Train:  39%|███▉      | 915/2326 [4:46:40<7:27:11, 19.02s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  39%|███▉      | 915/2326 [4:46:40<7:27:11, 19.02s/it]\n",
      "Train:  39%|███▉      | 915/2326 [4:46:40<7:27:11, 19.02s/it]\n",
      "Train:  39%|███▉      | 916/2326 [4:46:59<7:24:27, 18.91s/it]\n",
      "Train:  39%|███▉      | 917/2326 [4:47:19<7:31:29, 19.23s/it]\n",
      "Train:  39%|███▉      | 918/2326 [4:47:38<7:27:33, 19.07s/it]\n",
      "Train:  40%|███▉      | 919/2326 [4:47:55<7:19:19, 18.73s/it]\n",
      "Train:  40%|███▉      | 920/2326 [4:48:14<7:14:03, 18.52s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  40%|███▉      | 920/2326 [4:48:14<7:14:03, 18.52s/it]\n",
      "Train:  40%|███▉      | 920/2326 [4:48:14<7:14:03, 18.52s/it]\n",
      "Train:  40%|███▉      | 921/2326 [4:48:32<7:14:56, 18.57s/it]\n",
      "Train:  40%|███▉      | 922/2326 [4:48:50<7:10:11, 18.38s/it]\n",
      "Train:  40%|███▉      | 923/2326 [4:49:09<7:13:13, 18.53s/it]\n",
      "Train:  40%|███▉      | 924/2326 [4:49:29<7:24:47, 19.03s/it]\n",
      "Train:  40%|███▉      | 925/2326 [4:49:51<7:42:45, 19.82s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  40%|███▉      | 925/2326 [4:49:51<7:42:45, 19.82s/it]\n",
      "Train:  40%|███▉      | 925/2326 [4:49:51<7:42:45, 19.82s/it]\n",
      "Train:  40%|███▉      | 926/2326 [4:50:11<7:45:25, 19.95s/it]\n",
      "Train:  40%|███▉      | 927/2326 [4:50:29<7:32:16, 19.40s/it]\n",
      "Train:  40%|███▉      | 928/2326 [4:50:49<7:31:03, 19.36s/it]\n",
      "Train:  40%|███▉      | 929/2326 [4:51:08<7:29:02, 19.29s/it]\n",
      "Train:  40%|███▉      | 930/2326 [4:51:26<7:23:17, 19.05s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  40%|███▉      | 930/2326 [4:51:26<7:23:17, 19.05s/it]\n",
      "Train:  40%|███▉      | 930/2326 [4:51:26<7:23:17, 19.05s/it]\n",
      "Train:  40%|████      | 931/2326 [4:51:46<7:26:27, 19.20s/it]\n",
      "Train:  40%|████      | 932/2326 [4:52:06<7:32:12, 19.46s/it]\n",
      "Train:  40%|████      | 933/2326 [4:52:24<7:24:51, 19.16s/it]\n",
      "Train:  40%|████      | 934/2326 [4:52:43<7:23:51, 19.13s/it]\n",
      "Train:  40%|████      | 935/2326 [4:53:02<7:21:01, 19.02s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  40%|████      | 935/2326 [4:53:02<7:21:01, 19.02s/it]\n",
      "Train:  40%|████      | 935/2326 [4:53:02<7:21:01, 19.02s/it]\n",
      "Train:  40%|████      | 936/2326 [4:53:22<7:27:23, 19.31s/it]\n",
      "Train:  40%|████      | 937/2326 [4:53:42<7:32:23, 19.54s/it]\n",
      "Train:  40%|████      | 938/2326 [4:54:00<7:21:27, 19.08s/it]\n",
      "Train:  40%|████      | 939/2326 [4:54:19<7:17:52, 18.94s/it]\n",
      "Train:  40%|████      | 940/2326 [4:54:38<7:20:18, 19.06s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  40%|████      | 940/2326 [4:54:38<7:20:18, 19.06s/it]\n",
      "Train:  40%|████      | 940/2326 [4:54:38<7:20:18, 19.06s/it]\n",
      "Train:  40%|████      | 941/2326 [4:54:57<7:18:01, 18.98s/it]\n",
      "Train:  40%|████      | 942/2326 [4:55:15<7:13:05, 18.78s/it]\n",
      "Train:  41%|████      | 943/2326 [4:55:34<7:16:13, 18.93s/it]\n",
      "Train:  41%|████      | 944/2326 [4:55:53<7:12:43, 18.79s/it]\n",
      "Train:  41%|████      | 945/2326 [4:56:12<7:13:35, 18.84s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  41%|████      | 945/2326 [4:56:12<7:13:35, 18.84s/it]\n",
      "Train:  41%|████      | 945/2326 [4:56:12<7:13:35, 18.84s/it]\n",
      "Train:  41%|████      | 946/2326 [4:56:34<7:35:20, 19.80s/it]\n",
      "Train:  41%|████      | 947/2326 [4:56:54<7:35:20, 19.81s/it]\n",
      "Train:  41%|████      | 948/2326 [4:57:12<7:22:22, 19.26s/it]\n",
      "Train:  41%|████      | 949/2326 [4:57:31<7:24:00, 19.35s/it]\n",
      "Train:  41%|████      | 950/2326 [4:57:51<7:26:58, 19.49s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  41%|████      | 950/2326 [4:57:51<7:26:58, 19.49s/it]\n",
      "Train:  41%|████      | 950/2326 [4:57:51<7:26:58, 19.49s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v10-20250927-234036/checkpoint-950\n",
      "\n",
      "Train:  41%|████      | 951/2326 [4:58:10<7:22:52, 19.33s/it]\n",
      "Train:  41%|████      | 952/2326 [4:58:29<7:20:19, 19.23s/it]\n",
      "Train:  41%|████      | 953/2326 [4:58:50<7:29:33, 19.65s/it]\n",
      "Train:  41%|████      | 954/2326 [4:59:09<7:27:08, 19.55s/it]\n",
      "Train:  41%|████      | 955/2326 [4:59:30<7:37:12, 20.01s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  41%|████      | 955/2326 [4:59:30<7:37:12, 20.01s/it]\n",
      "Train:  41%|████      | 955/2326 [4:59:30<7:37:12, 20.01s/it]\n",
      "Train:  41%|████      | 956/2326 [4:59:48<7:26:04, 19.54s/it]\n",
      "Train:  41%|████      | 957/2326 [5:00:09<7:29:01, 19.68s/it]\n",
      "Train:  41%|████      | 958/2326 [5:00:28<7:24:56, 19.51s/it]\n",
      "Train:  41%|████      | 959/2326 [5:00:46<7:20:03, 19.31s/it]\n",
      "Train:  41%|████▏     | 960/2326 [5:01:04<7:09:35, 18.87s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  41%|████▏     | 960/2326 [5:01:05<7:09:35, 18.87s/it]\n",
      "Train:  41%|████▏     | 960/2326 [5:01:05<7:09:35, 18.87s/it]\n",
      "Train:  41%|████▏     | 961/2326 [5:01:24<7:17:26, 19.23s/it]\n",
      "Train:  41%|████▏     | 962/2326 [5:01:44<7:16:22, 19.20s/it]\n",
      "Train:  41%|████▏     | 963/2326 [5:02:02<7:13:10, 19.07s/it]\n",
      "Train:  41%|████▏     | 964/2326 [5:02:21<7:08:42, 18.89s/it]\n",
      "Train:  41%|████▏     | 965/2326 [5:02:39<7:07:08, 18.83s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  41%|████▏     | 965/2326 [5:02:39<7:07:08, 18.83s/it]\n",
      "Train:  41%|████▏     | 965/2326 [5:02:39<7:07:08, 18.83s/it]\n",
      "Train:  42%|████▏     | 966/2326 [5:02:58<7:03:44, 18.69s/it]\n",
      "Train:  42%|████▏     | 967/2326 [5:03:17<7:03:50, 18.71s/it]\n",
      "Train:  42%|████▏     | 968/2326 [5:03:36<7:06:11, 18.83s/it]\n",
      "Train:  42%|████▏     | 969/2326 [5:03:54<7:05:05, 18.80s/it]\n",
      "Train:  42%|████▏     | 970/2326 [5:04:13<7:03:55, 18.76s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  42%|████▏     | 970/2326 [5:04:13<7:03:55, 18.76s/it]\n",
      "Train:  42%|████▏     | 970/2326 [5:04:13<7:03:55, 18.76s/it]\n",
      "Train:  42%|████▏     | 971/2326 [5:04:34<7:17:38, 19.38s/it]\n",
      "Train:  42%|████▏     | 972/2326 [5:04:53<7:17:06, 19.37s/it]\n",
      "Train:  42%|████▏     | 973/2326 [5:05:11<7:08:31, 19.00s/it]\n",
      "Train:  42%|████▏     | 974/2326 [5:05:30<7:02:54, 18.77s/it]\n",
      "Train:  42%|████▏     | 975/2326 [5:05:48<7:02:16, 18.75s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  42%|████▏     | 975/2326 [5:05:48<7:02:16, 18.75s/it]\n",
      "Train:  42%|████▏     | 975/2326 [5:05:48<7:02:16, 18.75s/it]\n",
      "Train:  42%|████▏     | 976/2326 [5:06:07<7:04:43, 18.88s/it]\n",
      "Train:  42%|████▏     | 977/2326 [5:06:26<6:59:31, 18.66s/it]\n",
      "Train:  42%|████▏     | 978/2326 [5:06:44<6:57:16, 18.57s/it]\n",
      "Train:  42%|████▏     | 979/2326 [5:07:02<6:55:13, 18.50s/it]\n",
      "Train:  42%|████▏     | 980/2326 [5:07:20<6:51:31, 18.34s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  42%|████▏     | 980/2326 [5:07:20<6:51:31, 18.34s/it]\n",
      "Train:  42%|████▏     | 980/2326 [5:07:20<6:51:31, 18.34s/it]\n",
      "Train:  42%|████▏     | 981/2326 [5:07:39<6:55:04, 18.52s/it]\n",
      "Train:  42%|████▏     | 982/2326 [5:07:59<7:02:46, 18.87s/it]\n",
      "Train:  42%|████▏     | 983/2326 [5:08:17<6:57:21, 18.65s/it]\n",
      "Train:  42%|████▏     | 984/2326 [5:08:38<7:10:27, 19.25s/it]\n",
      "Train:  42%|████▏     | 985/2326 [5:08:56<7:02:56, 18.92s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  42%|████▏     | 985/2326 [5:08:56<7:02:56, 18.92s/it]\n",
      "Train:  42%|████▏     | 985/2326 [5:08:56<7:02:56, 18.92s/it]\n",
      "Train:  42%|████▏     | 986/2326 [5:09:15<7:00:58, 18.85s/it]\n",
      "Train:  42%|████▏     | 987/2326 [5:09:33<6:56:23, 18.66s/it]\n",
      "Train:  42%|████▏     | 988/2326 [5:09:52<6:58:11, 18.75s/it]\n",
      "Train:  43%|████▎     | 989/2326 [5:10:11<7:03:55, 19.02s/it]\n",
      "Train:  43%|████▎     | 990/2326 [5:10:30<7:01:26, 18.93s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  43%|████▎     | 990/2326 [5:10:30<7:01:26, 18.93s/it]\n",
      "Train:  43%|████▎     | 990/2326 [5:10:30<7:01:26, 18.93s/it]\n",
      "Train:  43%|████▎     | 991/2326 [5:10:49<7:03:25, 19.03s/it]\n",
      "Train:  43%|████▎     | 992/2326 [5:11:07<6:56:37, 18.74s/it]\n",
      "Train:  43%|████▎     | 993/2326 [5:11:25<6:50:11, 18.46s/it]\n",
      "Train:  43%|████▎     | 994/2326 [5:11:44<6:50:54, 18.51s/it]\n",
      "Train:  43%|████▎     | 995/2326 [5:12:02<6:48:53, 18.43s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  43%|████▎     | 995/2326 [5:12:02<6:48:53, 18.43s/it]\n",
      "Train:  43%|████▎     | 995/2326 [5:12:02<6:48:53, 18.43s/it]\n",
      "Train:  43%|████▎     | 996/2326 [5:12:21<6:52:58, 18.63s/it]\n",
      "Train:  43%|████▎     | 997/2326 [5:12:40<6:53:56, 18.69s/it]\n",
      "Train:  43%|████▎     | 998/2326 [5:12:59<6:54:53, 18.74s/it]\n",
      "Train:  43%|████▎     | 999/2326 [5:13:18<6:53:37, 18.70s/it]\n",
      "Train:  43%|████▎     | 1000/2326 [5:13:36<6:49:57, 18.55s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  43%|████▎     | 1000/2326 [5:13:36<6:49:57, 18.55s/it]\n",
      "Train:  43%|████▎     | 1000/2326 [5:13:36<6:49:57, 18.55s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v10-20250927-234036/checkpoint-1000\n",
      "\n",
      "Train:  43%|████▎     | 1001/2326 [5:13:56<6:58:56, 18.97s/it]\n",
      "Train:  43%|████▎     | 1002/2326 [5:14:14<6:53:26, 18.74s/it]\n",
      "Train:  43%|████▎     | 1003/2326 [5:14:34<6:59:52, 19.04s/it]\n",
      "Train:  43%|████▎     | 1004/2326 [5:14:52<6:56:41, 18.91s/it]\n",
      "Train:  43%|████▎     | 1005/2326 [5:15:11<6:55:41, 18.88s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  43%|████▎     | 1005/2326 [5:15:11<6:55:41, 18.88s/it]\n",
      "Train:  43%|████▎     | 1005/2326 [5:15:11<6:55:41, 18.88s/it]\n",
      "Train:  43%|████▎     | 1006/2326 [5:15:31<7:03:18, 19.24s/it]\n",
      "Train:  43%|████▎     | 1007/2326 [5:15:50<7:00:21, 19.12s/it]\n",
      "Train:  43%|████▎     | 1008/2326 [5:16:09<6:56:57, 18.98s/it]\n",
      "Train:  43%|████▎     | 1009/2326 [5:16:27<6:55:48, 18.94s/it]\n",
      "Train:  43%|████▎     | 1010/2326 [5:16:46<6:55:00, 18.92s/it]\n",
      "                                                              \n",
      "{'loss': 1.87399998, 'token_acc': 0.59751948, 'grad_norm': 1.53132296, 'learning_rate': 7.397e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053218, 'epoch': 0.75, 'global_step/max_steps': '870/2326', 'percentage': '37.40%', 'elapsed_time': '4h 32m 27s', 'remaining_time': '7h 35m 58s'}\n",
      "{'loss': 1.85187588, 'token_acc': 0.60167162, 'grad_norm': 1.18821931, 'learning_rate': 7.365e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053218, 'epoch': 0.75, 'global_step/max_steps': '875/2326', 'percentage': '37.62%', 'elapsed_time': '4h 34m 1s', 'remaining_time': '7h 34m 24s'}\n",
      "{'loss': 1.94768753, 'token_acc': 0.58099114, 'grad_norm': 0.92818356, 'learning_rate': 7.334e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053203, 'epoch': 0.76, 'global_step/max_steps': '880/2326', 'percentage': '37.83%', 'elapsed_time': '4h 35m 40s', 'remaining_time': '7h 32m 58s'}\n",
      "{'loss': 1.7993103, 'token_acc': 0.61246069, 'grad_norm': 1.12500632, 'learning_rate': 7.303e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053201, 'epoch': 0.76, 'global_step/max_steps': '885/2326', 'percentage': '38.05%', 'elapsed_time': '4h 37m 14s', 'remaining_time': '7h 31m 25s'}\n",
      "{'loss': 1.8887989, 'token_acc': 0.59911697, 'grad_norm': 1.21115208, 'learning_rate': 7.271e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053203, 'epoch': 0.77, 'global_step/max_steps': '890/2326', 'percentage': '38.26%', 'elapsed_time': '4h 38m 48s', 'remaining_time': '7h 29m 50s'}\n",
      "{'loss': 1.97198181, 'token_acc': 0.57851632, 'grad_norm': 1.55544734, 'learning_rate': 7.239e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.05321, 'epoch': 0.77, 'global_step/max_steps': '895/2326', 'percentage': '38.48%', 'elapsed_time': '4h 40m 19s', 'remaining_time': '7h 28m 12s'}\n",
      "{'loss': 1.87420216, 'token_acc': 0.59863215, 'grad_norm': 1.28264642, 'learning_rate': 7.207e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053215, 'epoch': 0.77, 'global_step/max_steps': '900/2326', 'percentage': '38.69%', 'elapsed_time': '4h 41m 52s', 'remaining_time': '7h 26m 36s'}\n",
      "{'loss': 2.03843193, 'token_acc': 0.55728694, 'grad_norm': 1.32434785, 'learning_rate': 7.175e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053204, 'epoch': 0.78, 'global_step/max_steps': '905/2326', 'percentage': '38.91%', 'elapsed_time': '4h 43m 29s', 'remaining_time': '7h 25m 8s'}\n",
      "{'loss': 1.78149376, 'token_acc': 0.61591627, 'grad_norm': 0.95381409, 'learning_rate': 7.143e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053193, 'epoch': 0.78, 'global_step/max_steps': '910/2326', 'percentage': '39.12%', 'elapsed_time': '4h 45m 7s', 'remaining_time': '7h 23m 39s'}\n",
      "{'loss': 1.99242992, 'token_acc': 0.57743807, 'grad_norm': 1.14046574, 'learning_rate': 7.111e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053195, 'epoch': 0.79, 'global_step/max_steps': '915/2326', 'percentage': '39.34%', 'elapsed_time': '4h 46m 40s', 'remaining_time': '7h 22m 4s'}\n",
      "{'loss': 1.86521606, 'token_acc': 0.59995406, 'grad_norm': 1.3978802, 'learning_rate': 7.079e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053197, 'epoch': 0.79, 'global_step/max_steps': '920/2326', 'percentage': '39.55%', 'elapsed_time': '4h 48m 14s', 'remaining_time': '7h 20m 29s'}\n",
      "{'loss': 1.90503712, 'token_acc': 0.58568202, 'grad_norm': 1.00097036, 'learning_rate': 7.046e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053186, 'epoch': 0.8, 'global_step/max_steps': '925/2326', 'percentage': '39.77%', 'elapsed_time': '4h 49m 51s', 'remaining_time': '7h 19m 0s'}\n",
      "{'loss': 1.97072411, 'token_acc': 0.57562957, 'grad_norm': 1.43122196, 'learning_rate': 7.014e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053183, 'epoch': 0.8, 'global_step/max_steps': '930/2326', 'percentage': '39.98%', 'elapsed_time': '4h 51m 26s', 'remaining_time': '7h 17m 28s'}\n",
      "{'loss': 1.85802631, 'token_acc': 0.60376962, 'grad_norm': 1.40345955, 'learning_rate': 6.981e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053177, 'epoch': 0.8, 'global_step/max_steps': '935/2326', 'percentage': '40.20%', 'elapsed_time': '4h 53m 2s', 'remaining_time': '7h 15m 57s'}\n",
      "{'loss': 1.95709667, 'token_acc': 0.57985206, 'grad_norm': 1.14245832, 'learning_rate': 6.949e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053171, 'epoch': 0.81, 'global_step/max_steps': '940/2326', 'percentage': '40.41%', 'elapsed_time': '4h 54m 38s', 'remaining_time': '7h 14m 26s'}\n",
      "{'loss': 1.87804012, 'token_acc': 0.60274661, 'grad_norm': 1.23898351, 'learning_rate': 6.916e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053172, 'epoch': 0.81, 'global_step/max_steps': '945/2326', 'percentage': '40.63%', 'elapsed_time': '4h 56m 12s', 'remaining_time': '7h 12m 52s'}\n",
      "{'loss': 1.89069805, 'token_acc': 0.58880015, 'grad_norm': 1.1492753, 'learning_rate': 6.883e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053156, 'epoch': 0.82, 'global_step/max_steps': '950/2326', 'percentage': '40.84%', 'elapsed_time': '4h 57m 51s', 'remaining_time': '7h 11m 25s'}\n",
      "{'loss': 1.90358047, 'token_acc': 0.58365913, 'grad_norm': 1.01236987, 'learning_rate': 6.85e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053142, 'epoch': 0.82, 'global_step/max_steps': '955/2326', 'percentage': '41.06%', 'elapsed_time': '4h 59m 30s', 'remaining_time': '7h 9m 58s'}\n",
      "{'loss': 1.92379684, 'token_acc': 0.58818659, 'grad_norm': 1.36406577, 'learning_rate': 6.817e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053141, 'epoch': 0.83, 'global_step/max_steps': '960/2326', 'percentage': '41.27%', 'elapsed_time': '5h 1m 5s', 'remaining_time': '7h 8m 25s'}\n",
      "{'loss': 1.90747223, 'token_acc': 0.59120476, 'grad_norm': 1.41247094, 'learning_rate': 6.784e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053138, 'epoch': 0.83, 'global_step/max_steps': '965/2326', 'percentage': '41.49%', 'elapsed_time': '5h 2m 39s', 'remaining_time': '7h 6m 52s'}\n",
      "{'loss': 1.73633118, 'token_acc': 0.62221081, 'grad_norm': 1.38714135, 'learning_rate': 6.751e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053139, 'epoch': 0.83, 'global_step/max_steps': '970/2326', 'percentage': '41.70%', 'elapsed_time': '5h 4m 13s', 'remaining_time': '7h 5m 17s'}\n",
      "{'loss': 1.91002426, 'token_acc': 0.58430052, 'grad_norm': 1.16336358, 'learning_rate': 6.717e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053136, 'epoch': 0.84, 'global_step/max_steps': '975/2326', 'percentage': '41.92%', 'elapsed_time': '5h 5m 48s', 'remaining_time': '7h 3m 44s'}\n",
      "{'loss': 1.86401615, 'token_acc': 0.59805389, 'grad_norm': 1.56992102, 'learning_rate': 6.684e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053142, 'epoch': 0.84, 'global_step/max_steps': '980/2326', 'percentage': '42.13%', 'elapsed_time': '5h 7m 20s', 'remaining_time': '7h 2m 7s'}\n",
      "{'loss': 2.02085705, 'token_acc': 0.5646711, 'grad_norm': 1.52020347, 'learning_rate': 6.65e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053138, 'epoch': 0.85, 'global_step/max_steps': '985/2326', 'percentage': '42.35%', 'elapsed_time': '5h 8m 56s', 'remaining_time': '7h 0m 35s'}\n",
      "{'loss': 1.9327219, 'token_acc': 0.58681528, 'grad_norm': 1.30425668, 'learning_rate': 6.617e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053138, 'epoch': 0.85, 'global_step/max_steps': '990/2326', 'percentage': '42.56%', 'elapsed_time': '5h 10m 30s', 'remaining_time': '6h 59m 1s'}\n",
      "{'loss': 1.97222939, 'token_acc': 0.58113363, 'grad_norm': 1.19837713, 'learning_rate': 6.583e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053143, 'epoch': 0.86, 'global_step/max_steps': '995/2326', 'percentage': '42.78%', 'elapsed_time': '5h 12m 2s', 'remaining_time': '6h 57m 25s'}\n",
      "{'loss': 1.73366547, 'token_acc': 0.62373332, 'grad_norm': 1.31780565, 'learning_rate': 6.549e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053145, 'epoch': 0.86, 'global_step/max_steps': '1000/2326', 'percentage': '42.99%', 'elapsed_time': '5h 13m 36s', 'remaining_time': '6h 55m 50s'}\n",
      "{'loss': 1.86941528, 'token_acc': 0.59704641, 'grad_norm': 1.42516053, 'learning_rate': 6.515e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053141, 'epoch': 0.86, 'global_step/max_steps': '1005/2326', 'percentage': '43.21%', 'elapsed_time': '5h 15m 11s', 'remaining_time': '6h 54m 17s'}\n",
      "{'loss': 1.96914558, 'token_acc': 0.57407115, 'grad_norm': 1.54513633, 'learning_rate': 6.481e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053138, 'epoch': 0.87, 'global_step/max_steps': '1010/2326', 'percentage': '43.42%', 'elapsed_time': '5h 16m 46s', 'remaining_time': '6h 52m 45s'}\n",
      "Train:  43%|████▎     | 1010/2326 [5:16:46<6:55:00, 18.92s/it]\n",
      "Train:  43%|████▎     | 1010/2326 [5:16:46<6:55:00, 18.92s/it]\n",
      "Train:  43%|████▎     | 1011/2326 [5:17:07<7:03:10, 19.31s/it]\n",
      "Train:  44%|████▎     | 1012/2326 [5:17:25<6:57:26, 19.06s/it]\n",
      "Train:  44%|████▎     | 1013/2326 [5:17:44<6:54:17, 18.93s/it]\n",
      "Train:  44%|████▎     | 1014/2326 [5:18:01<6:46:20, 18.58s/it]\n",
      "Train:  44%|████▎     | 1015/2326 [5:18:20<6:45:39, 18.57s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  44%|████▎     | 1015/2326 [5:18:20<6:45:39, 18.57s/it]\n",
      "Train:  44%|████▎     | 1015/2326 [5:18:20<6:45:39, 18.57s/it]\n",
      "Train:  44%|████▎     | 1016/2326 [5:18:39<6:45:26, 18.57s/it]\n",
      "Train:  44%|████▎     | 1017/2326 [5:18:57<6:47:22, 18.67s/it]\n",
      "Train:  44%|████▍     | 1018/2326 [5:19:17<6:52:02, 18.90s/it]\n",
      "Train:  44%|████▍     | 1019/2326 [5:19:36<6:50:50, 18.86s/it]\n",
      "Train:  44%|████▍     | 1020/2326 [5:19:55<6:52:54, 18.97s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  44%|████▍     | 1020/2326 [5:19:55<6:52:54, 18.97s/it]\n",
      "Train:  44%|████▍     | 1020/2326 [5:19:55<6:52:54, 18.97s/it]\n",
      "Train:  44%|████▍     | 1021/2326 [5:20:17<7:14:25, 19.97s/it]\n",
      "Train:  44%|████▍     | 1022/2326 [5:20:36<7:05:05, 19.56s/it]\n",
      "Train:  44%|████▍     | 1023/2326 [5:20:55<7:00:54, 19.38s/it]\n",
      "Train:  44%|████▍     | 1024/2326 [5:21:13<6:55:35, 19.15s/it]\n",
      "Train:  44%|████▍     | 1025/2326 [5:21:33<6:57:10, 19.24s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  44%|████▍     | 1025/2326 [5:21:33<6:57:10, 19.24s/it]\n",
      "Train:  44%|████▍     | 1025/2326 [5:21:33<6:57:10, 19.24s/it]\n",
      "Train:  44%|████▍     | 1026/2326 [5:21:51<6:50:08, 18.93s/it]\n",
      "Train:  44%|████▍     | 1027/2326 [5:22:09<6:45:18, 18.72s/it]\n",
      "Train:  44%|████▍     | 1028/2326 [5:22:28<6:47:37, 18.84s/it]\n",
      "Train:  44%|████▍     | 1029/2326 [5:22:47<6:46:14, 18.79s/it]\n",
      "Train:  44%|████▍     | 1030/2326 [5:23:05<6:42:57, 18.66s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  44%|████▍     | 1030/2326 [5:23:05<6:42:57, 18.66s/it]\n",
      "Train:  44%|████▍     | 1030/2326 [5:23:05<6:42:57, 18.66s/it]\n",
      "Train:  44%|████▍     | 1031/2326 [5:23:24<6:41:36, 18.61s/it]\n",
      "Train:  44%|████▍     | 1032/2326 [5:23:42<6:40:29, 18.57s/it]\n",
      "Train:  44%|████▍     | 1033/2326 [5:24:01<6:40:43, 18.59s/it]\n",
      "Train:  44%|████▍     | 1034/2326 [5:24:19<6:38:13, 18.49s/it]\n",
      "Train:  44%|████▍     | 1035/2326 [5:24:38<6:39:48, 18.58s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  44%|████▍     | 1035/2326 [5:24:38<6:39:48, 18.58s/it]\n",
      "Train:  44%|████▍     | 1035/2326 [5:24:38<6:39:48, 18.58s/it]\n",
      "Train:  45%|████▍     | 1036/2326 [5:24:56<6:37:09, 18.47s/it]\n",
      "Train:  45%|████▍     | 1037/2326 [5:25:16<6:46:21, 18.91s/it]\n",
      "Train:  45%|████▍     | 1038/2326 [5:25:35<6:42:47, 18.76s/it]\n",
      "Train:  45%|████▍     | 1039/2326 [5:25:54<6:43:44, 18.82s/it]\n",
      "Train:  45%|████▍     | 1040/2326 [5:26:12<6:37:35, 18.55s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  45%|████▍     | 1040/2326 [5:26:12<6:37:35, 18.55s/it]\n",
      "Train:  45%|████▍     | 1040/2326 [5:26:12<6:37:35, 18.55s/it]\n",
      "Train:  45%|████▍     | 1041/2326 [5:26:31<6:41:49, 18.76s/it]\n",
      "Train:  45%|████▍     | 1042/2326 [5:26:50<6:46:16, 18.98s/it]\n",
      "Train:  45%|████▍     | 1043/2326 [5:27:09<6:41:44, 18.79s/it]\n",
      "Train:  45%|████▍     | 1044/2326 [5:27:27<6:37:48, 18.62s/it]\n",
      "Train:  45%|████▍     | 1045/2326 [5:27:46<6:39:19, 18.70s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  45%|████▍     | 1045/2326 [5:27:46<6:39:19, 18.70s/it]\n",
      "Train:  45%|████▍     | 1045/2326 [5:27:46<6:39:19, 18.70s/it]\n",
      "Train:  45%|████▍     | 1046/2326 [5:28:04<6:38:53, 18.70s/it]\n",
      "Train:  45%|████▌     | 1047/2326 [5:28:22<6:34:31, 18.51s/it]\n",
      "Train:  45%|████▌     | 1048/2326 [5:28:41<6:32:47, 18.44s/it]\n",
      "Train:  45%|████▌     | 1049/2326 [5:29:01<6:43:34, 18.96s/it]\n",
      "Train:  45%|████▌     | 1050/2326 [5:29:19<6:37:55, 18.71s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  45%|████▌     | 1050/2326 [5:29:19<6:37:55, 18.71s/it]\n",
      "Train:  45%|████▌     | 1050/2326 [5:29:19<6:37:55, 18.71s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v10-20250927-234036/checkpoint-1050\n",
      "\n",
      "Train:  45%|████▌     | 1051/2326 [5:29:39<6:43:20, 18.98s/it]\n",
      "Train:  45%|████▌     | 1052/2326 [5:29:58<6:44:59, 19.07s/it]\n",
      "Train:  45%|████▌     | 1053/2326 [5:30:17<6:42:45, 18.98s/it]\n",
      "Train:  45%|████▌     | 1054/2326 [5:30:35<6:37:03, 18.73s/it]\n",
      "Train:  45%|████▌     | 1055/2326 [5:30:53<6:35:17, 18.66s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  45%|████▌     | 1055/2326 [5:30:53<6:35:17, 18.66s/it]\n",
      "Train:  45%|████▌     | 1055/2326 [5:30:53<6:35:17, 18.66s/it]\n",
      "Train:  45%|████▌     | 1056/2326 [5:31:13<6:42:06, 19.00s/it]\n",
      "Train:  45%|████▌     | 1057/2326 [5:31:32<6:41:02, 18.96s/it]\n",
      "Train:  45%|████▌     | 1058/2326 [5:31:50<6:35:40, 18.72s/it]\n",
      "Train:  46%|████▌     | 1059/2326 [5:32:09<6:32:49, 18.60s/it]\n",
      "Train:  46%|████▌     | 1060/2326 [5:32:27<6:31:01, 18.53s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  46%|████▌     | 1060/2326 [5:32:27<6:31:01, 18.53s/it]\n",
      "Train:  46%|████▌     | 1060/2326 [5:32:27<6:31:01, 18.53s/it]\n",
      "Train:  46%|████▌     | 1061/2326 [5:32:46<6:35:09, 18.74s/it]\n",
      "Train:  46%|████▌     | 1062/2326 [5:33:04<6:27:40, 18.40s/it]\n",
      "Train:  46%|████▌     | 1063/2326 [5:33:23<6:30:28, 18.55s/it]\n",
      "Train:  46%|████▌     | 1064/2326 [5:33:41<6:28:52, 18.49s/it]\n",
      "Train:  46%|████▌     | 1065/2326 [5:33:59<6:24:12, 18.28s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  46%|████▌     | 1065/2326 [5:33:59<6:24:12, 18.28s/it]\n",
      "Train:  46%|████▌     | 1065/2326 [5:33:59<6:24:12, 18.28s/it]\n",
      "Train:  46%|████▌     | 1066/2326 [5:34:17<6:23:54, 18.28s/it]\n",
      "Train:  46%|████▌     | 1067/2326 [5:34:36<6:29:20, 18.55s/it]\n",
      "Train:  46%|████▌     | 1068/2326 [5:34:56<6:33:32, 18.77s/it]\n",
      "Train:  46%|████▌     | 1069/2326 [5:35:16<6:41:04, 19.14s/it]\n",
      "Train:  46%|████▌     | 1070/2326 [5:35:33<6:33:03, 18.78s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  46%|████▌     | 1070/2326 [5:35:34<6:33:03, 18.78s/it]\n",
      "Train:  46%|████▌     | 1070/2326 [5:35:34<6:33:03, 18.78s/it]\n",
      "Train:  46%|████▌     | 1071/2326 [5:35:52<6:28:45, 18.59s/it]\n",
      "Train:  46%|████▌     | 1072/2326 [5:36:11<6:32:50, 18.80s/it]\n",
      "Train:  46%|████▌     | 1073/2326 [5:36:29<6:30:26, 18.70s/it]\n",
      "Train:  46%|████▌     | 1074/2326 [5:36:49<6:35:03, 18.93s/it]\n",
      "Train:  46%|████▌     | 1075/2326 [5:37:08<6:37:34, 19.07s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  46%|████▌     | 1075/2326 [5:37:08<6:37:34, 19.07s/it]\n",
      "Train:  46%|████▌     | 1075/2326 [5:37:08<6:37:34, 19.07s/it]\n",
      "Train:  46%|████▋     | 1076/2326 [5:37:27<6:32:48, 18.85s/it]\n",
      "Train:  46%|████▋     | 1077/2326 [5:37:47<6:43:41, 19.39s/it]\n",
      "Train:  46%|████▋     | 1078/2326 [5:38:06<6:36:38, 19.07s/it]\n",
      "Train:  46%|████▋     | 1079/2326 [5:38:25<6:37:32, 19.13s/it]\n",
      "Train:  46%|████▋     | 1080/2326 [5:38:44<6:36:19, 19.08s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  46%|████▋     | 1080/2326 [5:38:44<6:36:19, 19.08s/it]\n",
      "Train:  46%|████▋     | 1080/2326 [5:38:44<6:36:19, 19.08s/it]\n",
      "Train:  46%|████▋     | 1081/2326 [5:39:02<6:33:38, 18.97s/it]\n",
      "Train:  47%|████▋     | 1082/2326 [5:39:21<6:30:03, 18.81s/it]\n",
      "Train:  47%|████▋     | 1083/2326 [5:39:40<6:34:01, 19.02s/it]\n",
      "Train:  47%|████▋     | 1084/2326 [5:39:59<6:30:26, 18.86s/it]\n",
      "Train:  47%|████▋     | 1085/2326 [5:40:17<6:27:48, 18.75s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  47%|████▋     | 1085/2326 [5:40:17<6:27:48, 18.75s/it]\n",
      "Train:  47%|████▋     | 1085/2326 [5:40:17<6:27:48, 18.75s/it]\n",
      "Train:  47%|████▋     | 1086/2326 [5:40:35<6:21:36, 18.47s/it]\n",
      "Train:  47%|████▋     | 1087/2326 [5:40:54<6:23:30, 18.57s/it]\n",
      "Train:  47%|████▋     | 1088/2326 [5:41:15<6:36:43, 19.23s/it]\n",
      "Train:  47%|████▋     | 1089/2326 [5:41:33<6:32:01, 19.01s/it]\n",
      "Train:  47%|████▋     | 1090/2326 [5:41:52<6:32:36, 19.06s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  47%|████▋     | 1090/2326 [5:41:53<6:32:36, 19.06s/it]\n",
      "Train:  47%|████▋     | 1090/2326 [5:41:53<6:32:36, 19.06s/it]\n",
      "Train:  47%|████▋     | 1091/2326 [5:42:11<6:32:06, 19.05s/it]\n",
      "Train:  47%|████▋     | 1092/2326 [5:42:33<6:46:31, 19.77s/it]\n",
      "Train:  47%|████▋     | 1093/2326 [5:42:52<6:40:46, 19.50s/it]\n",
      "Train:  47%|████▋     | 1094/2326 [5:43:10<6:32:50, 19.13s/it]\n",
      "Train:  47%|████▋     | 1095/2326 [5:43:28<6:25:02, 18.77s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  47%|████▋     | 1095/2326 [5:43:28<6:25:02, 18.77s/it]\n",
      "Train:  47%|████▋     | 1095/2326 [5:43:28<6:25:02, 18.77s/it]\n",
      "Train:  47%|████▋     | 1096/2326 [5:43:47<6:27:35, 18.91s/it]\n",
      "Train:  47%|████▋     | 1097/2326 [5:44:06<6:25:26, 18.82s/it]\n",
      "Train:  47%|████▋     | 1098/2326 [5:44:25<6:25:14, 18.82s/it]\n",
      "Train:  47%|████▋     | 1099/2326 [5:44:43<6:22:04, 18.68s/it]\n",
      "Train:  47%|████▋     | 1100/2326 [5:45:02<6:25:16, 18.85s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  47%|████▋     | 1100/2326 [5:45:02<6:25:16, 18.85s/it]\n",
      "Train:  47%|████▋     | 1100/2326 [5:45:02<6:25:16, 18.85s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v10-20250927-234036/checkpoint-1100\n",
      "\n",
      "Train:  47%|████▋     | 1101/2326 [5:45:22<6:32:31, 19.23s/it]\n",
      "Train:  47%|████▋     | 1102/2326 [5:45:42<6:33:23, 19.28s/it]\n",
      "Train:  47%|████▋     | 1103/2326 [5:46:01<6:33:27, 19.30s/it]\n",
      "Train:  47%|████▋     | 1104/2326 [5:46:20<6:29:38, 19.13s/it]\n",
      "Train:  48%|████▊     | 1105/2326 [5:46:39<6:29:16, 19.13s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  48%|████▊     | 1105/2326 [5:46:39<6:29:16, 19.13s/it]\n",
      "Train:  48%|████▊     | 1105/2326 [5:46:39<6:29:16, 19.13s/it]\n",
      "Train:  48%|████▊     | 1106/2326 [5:46:57<6:23:39, 18.87s/it]\n",
      "Train:  48%|████▊     | 1107/2326 [5:47:15<6:17:25, 18.58s/it]\n",
      "Train:  48%|████▊     | 1108/2326 [5:47:33<6:13:21, 18.39s/it]\n",
      "Train:  48%|████▊     | 1109/2326 [5:47:51<6:09:23, 18.21s/it]\n",
      "Train:  48%|████▊     | 1110/2326 [5:48:11<6:19:00, 18.70s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  48%|████▊     | 1110/2326 [5:48:11<6:19:00, 18.70s/it]\n",
      "Train:  48%|████▊     | 1110/2326 [5:48:11<6:19:00, 18.70s/it]\n",
      "Train:  48%|████▊     | 1111/2326 [5:48:31<6:25:19, 19.03s/it]\n",
      "Train:  48%|████▊     | 1112/2326 [5:48:50<6:27:23, 19.15s/it]\n",
      "Train:  48%|████▊     | 1113/2326 [5:49:08<6:22:29, 18.92s/it]\n",
      "Train:  48%|████▊     | 1114/2326 [5:49:30<6:36:24, 19.62s/it]\n",
      "Train:  48%|████▊     | 1115/2326 [5:49:47<6:23:38, 19.01s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  48%|████▊     | 1115/2326 [5:49:47<6:23:38, 19.01s/it]\n",
      "Train:  48%|████▊     | 1115/2326 [5:49:47<6:23:38, 19.01s/it]\n",
      "Train:  48%|████▊     | 1116/2326 [5:50:07<6:27:49, 19.23s/it]\n",
      "Train:  48%|████▊     | 1117/2326 [5:50:25<6:21:07, 18.91s/it]\n",
      "Train:  48%|████▊     | 1118/2326 [5:50:43<6:15:25, 18.65s/it]\n",
      "Train:  48%|████▊     | 1119/2326 [5:51:02<6:19:01, 18.84s/it]\n",
      "Train:  48%|████▊     | 1120/2326 [5:51:22<6:20:46, 18.94s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  48%|████▊     | 1120/2326 [5:51:22<6:20:46, 18.94s/it]\n",
      "Train:  48%|████▊     | 1120/2326 [5:51:22<6:20:46, 18.94s/it]\n",
      "Train:  48%|████▊     | 1121/2326 [5:51:40<6:17:56, 18.82s/it]\n",
      "Train:  48%|████▊     | 1122/2326 [5:51:59<6:15:14, 18.70s/it]\n",
      "Train:  48%|████▊     | 1123/2326 [5:52:16<6:09:01, 18.41s/it]\n",
      "Train:  48%|████▊     | 1124/2326 [5:52:35<6:10:31, 18.50s/it]\n",
      "Train:  48%|████▊     | 1125/2326 [5:52:54<6:11:24, 18.55s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  48%|████▊     | 1125/2326 [5:52:54<6:11:24, 18.55s/it]\n",
      "Train:  48%|████▊     | 1125/2326 [5:52:54<6:11:24, 18.55s/it]\n",
      "Train:  48%|████▊     | 1126/2326 [5:53:13<6:13:16, 18.66s/it]\n",
      "Train:  48%|████▊     | 1127/2326 [5:53:32<6:16:13, 18.83s/it]\n",
      "Train:  48%|████▊     | 1128/2326 [5:53:51<6:20:28, 19.06s/it]\n",
      "Train:  49%|████▊     | 1129/2326 [5:54:10<6:19:38, 19.03s/it]\n",
      "Train:  49%|████▊     | 1130/2326 [5:54:30<6:24:28, 19.29s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  49%|████▊     | 1130/2326 [5:54:30<6:24:28, 19.29s/it]\n",
      "Train:  49%|████▊     | 1130/2326 [5:54:30<6:24:28, 19.29s/it]\n",
      "Train:  49%|████▊     | 1131/2326 [5:54:49<6:20:23, 19.10s/it]\n",
      "Train:  49%|████▊     | 1132/2326 [5:55:07<6:14:46, 18.83s/it]\n",
      "Train:  49%|████▊     | 1133/2326 [5:55:25<6:10:08, 18.62s/it]\n",
      "Train:  49%|████▉     | 1134/2326 [5:55:44<6:12:42, 18.76s/it]\n",
      "Train:  49%|████▉     | 1135/2326 [5:56:04<6:14:57, 18.89s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  49%|████▉     | 1135/2326 [5:56:04<6:14:57, 18.89s/it]\n",
      "Train:  49%|████▉     | 1135/2326 [5:56:04<6:14:57, 18.89s/it]\n",
      "Train:  49%|████▉     | 1136/2326 [5:56:22<6:11:55, 18.75s/it]\n",
      "Train:  49%|████▉     | 1137/2326 [5:56:41<6:11:44, 18.76s/it]\n",
      "Train:  49%|████▉     | 1138/2326 [5:56:59<6:05:41, 18.47s/it]\n",
      "Train:  49%|████▉     | 1139/2326 [5:57:17<6:04:13, 18.41s/it]\n",
      "Train:  49%|████▉     | 1140/2326 [5:57:35<6:03:58, 18.41s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  49%|████▉     | 1140/2326 [5:57:35<6:03:58, 18.41s/it]\n",
      "Train:  49%|████▉     | 1140/2326 [5:57:35<6:03:58, 18.41s/it]\n",
      "Train:  49%|████▉     | 1141/2326 [5:57:53<6:01:19, 18.30s/it]\n",
      "Train:  49%|████▉     | 1142/2326 [5:58:12<6:02:12, 18.36s/it]\n",
      "Train:  49%|████▉     | 1143/2326 [5:58:29<5:58:19, 18.17s/it]\n",
      "Train:  49%|████▉     | 1144/2326 [5:58:49<6:05:42, 18.56s/it]\n",
      "Train:  49%|████▉     | 1145/2326 [5:59:08<6:08:56, 18.74s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  49%|████▉     | 1145/2326 [5:59:08<6:08:56, 18.74s/it]\n",
      "Train:  49%|████▉     | 1145/2326 [5:59:08<6:08:56, 18.74s/it]\n",
      "Train:  49%|████▉     | 1146/2326 [5:59:26<6:06:23, 18.63s/it]\n",
      "Train:  49%|████▉     | 1147/2326 [5:59:46<6:10:05, 18.83s/it]\n",
      "Train:  49%|████▉     | 1148/2326 [6:00:05<6:08:59, 18.79s/it]\n",
      "Train:  49%|████▉     | 1149/2326 [6:00:23<6:06:19, 18.67s/it]\n",
      "Train:  49%|████▉     | 1150/2326 [6:00:42<6:06:01, 18.67s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  49%|████▉     | 1150/2326 [6:00:42<6:06:01, 18.67s/it]\n",
      "Train:  49%|████▉     | 1150/2326 [6:00:42<6:06:01, 18.67s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v10-20250927-234036/checkpoint-1150\n",
      "\n",
      "Train:  49%|████▉     | 1151/2326 [6:01:01<6:11:52, 18.99s/it]\n",
      "Train:  50%|████▉     | 1152/2326 [6:01:20<6:10:19, 18.93s/it]\n",
      "Train:  50%|████▉     | 1153/2326 [6:01:39<6:09:32, 18.90s/it]\n",
      "Train:  50%|████▉     | 1154/2326 [6:01:57<6:06:44, 18.78s/it]\n",
      "Train:  50%|████▉     | 1155/2326 [6:02:15<5:59:48, 18.44s/it]\n",
      "                                                              \n",
      "{'loss': 1.92751408, 'token_acc': 0.582469, 'grad_norm': 1.1173166, 'learning_rate': 6.447e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053139, 'epoch': 0.87, 'global_step/max_steps': '1015/2326', 'percentage': '43.64%', 'elapsed_time': '5h 18m 20s', 'remaining_time': '6h 51m 10s'}\n",
      "{'loss': 1.8401823, 'token_acc': 0.60379727, 'grad_norm': 1.1478188, 'learning_rate': 6.413e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053137, 'epoch': 0.88, 'global_step/max_steps': '1020/2326', 'percentage': '43.85%', 'elapsed_time': '5h 19m 55s', 'remaining_time': '6h 49m 37s'}\n",
      "{'loss': 1.77037868, 'token_acc': 0.61414171, 'grad_norm': 1.28766346, 'learning_rate': 6.379e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053126, 'epoch': 0.88, 'global_step/max_steps': '1025/2326', 'percentage': '44.07%', 'elapsed_time': '5h 21m 33s', 'remaining_time': '6h 48m 8s'}\n",
      "{'loss': 1.85213223, 'token_acc': 0.60519103, 'grad_norm': 1.4340415, 'learning_rate': 6.345e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053131, 'epoch': 0.89, 'global_step/max_steps': '1030/2326', 'percentage': '44.28%', 'elapsed_time': '5h 23m 5s', 'remaining_time': '6h 46m 32s'}\n",
      "{'loss': 1.87617283, 'token_acc': 0.59833997, 'grad_norm': 1.36343491, 'learning_rate': 6.311e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053135, 'epoch': 0.89, 'global_step/max_steps': '1035/2326', 'percentage': '44.50%', 'elapsed_time': '5h 24m 38s', 'remaining_time': '6h 44m 56s'}\n",
      "{'loss': 1.97364254, 'token_acc': 0.57598638, 'grad_norm': 1.70870852, 'learning_rate': 6.276e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053136, 'epoch': 0.89, 'global_step/max_steps': '1040/2326', 'percentage': '44.71%', 'elapsed_time': '5h 26m 12s', 'remaining_time': '6h 43m 21s'}\n",
      "{'loss': 1.92974396, 'token_acc': 0.58516066, 'grad_norm': 1.3300817, 'learning_rate': 6.242e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053136, 'epoch': 0.9, 'global_step/max_steps': '1045/2326', 'percentage': '44.93%', 'elapsed_time': '5h 27m 46s', 'remaining_time': '6h 41m 47s'}\n",
      "{'loss': 1.98876686, 'token_acc': 0.57410443, 'grad_norm': 1.44962955, 'learning_rate': 6.207e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053138, 'epoch': 0.9, 'global_step/max_steps': '1050/2326', 'percentage': '45.14%', 'elapsed_time': '5h 29m 19s', 'remaining_time': '6h 40m 12s'}\n",
      "{'loss': 1.79756279, 'token_acc': 0.61237731, 'grad_norm': 1.34564734, 'learning_rate': 6.173e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053138, 'epoch': 0.91, 'global_step/max_steps': '1055/2326', 'percentage': '45.36%', 'elapsed_time': '5h 30m 53s', 'remaining_time': '6h 38m 38s'}\n",
      "{'loss': 1.85588436, 'token_acc': 0.60489551, 'grad_norm': 1.45434499, 'learning_rate': 6.138e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053139, 'epoch': 0.91, 'global_step/max_steps': '1060/2326', 'percentage': '45.57%', 'elapsed_time': '5h 32m 27s', 'remaining_time': '6h 37m 4s'}\n",
      "{'loss': 1.90626259, 'token_acc': 0.59083373, 'grad_norm': 1.36020899, 'learning_rate': 6.104e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053145, 'epoch': 0.92, 'global_step/max_steps': '1065/2326', 'percentage': '45.79%', 'elapsed_time': '5h 33m 59s', 'remaining_time': '6h 35m 27s'}\n",
      "{'loss': 1.80360432, 'token_acc': 0.61443332, 'grad_norm': 1.53371024, 'learning_rate': 6.069e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053143, 'epoch': 0.92, 'global_step/max_steps': '1070/2326', 'percentage': '46.00%', 'elapsed_time': '5h 35m 33s', 'remaining_time': '6h 33m 53s'}\n",
      "{'loss': 1.85010567, 'token_acc': 0.60351181, 'grad_norm': 1.27452374, 'learning_rate': 6.034e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053142, 'epoch': 0.93, 'global_step/max_steps': '1075/2326', 'percentage': '46.22%', 'elapsed_time': '5h 37m 8s', 'remaining_time': '6h 32m 20s'}\n",
      "{'loss': 1.97635231, 'token_acc': 0.57000105, 'grad_norm': 1.37452126, 'learning_rate': 5.999e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053138, 'epoch': 0.93, 'global_step/max_steps': '1080/2326', 'percentage': '46.43%', 'elapsed_time': '5h 38m 44s', 'remaining_time': '6h 30m 48s'}\n",
      "{'loss': 1.82196217, 'token_acc': 0.60497988, 'grad_norm': 1.50268626, 'learning_rate': 5.965e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053139, 'epoch': 0.93, 'global_step/max_steps': '1085/2326', 'percentage': '46.65%', 'elapsed_time': '5h 40m 17s', 'remaining_time': '6h 29m 13s'}\n",
      "{'loss': 1.81558533, 'token_acc': 0.60759142, 'grad_norm': 1.43481696, 'learning_rate': 5.93e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053136, 'epoch': 0.94, 'global_step/max_steps': '1090/2326', 'percentage': '46.86%', 'elapsed_time': '5h 41m 53s', 'remaining_time': '6h 27m 40s'}\n",
      "{'loss': 1.83544235, 'token_acc': 0.60647215, 'grad_norm': 1.5846833, 'learning_rate': 5.895e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053133, 'epoch': 0.94, 'global_step/max_steps': '1095/2326', 'percentage': '47.08%', 'elapsed_time': '5h 43m 28s', 'remaining_time': '6h 26m 8s'}\n",
      "{'loss': 1.90832939, 'token_acc': 0.58892778, 'grad_norm': 1.33447981, 'learning_rate': 5.86e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053132, 'epoch': 0.95, 'global_step/max_steps': '1100/2326', 'percentage': '47.29%', 'elapsed_time': '5h 45m 2s', 'remaining_time': '6h 24m 34s'}\n",
      "{'loss': 1.93934479, 'token_acc': 0.58439564, 'grad_norm': 1.30337715, 'learning_rate': 5.825e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053126, 'epoch': 0.95, 'global_step/max_steps': '1105/2326', 'percentage': '47.51%', 'elapsed_time': '5h 46m 39s', 'remaining_time': '6h 23m 3s'}\n",
      "{'loss': 1.8626749, 'token_acc': 0.59737597, 'grad_norm': 1.23717427, 'learning_rate': 5.79e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053132, 'epoch': 0.96, 'global_step/max_steps': '1110/2326', 'percentage': '47.72%', 'elapsed_time': '5h 48m 11s', 'remaining_time': '6h 21m 26s'}\n",
      "{'loss': 1.80192127, 'token_acc': 0.61109349, 'grad_norm': 1.55301738, 'learning_rate': 5.754e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053126, 'epoch': 0.96, 'global_step/max_steps': '1115/2326', 'percentage': '47.94%', 'elapsed_time': '5h 49m 47s', 'remaining_time': '6h 19m 54s'}\n",
      "{'loss': 1.81374683, 'token_acc': 0.61293285, 'grad_norm': 1.46886182, 'learning_rate': 5.719e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053125, 'epoch': 0.96, 'global_step/max_steps': '1120/2326', 'percentage': '48.15%', 'elapsed_time': '5h 51m 22s', 'remaining_time': '6h 18m 21s'}\n",
      "{'loss': 1.84960537, 'token_acc': 0.60282694, 'grad_norm': 1.56186986, 'learning_rate': 5.684e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.05313, 'epoch': 0.97, 'global_step/max_steps': '1125/2326', 'percentage': '48.37%', 'elapsed_time': '5h 52m 54s', 'remaining_time': '6h 16m 44s'}\n",
      "{'loss': 1.81336079, 'token_acc': 0.60793554, 'grad_norm': 1.18633032, 'learning_rate': 5.649e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053124, 'epoch': 0.97, 'global_step/max_steps': '1130/2326', 'percentage': '48.58%', 'elapsed_time': '5h 54m 30s', 'remaining_time': '6h 15m 13s'}\n",
      "{'loss': 1.84204025, 'token_acc': 0.60003429, 'grad_norm': 1.44883013, 'learning_rate': 5.614e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053126, 'epoch': 0.98, 'global_step/max_steps': '1135/2326', 'percentage': '48.80%', 'elapsed_time': '5h 56m 4s', 'remaining_time': '6h 13m 38s'}\n",
      "{'loss': 1.83686752, 'token_acc': 0.60647671, 'grad_norm': 1.43629026, 'learning_rate': 5.578e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053132, 'epoch': 0.98, 'global_step/max_steps': '1140/2326', 'percentage': '49.01%', 'elapsed_time': '5h 57m 35s', 'remaining_time': '6h 12m 1s'}\n",
      "{'loss': 2.0154232, 'token_acc': 0.57155035, 'grad_norm': 1.18992436, 'learning_rate': 5.543e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053135, 'epoch': 0.99, 'global_step/max_steps': '1145/2326', 'percentage': '49.23%', 'elapsed_time': '5h 59m 8s', 'remaining_time': '6h 10m 26s'}\n",
      "{'loss': 1.89327564, 'token_acc': 0.59440404, 'grad_norm': 1.27107441, 'learning_rate': 5.508e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053137, 'epoch': 0.99, 'global_step/max_steps': '1150/2326', 'percentage': '49.44%', 'elapsed_time': '6h 0m 42s', 'remaining_time': '6h 8m 51s'}\n",
      "{'loss': 1.9671236, 'token_acc': 0.58091114, 'grad_norm': 1.51942587, 'learning_rate': 5.472e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053138, 'epoch': 0.99, 'global_step/max_steps': '1155/2326', 'percentage': '49.66%', 'elapsed_time': '6h 2m 15s', 'remaining_time': '6h 7m 16s'}\n",
      "Train:  50%|████▉     | 1155/2326 [6:02:15<5:59:48, 18.44s/it]\n",
      "Train:  50%|████▉     | 1155/2326 [6:02:15<5:59:48, 18.44s/it]\n",
      "Train:  50%|████▉     | 1156/2326 [6:02:34<6:03:50, 18.66s/it]\n",
      "Train:  50%|████▉     | 1157/2326 [6:02:52<6:00:01, 18.48s/it]\n",
      "Train:  50%|████▉     | 1158/2326 [6:03:10<5:57:00, 18.34s/it]\n",
      "Train:  50%|████▉     | 1159/2326 [6:03:29<5:56:12, 18.31s/it]\n",
      "Train:  50%|████▉     | 1160/2326 [6:03:48<6:04:55, 18.78s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  50%|████▉     | 1160/2326 [6:03:48<6:04:55, 18.78s/it]\n",
      "Train:  50%|████▉     | 1160/2326 [6:03:48<6:04:55, 18.78s/it]\n",
      "Train:  50%|████▉     | 1161/2326 [6:04:07<6:06:16, 18.86s/it]\n",
      "Train:  50%|████▉     | 1162/2326 [6:04:26<6:05:09, 18.82s/it]\n",
      "Train:  50%|█████     | 1163/2326 [6:04:27<4:22:10, 13.53s/it]\n",
      "{'loss': 1.79903393, 'token_acc': 0.60923671, 'grad_norm': 1.30031013, 'learning_rate': 5.437e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.05314, 'epoch': 1.0, 'global_step/max_steps': '1160/2326', 'percentage': '49.87%', 'elapsed_time': '6h 3m 48s', 'remaining_time': '6h 5m 41s'}\n",
      "\n",
      "Train:  50%|█████     | 1164/2326 [6:04:46<4:52:56, 15.13s/it]\n",
      "Train:  50%|█████     | 1165/2326 [6:05:04<5:09:36, 16.00s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  50%|█████     | 1165/2326 [6:05:04<5:09:36, 16.00s/it]\n",
      "Train:  50%|█████     | 1165/2326 [6:05:04<5:09:36, 16.00s/it]\n",
      "Train:  50%|█████     | 1166/2326 [6:05:23<5:26:47, 16.90s/it]\n",
      "Train:  50%|█████     | 1167/2326 [6:05:42<5:34:08, 17.30s/it]\n",
      "Train:  50%|█████     | 1168/2326 [6:06:01<5:43:48, 17.81s/it]\n",
      "Train:  50%|█████     | 1169/2326 [6:06:19<5:48:11, 18.06s/it]\n",
      "Train:  50%|█████     | 1170/2326 [6:06:39<5:57:43, 18.57s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  50%|█████     | 1170/2326 [6:06:39<5:57:43, 18.57s/it]\n",
      "Train:  50%|█████     | 1170/2326 [6:06:39<5:57:43, 18.57s/it]\n",
      "Train:  50%|█████     | 1171/2326 [6:06:58<5:59:11, 18.66s/it]\n",
      "Train:  50%|█████     | 1172/2326 [6:07:16<5:54:15, 18.42s/it]\n",
      "Train:  50%|█████     | 1173/2326 [6:07:35<5:56:55, 18.57s/it]\n",
      "Train:  50%|█████     | 1174/2326 [6:07:52<5:52:19, 18.35s/it]\n",
      "Train:  51%|█████     | 1175/2326 [6:08:11<5:54:50, 18.50s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  51%|█████     | 1175/2326 [6:08:11<5:54:50, 18.50s/it]\n",
      "Train:  51%|█████     | 1175/2326 [6:08:11<5:54:50, 18.50s/it]\n",
      "Train:  51%|█████     | 1176/2326 [6:08:30<5:53:21, 18.44s/it]\n",
      "Train:  51%|█████     | 1177/2326 [6:08:47<5:50:04, 18.28s/it]\n",
      "Train:  51%|█████     | 1178/2326 [6:09:06<5:48:43, 18.23s/it]\n",
      "Train:  51%|█████     | 1179/2326 [6:09:24<5:50:44, 18.35s/it]\n",
      "Train:  51%|█████     | 1180/2326 [6:09:43<5:54:32, 18.56s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  51%|█████     | 1180/2326 [6:09:43<5:54:32, 18.56s/it]\n",
      "Train:  51%|█████     | 1180/2326 [6:09:43<5:54:32, 18.56s/it]\n",
      "Train:  51%|█████     | 1181/2326 [6:10:02<5:52:28, 18.47s/it]\n",
      "Train:  51%|█████     | 1182/2326 [6:10:20<5:53:12, 18.52s/it]\n",
      "Train:  51%|█████     | 1183/2326 [6:10:39<5:56:18, 18.70s/it]\n",
      "Train:  51%|█████     | 1184/2326 [6:10:59<6:00:00, 18.91s/it]\n",
      "Train:  51%|█████     | 1185/2326 [6:11:17<5:56:20, 18.74s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  51%|█████     | 1185/2326 [6:11:17<5:56:20, 18.74s/it]\n",
      "Train:  51%|█████     | 1185/2326 [6:11:17<5:56:20, 18.74s/it]\n",
      "Train:  51%|█████     | 1186/2326 [6:11:35<5:54:22, 18.65s/it]\n",
      "Train:  51%|█████     | 1187/2326 [6:11:54<5:50:58, 18.49s/it]\n",
      "Train:  51%|█████     | 1188/2326 [6:12:13<5:55:17, 18.73s/it]\n",
      "Train:  51%|█████     | 1189/2326 [6:12:31<5:52:33, 18.60s/it]\n",
      "Train:  51%|█████     | 1190/2326 [6:12:50<5:55:58, 18.80s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  51%|█████     | 1190/2326 [6:12:51<5:55:58, 18.80s/it]\n",
      "Train:  51%|█████     | 1190/2326 [6:12:51<5:55:58, 18.80s/it]\n",
      "Train:  51%|█████     | 1191/2326 [6:13:09<5:55:24, 18.79s/it]\n",
      "Train:  51%|█████     | 1192/2326 [6:13:28<5:53:41, 18.71s/it]\n",
      "Train:  51%|█████▏    | 1193/2326 [6:13:46<5:51:21, 18.61s/it]\n",
      "Train:  51%|█████▏    | 1194/2326 [6:14:06<5:57:22, 18.94s/it]\n",
      "Train:  51%|█████▏    | 1195/2326 [6:14:25<5:57:49, 18.98s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  51%|█████▏    | 1195/2326 [6:14:25<5:57:49, 18.98s/it]\n",
      "Train:  51%|█████▏    | 1195/2326 [6:14:25<5:57:49, 18.98s/it]\n",
      "Train:  51%|█████▏    | 1196/2326 [6:14:43<5:55:22, 18.87s/it]\n",
      "Train:  51%|█████▏    | 1197/2326 [6:15:02<5:50:25, 18.62s/it]\n",
      "Train:  52%|█████▏    | 1198/2326 [6:15:20<5:48:17, 18.53s/it]\n",
      "Train:  52%|█████▏    | 1199/2326 [6:15:38<5:47:23, 18.49s/it]\n",
      "Train:  52%|█████▏    | 1200/2326 [6:15:59<6:00:28, 19.21s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  52%|█████▏    | 1200/2326 [6:15:59<6:00:28, 19.21s/it]\n",
      "Train:  52%|█████▏    | 1200/2326 [6:15:59<6:00:28, 19.21s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v10-20250927-234036/checkpoint-1200\n",
      "\n",
      "Train:  52%|█████▏    | 1201/2326 [6:16:18<6:00:17, 19.22s/it]\n",
      "Train:  52%|█████▏    | 1202/2326 [6:16:37<5:57:23, 19.08s/it]\n",
      "Train:  52%|█████▏    | 1203/2326 [6:16:56<5:57:38, 19.11s/it]\n",
      "Train:  52%|█████▏    | 1204/2326 [6:17:16<6:01:08, 19.31s/it]\n",
      "Train:  52%|█████▏    | 1205/2326 [6:17:35<5:56:34, 19.09s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  52%|█████▏    | 1205/2326 [6:17:35<5:56:34, 19.09s/it]\n",
      "Train:  52%|█████▏    | 1205/2326 [6:17:35<5:56:34, 19.09s/it]\n",
      "Train:  52%|█████▏    | 1206/2326 [6:17:55<6:05:18, 19.57s/it]\n",
      "Train:  52%|█████▏    | 1207/2326 [6:18:14<5:59:09, 19.26s/it]\n",
      "Train:  52%|█████▏    | 1208/2326 [6:18:33<6:00:42, 19.36s/it]\n",
      "Train:  52%|█████▏    | 1209/2326 [6:18:53<5:58:40, 19.27s/it]\n",
      "Train:  52%|█████▏    | 1210/2326 [6:19:11<5:51:50, 18.92s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  52%|█████▏    | 1210/2326 [6:19:11<5:51:50, 18.92s/it]\n",
      "Train:  52%|█████▏    | 1210/2326 [6:19:11<5:51:50, 18.92s/it]\n",
      "Train:  52%|█████▏    | 1211/2326 [6:19:29<5:50:43, 18.87s/it]\n",
      "Train:  52%|█████▏    | 1212/2326 [6:19:48<5:50:33, 18.88s/it]\n",
      "Train:  52%|█████▏    | 1213/2326 [6:20:06<5:45:59, 18.65s/it]\n",
      "Train:  52%|█████▏    | 1214/2326 [6:20:25<5:43:14, 18.52s/it]\n",
      "Train:  52%|█████▏    | 1215/2326 [6:20:45<5:51:26, 18.98s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  52%|█████▏    | 1215/2326 [6:20:45<5:51:26, 18.98s/it]\n",
      "Train:  52%|█████▏    | 1215/2326 [6:20:45<5:51:26, 18.98s/it]\n",
      "Train:  52%|█████▏    | 1216/2326 [6:21:04<5:54:34, 19.17s/it]\n",
      "Train:  52%|█████▏    | 1217/2326 [6:21:23<5:52:13, 19.06s/it]\n",
      "Train:  52%|█████▏    | 1218/2326 [6:21:42<5:50:12, 18.96s/it]\n",
      "Train:  52%|█████▏    | 1219/2326 [6:22:00<5:45:15, 18.71s/it]\n",
      "Train:  52%|█████▏    | 1220/2326 [6:22:18<5:40:09, 18.45s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  52%|█████▏    | 1220/2326 [6:22:18<5:40:09, 18.45s/it]\n",
      "Train:  52%|█████▏    | 1220/2326 [6:22:18<5:40:09, 18.45s/it]\n",
      "Train:  52%|█████▏    | 1221/2326 [6:22:36<5:38:04, 18.36s/it]\n",
      "Train:  53%|█████▎    | 1222/2326 [6:22:55<5:40:55, 18.53s/it]\n",
      "Train:  53%|█████▎    | 1223/2326 [6:23:13<5:39:32, 18.47s/it]\n",
      "Train:  53%|█████▎    | 1224/2326 [6:23:31<5:38:16, 18.42s/it]\n",
      "Train:  53%|█████▎    | 1225/2326 [6:23:50<5:38:15, 18.43s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  53%|█████▎    | 1225/2326 [6:23:50<5:38:15, 18.43s/it]\n",
      "Train:  53%|█████▎    | 1225/2326 [6:23:50<5:38:15, 18.43s/it]\n",
      "Train:  53%|█████▎    | 1226/2326 [6:24:08<5:37:49, 18.43s/it]\n",
      "Train:  53%|█████▎    | 1227/2326 [6:24:28<5:42:39, 18.71s/it]\n",
      "Train:  53%|█████▎    | 1228/2326 [6:24:46<5:37:52, 18.46s/it]\n",
      "Train:  53%|█████▎    | 1229/2326 [6:25:04<5:35:17, 18.34s/it]\n",
      "Train:  53%|█████▎    | 1230/2326 [6:25:22<5:33:29, 18.26s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  53%|█████▎    | 1230/2326 [6:25:22<5:33:29, 18.26s/it]\n",
      "Train:  53%|█████▎    | 1230/2326 [6:25:22<5:33:29, 18.26s/it]\n",
      "Train:  53%|█████▎    | 1231/2326 [6:25:41<5:36:39, 18.45s/it]\n",
      "Train:  53%|█████▎    | 1232/2326 [6:25:58<5:33:07, 18.27s/it]\n",
      "Train:  53%|█████▎    | 1233/2326 [6:26:18<5:38:36, 18.59s/it]\n",
      "Train:  53%|█████▎    | 1234/2326 [6:26:37<5:39:36, 18.66s/it]\n",
      "Train:  53%|█████▎    | 1235/2326 [6:26:57<5:47:19, 19.10s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  53%|█████▎    | 1235/2326 [6:26:57<5:47:19, 19.10s/it]\n",
      "Train:  53%|█████▎    | 1235/2326 [6:26:57<5:47:19, 19.10s/it]\n",
      "Train:  53%|█████▎    | 1236/2326 [6:27:15<5:43:37, 18.92s/it]\n",
      "Train:  53%|█████▎    | 1237/2326 [6:27:34<5:43:34, 18.93s/it]\n",
      "Train:  53%|█████▎    | 1238/2326 [6:27:54<5:49:09, 19.26s/it]\n",
      "Train:  53%|█████▎    | 1239/2326 [6:28:13<5:47:03, 19.16s/it]\n",
      "Train:  53%|█████▎    | 1240/2326 [6:28:32<5:44:23, 19.03s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  53%|█████▎    | 1240/2326 [6:28:32<5:44:23, 19.03s/it]\n",
      "Train:  53%|█████▎    | 1240/2326 [6:28:32<5:44:23, 19.03s/it]\n",
      "Train:  53%|█████▎    | 1241/2326 [6:28:51<5:42:20, 18.93s/it]\n",
      "Train:  53%|█████▎    | 1242/2326 [6:29:09<5:41:47, 18.92s/it]\n",
      "Train:  53%|█████▎    | 1243/2326 [6:29:28<5:37:21, 18.69s/it]\n",
      "Train:  53%|█████▎    | 1244/2326 [6:29:47<5:39:38, 18.83s/it]\n",
      "Train:  54%|█████▎    | 1245/2326 [6:30:05<5:37:00, 18.70s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  54%|█████▎    | 1245/2326 [6:30:05<5:37:00, 18.70s/it]\n",
      "Train:  54%|█████▎    | 1245/2326 [6:30:05<5:37:00, 18.70s/it]\n",
      "Train:  54%|█████▎    | 1246/2326 [6:30:25<5:40:28, 18.92s/it]\n",
      "Train:  54%|█████▎    | 1247/2326 [6:30:43<5:38:51, 18.84s/it]\n",
      "Train:  54%|█████▎    | 1248/2326 [6:31:02<5:36:17, 18.72s/it]\n",
      "Train:  54%|█████▎    | 1249/2326 [6:31:22<5:41:55, 19.05s/it]\n",
      "Train:  54%|█████▎    | 1250/2326 [6:31:41<5:43:12, 19.14s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  54%|█████▎    | 1250/2326 [6:31:41<5:43:12, 19.14s/it]\n",
      "Train:  54%|█████▎    | 1250/2326 [6:31:41<5:43:12, 19.14s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v10-20250927-234036/checkpoint-1250\n",
      "\n",
      "Train:  54%|█████▍    | 1251/2326 [6:32:00<5:44:29, 19.23s/it]\n",
      "Train:  54%|█████▍    | 1252/2326 [6:32:19<5:39:32, 18.97s/it]\n",
      "Train:  54%|█████▍    | 1253/2326 [6:32:38<5:38:53, 18.95s/it]\n",
      "Train:  54%|█████▍    | 1254/2326 [6:32:56<5:34:19, 18.71s/it]\n",
      "Train:  54%|█████▍    | 1255/2326 [6:33:14<5:33:37, 18.69s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  54%|█████▍    | 1255/2326 [6:33:14<5:33:37, 18.69s/it]\n",
      "Train:  54%|█████▍    | 1255/2326 [6:33:14<5:33:37, 18.69s/it]\n",
      "Train:  54%|█████▍    | 1256/2326 [6:33:33<5:31:28, 18.59s/it]\n",
      "Train:  54%|█████▍    | 1257/2326 [6:33:52<5:33:37, 18.73s/it]\n",
      "Train:  54%|█████▍    | 1258/2326 [6:34:09<5:25:31, 18.29s/it]\n",
      "Train:  54%|█████▍    | 1259/2326 [6:34:27<5:22:27, 18.13s/it]\n",
      "Train:  54%|█████▍    | 1260/2326 [6:34:46<5:27:23, 18.43s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  54%|█████▍    | 1260/2326 [6:34:46<5:27:23, 18.43s/it]\n",
      "Train:  54%|█████▍    | 1260/2326 [6:34:46<5:27:23, 18.43s/it]\n",
      "Train:  54%|█████▍    | 1261/2326 [6:35:04<5:27:02, 18.42s/it]\n",
      "Train:  54%|█████▍    | 1262/2326 [6:35:23<5:28:47, 18.54s/it]\n",
      "Train:  54%|█████▍    | 1263/2326 [6:35:42<5:27:52, 18.51s/it]\n",
      "Train:  54%|█████▍    | 1264/2326 [6:36:01<5:31:13, 18.71s/it]\n",
      "Train:  54%|█████▍    | 1265/2326 [6:36:21<5:36:31, 19.03s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  54%|█████▍    | 1265/2326 [6:36:21<5:36:31, 19.03s/it]\n",
      "Train:  54%|█████▍    | 1265/2326 [6:36:21<5:36:31, 19.03s/it]\n",
      "Train:  54%|█████▍    | 1266/2326 [6:36:38<5:29:37, 18.66s/it]\n",
      "Train:  54%|█████▍    | 1267/2326 [6:36:56<5:25:40, 18.45s/it]\n",
      "Train:  55%|█████▍    | 1268/2326 [6:37:15<5:26:24, 18.51s/it]\n",
      "Train:  55%|█████▍    | 1269/2326 [6:37:34<5:30:52, 18.78s/it]\n",
      "Train:  55%|█████▍    | 1270/2326 [6:37:53<5:27:10, 18.59s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  55%|█████▍    | 1270/2326 [6:37:53<5:27:10, 18.59s/it]\n",
      "Train:  55%|█████▍    | 1270/2326 [6:37:53<5:27:10, 18.59s/it]\n",
      "Train:  55%|█████▍    | 1271/2326 [6:38:12<5:32:12, 18.89s/it]\n",
      "Train:  55%|█████▍    | 1272/2326 [6:38:30<5:28:07, 18.68s/it]\n",
      "Train:  55%|█████▍    | 1273/2326 [6:38:48<5:25:07, 18.53s/it]\n",
      "Train:  55%|█████▍    | 1274/2326 [6:39:07<5:23:34, 18.45s/it]\n",
      "Train:  55%|█████▍    | 1275/2326 [6:39:25<5:23:32, 18.47s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  55%|█████▍    | 1275/2326 [6:39:25<5:23:32, 18.47s/it]\n",
      "Train:  55%|█████▍    | 1275/2326 [6:39:25<5:23:32, 18.47s/it]\n",
      "Train:  55%|█████▍    | 1276/2326 [6:39:45<5:28:46, 18.79s/it]\n",
      "Train:  55%|█████▍    | 1277/2326 [6:40:03<5:26:20, 18.67s/it]\n",
      "Train:  55%|█████▍    | 1278/2326 [6:40:21<5:22:22, 18.46s/it]\n",
      "Train:  55%|█████▍    | 1279/2326 [6:40:40<5:23:13, 18.52s/it]\n",
      "Train:  55%|█████▌    | 1280/2326 [6:40:59<5:27:36, 18.79s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  55%|█████▌    | 1280/2326 [6:40:59<5:27:36, 18.79s/it]\n",
      "Train:  55%|█████▌    | 1280/2326 [6:40:59<5:27:36, 18.79s/it]\n",
      "Train:  55%|█████▌    | 1281/2326 [6:41:18<5:28:31, 18.86s/it]\n",
      "Train:  55%|█████▌    | 1282/2326 [6:41:37<5:29:27, 18.93s/it]\n",
      "Train:  55%|█████▌    | 1283/2326 [6:41:56<5:26:15, 18.77s/it]\n",
      "Train:  55%|█████▌    | 1284/2326 [6:42:15<5:27:49, 18.88s/it]\n",
      "Train:  55%|█████▌    | 1285/2326 [6:42:33<5:23:40, 18.66s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  55%|█████▌    | 1285/2326 [6:42:33<5:23:40, 18.66s/it]\n",
      "Train:  55%|█████▌    | 1285/2326 [6:42:33<5:23:40, 18.66s/it]\n",
      "Train:  55%|█████▌    | 1286/2326 [6:42:52<5:22:37, 18.61s/it]\n",
      "Train:  55%|█████▌    | 1287/2326 [6:43:11<5:24:23, 18.73s/it]\n",
      "Train:  55%|█████▌    | 1288/2326 [6:43:29<5:23:27, 18.70s/it]\n",
      "Train:  55%|█████▌    | 1289/2326 [6:43:48<5:24:15, 18.76s/it]\n",
      "Train:  55%|█████▌    | 1290/2326 [6:44:06<5:21:00, 18.59s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  55%|█████▌    | 1290/2326 [6:44:06<5:21:00, 18.59s/it]\n",
      "Train:  55%|█████▌    | 1290/2326 [6:44:06<5:21:00, 18.59s/it]\n",
      "Train:  56%|█████▌    | 1291/2326 [6:44:25<5:22:48, 18.71s/it]\n",
      "Train:  56%|█████▌    | 1292/2326 [6:44:44<5:20:25, 18.59s/it]\n",
      "Train:  56%|█████▌    | 1293/2326 [6:45:02<5:19:18, 18.55s/it]\n",
      "Train:  56%|█████▌    | 1294/2326 [6:45:21<5:22:56, 18.78s/it]\n",
      "Train:  56%|█████▌    | 1295/2326 [6:45:40<5:23:32, 18.83s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  56%|█████▌    | 1295/2326 [6:45:40<5:23:32, 18.83s/it]\n",
      "Train:  56%|█████▌    | 1295/2326 [6:45:40<5:23:32, 18.83s/it]\n",
      "Train:  56%|█████▌    | 1296/2326 [6:45:59<5:23:22, 18.84s/it]\n",
      "Train:  56%|█████▌    | 1297/2326 [6:46:17<5:20:30, 18.69s/it]\n",
      "Train:  56%|█████▌    | 1298/2326 [6:46:36<5:21:14, 18.75s/it]\n",
      "Train:  56%|█████▌    | 1299/2326 [6:46:56<5:24:51, 18.98s/it]\n",
      "Train:  56%|█████▌    | 1300/2326 [6:47:14<5:20:26, 18.74s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  56%|█████▌    | 1300/2326 [6:47:14<5:20:26, 18.74s/it]\n",
      "Train:  56%|█████▌    | 1300/2326 [6:47:14<5:20:26, 18.74s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v10-20250927-234036/checkpoint-1300\n",
      "\n",
      "Train:  56%|█████▌    | 1301/2326 [6:47:35<5:29:43, 19.30s/it]\n",
      "Train:  56%|█████▌    | 1302/2326 [6:47:53<5:24:08, 18.99s/it]\n",
      "Train:  56%|█████▌    | 1303/2326 [6:48:11<5:21:02, 18.83s/it]\n",
      "Train:  56%|█████▌    | 1304/2326 [6:48:30<5:21:11, 18.86s/it]\n",
      "Train:  56%|█████▌    | 1305/2326 [6:48:50<5:25:04, 19.10s/it]\n",
      "                                                              \n",
      "{'loss': 1.83572674, 'token_acc': 0.62646873, 'grad_norm': 1.38010669, 'learning_rate': 5.401e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053184, 'epoch': 1.0, 'global_step/max_steps': '1165/2326', 'percentage': '50.09%', 'elapsed_time': '6h 5m 4s', 'remaining_time': '6h 3m 49s'}\n",
      "{'loss': 1.65426235, 'token_acc': 0.63242835, 'grad_norm': 1.32623947, 'learning_rate': 5.366e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053183, 'epoch': 1.01, 'global_step/max_steps': '1170/2326', 'percentage': '50.30%', 'elapsed_time': '6h 6m 39s', 'remaining_time': '6h 2m 16s'}\n",
      "{'loss': 1.74259586, 'token_acc': 0.61526334, 'grad_norm': 1.41286063, 'learning_rate': 5.33e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053187, 'epoch': 1.01, 'global_step/max_steps': '1175/2326', 'percentage': '50.52%', 'elapsed_time': '6h 8m 11s', 'remaining_time': '6h 0m 40s'}\n",
      "{'loss': 1.70873318, 'token_acc': 0.62665577, 'grad_norm': 1.48633945, 'learning_rate': 5.295e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053191, 'epoch': 1.01, 'global_step/max_steps': '1180/2326', 'percentage': '50.73%', 'elapsed_time': '6h 9m 43s', 'remaining_time': '5h 59m 4s'}\n",
      "{'loss': 1.75000401, 'token_acc': 0.61472446, 'grad_norm': 1.544168, 'learning_rate': 5.259e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053192, 'epoch': 1.02, 'global_step/max_steps': '1185/2326', 'percentage': '50.95%', 'elapsed_time': '6h 11m 17s', 'remaining_time': '5h 57m 30s'}\n",
      "{'loss': 1.76441174, 'token_acc': 0.60880624, 'grad_norm': 1.46513224, 'learning_rate': 5.224e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053193, 'epoch': 1.02, 'global_step/max_steps': '1190/2326', 'percentage': '51.16%', 'elapsed_time': '6h 12m 51s', 'remaining_time': '5h 55m 55s'}\n",
      "{'loss': 1.61916084, 'token_acc': 0.64888889, 'grad_norm': 1.63296032, 'learning_rate': 5.188e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053192, 'epoch': 1.03, 'global_step/max_steps': '1195/2326', 'percentage': '51.38%', 'elapsed_time': '6h 14m 25s', 'remaining_time': '5h 54m 22s'}\n",
      "{'loss': 1.82495232, 'token_acc': 0.60028058, 'grad_norm': 1.16210902, 'learning_rate': 5.153e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053192, 'epoch': 1.03, 'global_step/max_steps': '1200/2326', 'percentage': '51.59%', 'elapsed_time': '6h 15m 59s', 'remaining_time': '5h 52m 48s'}\n",
      "{'loss': 1.81117363, 'token_acc': 0.60543234, 'grad_norm': 1.57692373, 'learning_rate': 5.117e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053188, 'epoch': 1.04, 'global_step/max_steps': '1205/2326', 'percentage': '51.81%', 'elapsed_time': '6h 17m 35s', 'remaining_time': '5h 51m 15s'}\n",
      "{'loss': 1.72084312, 'token_acc': 0.62519324, 'grad_norm': 1.60470092, 'learning_rate': 5.082e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053184, 'epoch': 1.04, 'global_step/max_steps': '1210/2326', 'percentage': '52.02%', 'elapsed_time': '6h 19m 11s', 'remaining_time': '5h 49m 43s'}\n",
      "{'loss': 1.76452579, 'token_acc': 0.61487779, 'grad_norm': 1.19270325, 'learning_rate': 5.046e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053183, 'epoch': 1.04, 'global_step/max_steps': '1215/2326', 'percentage': '52.24%', 'elapsed_time': '6h 20m 45s', 'remaining_time': '5h 48m 9s'}\n",
      "{'loss': 1.88554249, 'token_acc': 0.59651363, 'grad_norm': 1.62831414, 'learning_rate': 5.011e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053185, 'epoch': 1.05, 'global_step/max_steps': '1220/2326', 'percentage': '52.45%', 'elapsed_time': '6h 22m 18s', 'remaining_time': '5h 46m 34s'}\n",
      "{'loss': 1.82824688, 'token_acc': 0.60330917, 'grad_norm': 1.42480934, 'learning_rate': 4.975e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.05319, 'epoch': 1.05, 'global_step/max_steps': '1225/2326', 'percentage': '52.67%', 'elapsed_time': '6h 23m 50s', 'remaining_time': '5h 44m 59s'}\n",
      "{'loss': 1.8238884, 'token_acc': 0.60622176, 'grad_norm': 1.52726293, 'learning_rate': 4.94e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053195, 'epoch': 1.06, 'global_step/max_steps': '1230/2326', 'percentage': '52.88%', 'elapsed_time': '6h 25m 22s', 'remaining_time': '5h 43m 23s'}\n",
      "{'loss': 1.80898914, 'token_acc': 0.60632543, 'grad_norm': 1.37082767, 'learning_rate': 4.904e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053192, 'epoch': 1.06, 'global_step/max_steps': '1235/2326', 'percentage': '53.10%', 'elapsed_time': '6h 26m 57s', 'remaining_time': '5h 41m 50s'}\n",
      "{'loss': 1.73409748, 'token_acc': 0.61869387, 'grad_norm': 1.54984915, 'learning_rate': 4.868e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.05319, 'epoch': 1.07, 'global_step/max_steps': '1240/2326', 'percentage': '53.31%', 'elapsed_time': '6h 28m 32s', 'remaining_time': '5h 40m 17s'}\n",
      "{'loss': 1.85185547, 'token_acc': 0.60144146, 'grad_norm': 1.59171331, 'learning_rate': 4.833e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053191, 'epoch': 1.07, 'global_step/max_steps': '1245/2326', 'percentage': '53.53%', 'elapsed_time': '6h 30m 5s', 'remaining_time': '5h 38m 42s'}\n",
      "{'loss': 1.6795599, 'token_acc': 0.63187335, 'grad_norm': 1.26758575, 'learning_rate': 4.797e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053188, 'epoch': 1.07, 'global_step/max_steps': '1250/2326', 'percentage': '53.74%', 'elapsed_time': '6h 31m 41s', 'remaining_time': '5h 37m 10s'}\n",
      "{'loss': 1.72003422, 'token_acc': 0.62399815, 'grad_norm': 1.54885221, 'learning_rate': 4.762e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053189, 'epoch': 1.08, 'global_step/max_steps': '1255/2326', 'percentage': '53.96%', 'elapsed_time': '6h 33m 14s', 'remaining_time': '5h 35m 35s'}\n",
      "{'loss': 1.71363792, 'token_acc': 0.6216089, 'grad_norm': 1.43674922, 'learning_rate': 4.726e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053194, 'epoch': 1.08, 'global_step/max_steps': '1260/2326', 'percentage': '54.17%', 'elapsed_time': '6h 34m 46s', 'remaining_time': '5h 33m 59s'}\n",
      "{'loss': 1.64674358, 'token_acc': 0.63950418, 'grad_norm': 1.25160527, 'learning_rate': 4.691e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053193, 'epoch': 1.09, 'global_step/max_steps': '1265/2326', 'percentage': '54.39%', 'elapsed_time': '6h 36m 21s', 'remaining_time': '5h 32m 26s'}\n",
      "{'loss': 1.81292934, 'token_acc': 0.60981492, 'grad_norm': 1.85326898, 'learning_rate': 4.655e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053197, 'epoch': 1.09, 'global_step/max_steps': '1270/2326', 'percentage': '54.60%', 'elapsed_time': '6h 37m 53s', 'remaining_time': '5h 30m 50s'}\n",
      "{'loss': 1.74771309, 'token_acc': 0.62022955, 'grad_norm': 1.46771717, 'learning_rate': 4.62e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.0532, 'epoch': 1.1, 'global_step/max_steps': '1275/2326', 'percentage': '54.82%', 'elapsed_time': '6h 39m 25s', 'remaining_time': '5h 29m 15s'}\n",
      "{'loss': 1.76426182, 'token_acc': 0.61881053, 'grad_norm': 1.22972405, 'learning_rate': 4.584e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.0532, 'epoch': 1.1, 'global_step/max_steps': '1280/2326', 'percentage': '55.03%', 'elapsed_time': '6h 40m 59s', 'remaining_time': '5h 27m 41s'}\n",
      "{'loss': 1.79767418, 'token_acc': 0.60853369, 'grad_norm': 1.75881767, 'learning_rate': 4.549e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053201, 'epoch': 1.1, 'global_step/max_steps': '1285/2326', 'percentage': '55.25%', 'elapsed_time': '6h 42m 33s', 'remaining_time': '5h 26m 7s'}\n",
      "{'loss': 1.76688995, 'token_acc': 0.6156105, 'grad_norm': 1.49504077, 'learning_rate': 4.514e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053202, 'epoch': 1.11, 'global_step/max_steps': '1290/2326', 'percentage': '55.46%', 'elapsed_time': '6h 44m 6s', 'remaining_time': '5h 24m 32s'}\n",
      "{'loss': 1.84280834, 'token_acc': 0.60341918, 'grad_norm': 1.43259227, 'learning_rate': 4.478e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053202, 'epoch': 1.11, 'global_step/max_steps': '1295/2326', 'percentage': '55.67%', 'elapsed_time': '6h 45m 40s', 'remaining_time': '5h 22m 58s'}\n",
      "{'loss': 1.71385555, 'token_acc': 0.62987013, 'grad_norm': 1.53882837, 'learning_rate': 4.443e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053203, 'epoch': 1.12, 'global_step/max_steps': '1300/2326', 'percentage': '55.89%', 'elapsed_time': '6h 47m 14s', 'remaining_time': '5h 21m 24s'}\n",
      "{'loss': 1.79179649, 'token_acc': 0.60631861, 'grad_norm': 1.53957319, 'learning_rate': 4.408e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053198, 'epoch': 1.12, 'global_step/max_steps': '1305/2326', 'percentage': '56.10%', 'elapsed_time': '6h 48m 50s', 'remaining_time': '5h 19m 52s'}\n",
      "Train:  56%|█████▌    | 1305/2326 [6:48:50<5:25:04, 19.10s/it]\n",
      "Train:  56%|█████▌    | 1305/2326 [6:48:50<5:25:04, 19.10s/it]\n",
      "Train:  56%|█████▌    | 1306/2326 [6:49:09<5:24:11, 19.07s/it]\n",
      "Train:  56%|█████▌    | 1307/2326 [6:49:28<5:21:56, 18.96s/it]\n",
      "Train:  56%|█████▌    | 1308/2326 [6:49:46<5:17:54, 18.74s/it]\n",
      "Train:  56%|█████▋    | 1309/2326 [6:50:04<5:13:39, 18.50s/it]\n",
      "Train:  56%|█████▋    | 1310/2326 [6:50:22<5:10:23, 18.33s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  56%|█████▋    | 1310/2326 [6:50:22<5:10:23, 18.33s/it]\n",
      "Train:  56%|█████▋    | 1310/2326 [6:50:22<5:10:23, 18.33s/it]\n",
      "Train:  56%|█████▋    | 1311/2326 [6:50:41<5:16:45, 18.72s/it]\n",
      "Train:  56%|█████▋    | 1312/2326 [6:51:00<5:14:34, 18.61s/it]\n",
      "Train:  56%|█████▋    | 1313/2326 [6:51:19<5:15:51, 18.71s/it]\n",
      "Train:  56%|█████▋    | 1314/2326 [6:51:37<5:14:35, 18.65s/it]\n",
      "Train:  57%|█████▋    | 1315/2326 [6:51:57<5:18:07, 18.88s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  57%|█████▋    | 1315/2326 [6:51:57<5:18:07, 18.88s/it]\n",
      "Train:  57%|█████▋    | 1315/2326 [6:51:57<5:18:07, 18.88s/it]\n",
      "Train:  57%|█████▋    | 1316/2326 [6:52:16<5:22:09, 19.14s/it]\n",
      "Train:  57%|█████▋    | 1317/2326 [6:52:35<5:21:13, 19.10s/it]\n",
      "Train:  57%|█████▋    | 1318/2326 [6:52:54<5:19:32, 19.02s/it]\n",
      "Train:  57%|█████▋    | 1319/2326 [6:53:13<5:19:15, 19.02s/it]\n",
      "Train:  57%|█████▋    | 1320/2326 [6:53:32<5:16:35, 18.88s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  57%|█████▋    | 1320/2326 [6:53:32<5:16:35, 18.88s/it]\n",
      "Train:  57%|█████▋    | 1320/2326 [6:53:32<5:16:35, 18.88s/it]\n",
      "Train:  57%|█████▋    | 1321/2326 [6:53:52<5:21:27, 19.19s/it]\n",
      "Train:  57%|█████▋    | 1322/2326 [6:54:11<5:19:32, 19.10s/it]\n",
      "Train:  57%|█████▋    | 1323/2326 [6:54:31<5:25:10, 19.45s/it]\n",
      "Train:  57%|█████▋    | 1324/2326 [6:54:50<5:25:34, 19.50s/it]\n",
      "Train:  57%|█████▋    | 1325/2326 [6:55:10<5:23:02, 19.36s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  57%|█████▋    | 1325/2326 [6:55:10<5:23:02, 19.36s/it]\n",
      "Train:  57%|█████▋    | 1325/2326 [6:55:10<5:23:02, 19.36s/it]\n",
      "Train:  57%|█████▋    | 1326/2326 [6:55:28<5:16:28, 18.99s/it]\n",
      "Train:  57%|█████▋    | 1327/2326 [6:55:48<5:22:36, 19.38s/it]\n",
      "Train:  57%|█████▋    | 1328/2326 [6:56:08<5:23:17, 19.44s/it]\n",
      "Train:  57%|█████▋    | 1329/2326 [6:56:27<5:20:55, 19.31s/it]\n",
      "Train:  57%|█████▋    | 1330/2326 [6:56:44<5:11:55, 18.79s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  57%|█████▋    | 1330/2326 [6:56:44<5:11:55, 18.79s/it]\n",
      "Train:  57%|█████▋    | 1330/2326 [6:56:44<5:11:55, 18.79s/it]\n",
      "Train:  57%|█████▋    | 1331/2326 [6:57:05<5:20:48, 19.35s/it]\n",
      "Train:  57%|█████▋    | 1332/2326 [6:57:24<5:18:45, 19.24s/it]\n",
      "Train:  57%|█████▋    | 1333/2326 [6:57:42<5:13:00, 18.91s/it]\n",
      "Train:  57%|█████▋    | 1334/2326 [6:58:01<5:12:39, 18.91s/it]\n",
      "Train:  57%|█████▋    | 1335/2326 [6:58:18<5:05:25, 18.49s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  57%|█████▋    | 1335/2326 [6:58:18<5:05:25, 18.49s/it]\n",
      "Train:  57%|█████▋    | 1335/2326 [6:58:18<5:05:25, 18.49s/it]\n",
      "Train:  57%|█████▋    | 1336/2326 [6:58:37<5:05:08, 18.49s/it]\n",
      "Train:  57%|█████▋    | 1337/2326 [6:58:57<5:15:01, 19.11s/it]\n",
      "Train:  58%|█████▊    | 1338/2326 [6:59:16<5:12:25, 18.97s/it]\n",
      "Train:  58%|█████▊    | 1339/2326 [6:59:34<5:09:01, 18.79s/it]\n",
      "Train:  58%|█████▊    | 1340/2326 [6:59:53<5:07:22, 18.70s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  58%|█████▊    | 1340/2326 [6:59:53<5:07:22, 18.70s/it]\n",
      "Train:  58%|█████▊    | 1340/2326 [6:59:53<5:07:22, 18.70s/it]\n",
      "Train:  58%|█████▊    | 1341/2326 [7:00:14<5:20:08, 19.50s/it]\n",
      "Train:  58%|█████▊    | 1342/2326 [7:00:32<5:12:07, 19.03s/it]\n",
      "Train:  58%|█████▊    | 1343/2326 [7:00:50<5:06:18, 18.70s/it]\n",
      "Train:  58%|█████▊    | 1344/2326 [7:01:09<5:04:51, 18.63s/it]\n",
      "Train:  58%|█████▊    | 1345/2326 [7:01:28<5:09:39, 18.94s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  58%|█████▊    | 1345/2326 [7:01:28<5:09:39, 18.94s/it]\n",
      "Train:  58%|█████▊    | 1345/2326 [7:01:28<5:09:39, 18.94s/it]\n",
      "Train:  58%|█████▊    | 1346/2326 [7:01:46<5:03:47, 18.60s/it]\n",
      "Train:  58%|█████▊    | 1347/2326 [7:02:05<5:05:11, 18.70s/it]\n",
      "Train:  58%|█████▊    | 1348/2326 [7:02:24<5:06:38, 18.81s/it]\n",
      "Train:  58%|█████▊    | 1349/2326 [7:02:42<5:04:07, 18.68s/it]\n",
      "Train:  58%|█████▊    | 1350/2326 [7:03:00<5:00:33, 18.48s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  58%|█████▊    | 1350/2326 [7:03:00<5:00:33, 18.48s/it]\n",
      "Train:  58%|█████▊    | 1350/2326 [7:03:00<5:00:33, 18.48s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v10-20250927-234036/checkpoint-1350\n",
      "\n",
      "Train:  58%|█████▊    | 1351/2326 [7:03:20<5:07:45, 18.94s/it]\n",
      "Train:  58%|█████▊    | 1352/2326 [7:03:39<5:03:40, 18.71s/it]\n",
      "Train:  58%|█████▊    | 1353/2326 [7:03:59<5:09:40, 19.10s/it]\n",
      "Train:  58%|█████▊    | 1354/2326 [7:04:17<5:07:37, 18.99s/it]\n",
      "Train:  58%|█████▊    | 1355/2326 [7:04:36<5:03:57, 18.78s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  58%|█████▊    | 1355/2326 [7:04:36<5:03:57, 18.78s/it]\n",
      "Train:  58%|█████▊    | 1355/2326 [7:04:36<5:03:57, 18.78s/it]\n",
      "Train:  58%|█████▊    | 1356/2326 [7:04:55<5:05:19, 18.89s/it]\n",
      "Train:  58%|█████▊    | 1357/2326 [7:05:14<5:04:18, 18.84s/it]\n",
      "Train:  58%|█████▊    | 1358/2326 [7:05:34<5:10:21, 19.24s/it]\n",
      "Train:  58%|█████▊    | 1359/2326 [7:05:53<5:08:40, 19.15s/it]\n",
      "Train:  58%|█████▊    | 1360/2326 [7:06:11<5:05:10, 18.96s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  58%|█████▊    | 1360/2326 [7:06:11<5:05:10, 18.96s/it]\n",
      "Train:  58%|█████▊    | 1360/2326 [7:06:11<5:05:10, 18.96s/it]\n",
      "Train:  59%|█████▊    | 1361/2326 [7:06:29<5:01:53, 18.77s/it]\n",
      "Train:  59%|█████▊    | 1362/2326 [7:06:48<5:01:24, 18.76s/it]\n",
      "Train:  59%|█████▊    | 1363/2326 [7:07:06<4:57:29, 18.54s/it]\n",
      "Train:  59%|█████▊    | 1364/2326 [7:07:24<4:53:40, 18.32s/it]\n",
      "Train:  59%|█████▊    | 1365/2326 [7:07:43<4:57:14, 18.56s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  59%|█████▊    | 1365/2326 [7:07:43<4:57:14, 18.56s/it]\n",
      "Train:  59%|█████▊    | 1365/2326 [7:07:43<4:57:14, 18.56s/it]\n",
      "Train:  59%|█████▊    | 1366/2326 [7:08:02<5:00:05, 18.76s/it]\n",
      "Train:  59%|█████▉    | 1367/2326 [7:08:20<4:56:11, 18.53s/it]\n",
      "Train:  59%|█████▉    | 1368/2326 [7:08:39<4:56:25, 18.56s/it]\n",
      "Train:  59%|█████▉    | 1369/2326 [7:08:57<4:53:49, 18.42s/it]\n",
      "Train:  59%|█████▉    | 1370/2326 [7:09:15<4:52:15, 18.34s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  59%|█████▉    | 1370/2326 [7:09:15<4:52:15, 18.34s/it]\n",
      "Train:  59%|█████▉    | 1370/2326 [7:09:15<4:52:15, 18.34s/it]\n",
      "Train:  59%|█████▉    | 1371/2326 [7:09:34<4:53:05, 18.41s/it]\n",
      "Train:  59%|█████▉    | 1372/2326 [7:09:52<4:52:51, 18.42s/it]\n",
      "Train:  59%|█████▉    | 1373/2326 [7:10:10<4:49:47, 18.24s/it]\n",
      "Train:  59%|█████▉    | 1374/2326 [7:10:28<4:47:47, 18.14s/it]\n",
      "Train:  59%|█████▉    | 1375/2326 [7:10:46<4:47:48, 18.16s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  59%|█████▉    | 1375/2326 [7:10:46<4:47:48, 18.16s/it]\n",
      "Train:  59%|█████▉    | 1375/2326 [7:10:46<4:47:48, 18.16s/it]\n",
      "Train:  59%|█████▉    | 1376/2326 [7:11:05<4:51:49, 18.43s/it]\n",
      "Train:  59%|█████▉    | 1377/2326 [7:11:23<4:49:33, 18.31s/it]\n",
      "Train:  59%|█████▉    | 1378/2326 [7:11:42<4:50:50, 18.41s/it]\n",
      "Train:  59%|█████▉    | 1379/2326 [7:12:00<4:49:51, 18.36s/it]\n",
      "Train:  59%|█████▉    | 1380/2326 [7:12:20<4:58:09, 18.91s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  59%|█████▉    | 1380/2326 [7:12:20<4:58:09, 18.91s/it]\n",
      "Train:  59%|█████▉    | 1380/2326 [7:12:20<4:58:09, 18.91s/it]\n",
      "Train:  59%|█████▉    | 1381/2326 [7:12:40<5:01:10, 19.12s/it]\n",
      "Train:  59%|█████▉    | 1382/2326 [7:12:59<4:58:35, 18.98s/it]\n",
      "Train:  59%|█████▉    | 1383/2326 [7:13:17<4:57:03, 18.90s/it]\n",
      "Train:  60%|█████▉    | 1384/2326 [7:13:36<4:53:41, 18.71s/it]\n",
      "Train:  60%|█████▉    | 1385/2326 [7:13:55<4:56:31, 18.91s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  60%|█████▉    | 1385/2326 [7:13:55<4:56:31, 18.91s/it]\n",
      "Train:  60%|█████▉    | 1385/2326 [7:13:55<4:56:31, 18.91s/it]\n",
      "Train:  60%|█████▉    | 1386/2326 [7:14:14<4:55:02, 18.83s/it]\n",
      "Train:  60%|█████▉    | 1387/2326 [7:14:35<5:05:50, 19.54s/it]\n",
      "Train:  60%|█████▉    | 1388/2326 [7:14:54<5:04:59, 19.51s/it]\n",
      "Train:  60%|█████▉    | 1389/2326 [7:15:14<5:07:36, 19.70s/it]\n",
      "Train:  60%|█████▉    | 1390/2326 [7:15:35<5:11:06, 19.94s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  60%|█████▉    | 1390/2326 [7:15:35<5:11:06, 19.94s/it]\n",
      "Train:  60%|█████▉    | 1390/2326 [7:15:35<5:11:06, 19.94s/it]\n",
      "Train:  60%|█████▉    | 1391/2326 [7:15:54<5:06:21, 19.66s/it]\n",
      "Train:  60%|█████▉    | 1392/2326 [7:16:13<5:02:25, 19.43s/it]\n",
      "Train:  60%|█████▉    | 1393/2326 [7:16:31<4:56:12, 19.05s/it]\n",
      "Train:  60%|█████▉    | 1394/2326 [7:16:50<4:55:51, 19.05s/it]\n",
      "Train:  60%|█████▉    | 1395/2326 [7:17:10<4:57:57, 19.20s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  60%|█████▉    | 1395/2326 [7:17:10<4:57:57, 19.20s/it]\n",
      "Train:  60%|█████▉    | 1395/2326 [7:17:10<4:57:57, 19.20s/it]\n",
      "Train:  60%|██████    | 1396/2326 [7:17:29<4:56:34, 19.13s/it]\n",
      "Train:  60%|██████    | 1397/2326 [7:17:47<4:54:32, 19.02s/it]\n",
      "Train:  60%|██████    | 1398/2326 [7:18:05<4:49:41, 18.73s/it]\n",
      "Train:  60%|██████    | 1399/2326 [7:18:25<4:51:53, 18.89s/it]\n",
      "Train:  60%|██████    | 1400/2326 [7:18:44<4:52:16, 18.94s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  60%|██████    | 1400/2326 [7:18:44<4:52:16, 18.94s/it]\n",
      "Train:  60%|██████    | 1400/2326 [7:18:44<4:52:16, 18.94s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v10-20250927-234036/checkpoint-1400\n",
      "\n",
      "Train:  60%|██████    | 1401/2326 [7:19:03<4:53:10, 19.02s/it]\n",
      "Train:  60%|██████    | 1402/2326 [7:19:21<4:48:26, 18.73s/it]\n",
      "Train:  60%|██████    | 1403/2326 [7:19:40<4:50:58, 18.91s/it]\n",
      "Train:  60%|██████    | 1404/2326 [7:20:00<4:55:58, 19.26s/it]\n",
      "Train:  60%|██████    | 1405/2326 [7:20:21<5:00:19, 19.56s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  60%|██████    | 1405/2326 [7:20:21<5:00:19, 19.56s/it]\n",
      "Train:  60%|██████    | 1405/2326 [7:20:21<5:00:19, 19.56s/it]\n",
      "Train:  60%|██████    | 1406/2326 [7:20:41<5:05:34, 19.93s/it]\n",
      "Train:  60%|██████    | 1407/2326 [7:21:00<4:58:59, 19.52s/it]\n",
      "Train:  61%|██████    | 1408/2326 [7:21:18<4:51:17, 19.04s/it]\n",
      "Train:  61%|██████    | 1409/2326 [7:21:37<4:50:44, 19.02s/it]\n",
      "Train:  61%|██████    | 1410/2326 [7:21:56<4:48:49, 18.92s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  61%|██████    | 1410/2326 [7:21:56<4:48:49, 18.92s/it]\n",
      "Train:  61%|██████    | 1410/2326 [7:21:56<4:48:49, 18.92s/it]\n",
      "Train:  61%|██████    | 1411/2326 [7:22:14<4:44:18, 18.64s/it]\n",
      "Train:  61%|██████    | 1412/2326 [7:22:32<4:42:22, 18.54s/it]\n",
      "Train:  61%|██████    | 1413/2326 [7:22:51<4:45:35, 18.77s/it]\n",
      "Train:  61%|██████    | 1414/2326 [7:23:09<4:42:46, 18.60s/it]\n",
      "Train:  61%|██████    | 1415/2326 [7:23:28<4:41:24, 18.53s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  61%|██████    | 1415/2326 [7:23:28<4:41:24, 18.53s/it]\n",
      "Train:  61%|██████    | 1415/2326 [7:23:28<4:41:24, 18.53s/it]\n",
      "Train:  61%|██████    | 1416/2326 [7:23:46<4:41:23, 18.55s/it]\n",
      "Train:  61%|██████    | 1417/2326 [7:24:04<4:38:40, 18.39s/it]\n",
      "Train:  61%|██████    | 1418/2326 [7:24:24<4:43:29, 18.73s/it]\n",
      "Train:  61%|██████    | 1419/2326 [7:24:42<4:40:03, 18.53s/it]\n",
      "Train:  61%|██████    | 1420/2326 [7:25:01<4:42:45, 18.73s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  61%|██████    | 1420/2326 [7:25:01<4:42:45, 18.73s/it]\n",
      "Train:  61%|██████    | 1420/2326 [7:25:01<4:42:45, 18.73s/it]\n",
      "Train:  61%|██████    | 1421/2326 [7:25:20<4:45:19, 18.92s/it]\n",
      "Train:  61%|██████    | 1422/2326 [7:25:39<4:41:16, 18.67s/it]\n",
      "Train:  61%|██████    | 1423/2326 [7:25:59<4:48:35, 19.18s/it]\n",
      "Train:  61%|██████    | 1424/2326 [7:26:18<4:47:00, 19.09s/it]\n",
      "Train:  61%|██████▏   | 1425/2326 [7:26:37<4:45:55, 19.04s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  61%|██████▏   | 1425/2326 [7:26:37<4:45:55, 19.04s/it]\n",
      "Train:  61%|██████▏   | 1425/2326 [7:26:37<4:45:55, 19.04s/it]\n",
      "Train:  61%|██████▏   | 1426/2326 [7:26:56<4:46:03, 19.07s/it]\n",
      "Train:  61%|██████▏   | 1427/2326 [7:27:14<4:39:43, 18.67s/it]\n",
      "Train:  61%|██████▏   | 1428/2326 [7:27:32<4:38:13, 18.59s/it]\n",
      "Train:  61%|██████▏   | 1429/2326 [7:27:50<4:34:35, 18.37s/it]\n",
      "Train:  61%|██████▏   | 1430/2326 [7:28:08<4:34:28, 18.38s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  61%|██████▏   | 1430/2326 [7:28:08<4:34:28, 18.38s/it]\n",
      "Train:  61%|██████▏   | 1430/2326 [7:28:08<4:34:28, 18.38s/it]\n",
      "Train:  62%|██████▏   | 1431/2326 [7:28:27<4:36:32, 18.54s/it]\n",
      "Train:  62%|██████▏   | 1432/2326 [7:28:45<4:34:19, 18.41s/it]\n",
      "Train:  62%|██████▏   | 1433/2326 [7:29:04<4:36:54, 18.61s/it]\n",
      "Train:  62%|██████▏   | 1434/2326 [7:29:23<4:34:49, 18.49s/it]\n",
      "Train:  62%|██████▏   | 1435/2326 [7:29:41<4:36:02, 18.59s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  62%|██████▏   | 1435/2326 [7:29:41<4:36:02, 18.59s/it]\n",
      "Train:  62%|██████▏   | 1435/2326 [7:29:41<4:36:02, 18.59s/it]\n",
      "Train:  62%|██████▏   | 1436/2326 [7:29:59<4:31:49, 18.32s/it]\n",
      "Train:  62%|██████▏   | 1437/2326 [7:30:19<4:36:28, 18.66s/it]\n",
      "Train:  62%|██████▏   | 1438/2326 [7:30:37<4:34:54, 18.58s/it]\n",
      "Train:  62%|██████▏   | 1439/2326 [7:30:55<4:33:05, 18.47s/it]\n",
      "Train:  62%|██████▏   | 1440/2326 [7:31:14<4:33:43, 18.54s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  62%|██████▏   | 1440/2326 [7:31:14<4:33:43, 18.54s/it]\n",
      "Train:  62%|██████▏   | 1440/2326 [7:31:14<4:33:43, 18.54s/it]\n",
      "Train:  62%|██████▏   | 1441/2326 [7:31:34<4:39:46, 18.97s/it]\n",
      "Train:  62%|██████▏   | 1442/2326 [7:31:53<4:38:43, 18.92s/it]\n",
      "Train:  62%|██████▏   | 1443/2326 [7:32:11<4:35:50, 18.74s/it]\n",
      "Train:  62%|██████▏   | 1444/2326 [7:32:29<4:34:23, 18.67s/it]\n",
      "Train:  62%|██████▏   | 1445/2326 [7:32:48<4:34:31, 18.70s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  62%|██████▏   | 1445/2326 [7:32:48<4:34:31, 18.70s/it]\n",
      "Train:  62%|██████▏   | 1445/2326 [7:32:48<4:34:31, 18.70s/it]\n",
      "Train:  62%|██████▏   | 1446/2326 [7:33:07<4:32:41, 18.59s/it]\n",
      "Train:  62%|██████▏   | 1447/2326 [7:33:25<4:33:32, 18.67s/it]\n",
      "Train:  62%|██████▏   | 1448/2326 [7:33:44<4:31:54, 18.58s/it]\n",
      "Train:  62%|██████▏   | 1449/2326 [7:34:02<4:30:42, 18.52s/it]\n",
      "Train:  62%|██████▏   | 1450/2326 [7:34:21<4:29:48, 18.48s/it]\n",
      "                                                              \n",
      "{'loss': 1.7781498, 'token_acc': 0.60758961, 'grad_norm': 1.63858855, 'learning_rate': 4.372e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053203, 'epoch': 1.13, 'global_step/max_steps': '1310/2326', 'percentage': '56.32%', 'elapsed_time': '6h 50m 22s', 'remaining_time': '5h 18m 16s'}\n",
      "{'loss': 1.73313618, 'token_acc': 0.61820325, 'grad_norm': 1.69135952, 'learning_rate': 4.337e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053201, 'epoch': 1.13, 'global_step/max_steps': '1315/2326', 'percentage': '56.53%', 'elapsed_time': '6h 51m 57s', 'remaining_time': '5h 16m 43s'}\n",
      "{'loss': 1.63465424, 'token_acc': 0.64013641, 'grad_norm': 1.61892426, 'learning_rate': 4.302e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053199, 'epoch': 1.14, 'global_step/max_steps': '1320/2326', 'percentage': '56.75%', 'elapsed_time': '6h 53m 32s', 'remaining_time': '5h 15m 10s'}\n",
      "{'loss': 1.71358547, 'token_acc': 0.62383098, 'grad_norm': 1.62486076, 'learning_rate': 4.267e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053191, 'epoch': 1.14, 'global_step/max_steps': '1325/2326', 'percentage': '56.96%', 'elapsed_time': '6h 55m 10s', 'remaining_time': '5h 13m 38s'}\n",
      "{'loss': 1.64592934, 'token_acc': 0.63924051, 'grad_norm': 1.84696078, 'learning_rate': 4.232e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.05319, 'epoch': 1.14, 'global_step/max_steps': '1330/2326', 'percentage': '57.18%', 'elapsed_time': '6h 56m 44s', 'remaining_time': '5h 12m 5s'}\n",
      "{'loss': 1.80409966, 'token_acc': 0.6060208, 'grad_norm': 1.79303658, 'learning_rate': 4.196e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053189, 'epoch': 1.15, 'global_step/max_steps': '1335/2326', 'percentage': '57.39%', 'elapsed_time': '6h 58m 18s', 'remaining_time': '5h 10m 31s'}\n",
      "{'loss': 1.69539738, 'token_acc': 0.63148069, 'grad_norm': 1.78804076, 'learning_rate': 4.161e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053188, 'epoch': 1.15, 'global_step/max_steps': '1340/2326', 'percentage': '57.61%', 'elapsed_time': '6h 59m 53s', 'remaining_time': '5h 8m 57s'}\n",
      "{'loss': 1.80623264, 'token_acc': 0.6060795, 'grad_norm': 1.35927331, 'learning_rate': 4.126e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053185, 'epoch': 1.16, 'global_step/max_steps': '1345/2326', 'percentage': '57.82%', 'elapsed_time': '7h 1m 28s', 'remaining_time': '5h 7m 24s'}\n",
      "{'loss': 1.70774784, 'token_acc': 0.61712632, 'grad_norm': 1.69952965, 'learning_rate': 4.091e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053189, 'epoch': 1.16, 'global_step/max_steps': '1350/2326', 'percentage': '58.04%', 'elapsed_time': '7h 3m 0s', 'remaining_time': '5h 5m 49s'}\n",
      "{'loss': 1.74627247, 'token_acc': 0.62138713, 'grad_norm': 1.58479834, 'learning_rate': 4.056e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053186, 'epoch': 1.17, 'global_step/max_steps': '1355/2326', 'percentage': '58.25%', 'elapsed_time': '7h 4m 36s', 'remaining_time': '5h 4m 16s'}\n",
      "{'loss': 1.76744118, 'token_acc': 0.61844455, 'grad_norm': 1.62370634, 'learning_rate': 4.021e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053183, 'epoch': 1.17, 'global_step/max_steps': '1360/2326', 'percentage': '58.47%', 'elapsed_time': '7h 6m 11s', 'remaining_time': '5h 2m 43s'}\n",
      "{'loss': 1.78625946, 'token_acc': 0.61154946, 'grad_norm': 1.62418246, 'learning_rate': 3.987e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053187, 'epoch': 1.17, 'global_step/max_steps': '1365/2326', 'percentage': '58.68%', 'elapsed_time': '7h 7m 43s', 'remaining_time': '5h 1m 8s'}\n",
      "{'loss': 1.75043812, 'token_acc': 0.61389784, 'grad_norm': 1.82712221, 'learning_rate': 3.952e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053191, 'epoch': 1.18, 'global_step/max_steps': '1370/2326', 'percentage': '58.90%', 'elapsed_time': '7h 9m 15s', 'remaining_time': '4h 59m 32s'}\n",
      "{'loss': 1.7860014, 'token_acc': 0.61147695, 'grad_norm': 1.57427049, 'learning_rate': 3.917e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053198, 'epoch': 1.18, 'global_step/max_steps': '1375/2326', 'percentage': '59.11%', 'elapsed_time': '7h 10m 46s', 'remaining_time': '4h 57m 56s'}\n",
      "{'loss': 1.7888689, 'token_acc': 0.60606392, 'grad_norm': 1.69737124, 'learning_rate': 3.882e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053197, 'epoch': 1.19, 'global_step/max_steps': '1380/2326', 'percentage': '59.33%', 'elapsed_time': '7h 12m 20s', 'remaining_time': '4h 56m 22s'}\n",
      "{'loss': 1.72096443, 'token_acc': 0.62646183, 'grad_norm': 1.51312935, 'learning_rate': 3.848e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053196, 'epoch': 1.19, 'global_step/max_steps': '1385/2326', 'percentage': '59.54%', 'elapsed_time': '7h 13m 55s', 'remaining_time': '4h 54m 49s'}\n",
      "{'loss': 1.75894108, 'token_acc': 0.62005328, 'grad_norm': 1.50683105, 'learning_rate': 3.813e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053184, 'epoch': 1.2, 'global_step/max_steps': '1390/2326', 'percentage': '59.76%', 'elapsed_time': '7h 15m 35s', 'remaining_time': '4h 53m 19s'}\n",
      "{'loss': 1.70611801, 'token_acc': 0.6266948, 'grad_norm': 1.50831449, 'learning_rate': 3.779e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053183, 'epoch': 1.2, 'global_step/max_steps': '1395/2326', 'percentage': '59.97%', 'elapsed_time': '7h 17m 10s', 'remaining_time': '4h 51m 45s'}\n",
      "{'loss': 1.74869785, 'token_acc': 0.61989506, 'grad_norm': 1.61869335, 'learning_rate': 3.744e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053182, 'epoch': 1.2, 'global_step/max_steps': '1400/2326', 'percentage': '60.19%', 'elapsed_time': '7h 18m 44s', 'remaining_time': '4h 50m 11s'}\n",
      "{'loss': 1.86195812, 'token_acc': 0.5949334, 'grad_norm': 1.4705112, 'learning_rate': 3.71e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053177, 'epoch': 1.21, 'global_step/max_steps': '1405/2326', 'percentage': '60.40%', 'elapsed_time': '7h 20m 21s', 'remaining_time': '4h 48m 39s'}\n",
      "{'loss': 1.66845074, 'token_acc': 0.63761694, 'grad_norm': 1.57837832, 'learning_rate': 3.676e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053175, 'epoch': 1.21, 'global_step/max_steps': '1410/2326', 'percentage': '60.62%', 'elapsed_time': '7h 21m 56s', 'remaining_time': '4h 47m 6s'}\n",
      "{'loss': 1.73124237, 'token_acc': 0.6289827, 'grad_norm': 1.70204866, 'learning_rate': 3.641e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053178, 'epoch': 1.22, 'global_step/max_steps': '1415/2326', 'percentage': '60.83%', 'elapsed_time': '7h 23m 28s', 'remaining_time': '4h 45m 30s'}\n",
      "{'loss': 1.57644424, 'token_acc': 0.64374965, 'grad_norm': 1.78738368, 'learning_rate': 3.607e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.05318, 'epoch': 1.22, 'global_step/max_steps': '1420/2326', 'percentage': '61.05%', 'elapsed_time': '7h 25m 1s', 'remaining_time': '4h 43m 56s'}\n",
      "{'loss': 1.7483778, 'token_acc': 0.61620583, 'grad_norm': 1.58028781, 'learning_rate': 3.573e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053177, 'epoch': 1.23, 'global_step/max_steps': '1425/2326', 'percentage': '61.26%', 'elapsed_time': '7h 26m 37s', 'remaining_time': '4h 42m 23s'}\n",
      "{'loss': 1.78101978, 'token_acc': 0.61438064, 'grad_norm': 1.7443167, 'learning_rate': 3.539e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053181, 'epoch': 1.23, 'global_step/max_steps': '1430/2326', 'percentage': '61.48%', 'elapsed_time': '7h 28m 8s', 'remaining_time': '4h 40m 47s'}\n",
      "{'loss': 1.71224575, 'token_acc': 0.62357287, 'grad_norm': 1.46127844, 'learning_rate': 3.505e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053183, 'epoch': 1.23, 'global_step/max_steps': '1435/2326', 'percentage': '61.69%', 'elapsed_time': '7h 29m 41s', 'remaining_time': '4h 39m 13s'}\n",
      "{'loss': 1.79443951, 'token_acc': 0.6137014, 'grad_norm': 1.60518253, 'learning_rate': 3.471e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053186, 'epoch': 1.24, 'global_step/max_steps': '1440/2326', 'percentage': '61.91%', 'elapsed_time': '7h 31m 14s', 'remaining_time': '4h 37m 38s'}\n",
      "{'loss': 1.64660244, 'token_acc': 0.63791229, 'grad_norm': 1.65293288, 'learning_rate': 3.437e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053186, 'epoch': 1.24, 'global_step/max_steps': '1445/2326', 'percentage': '62.12%', 'elapsed_time': '7h 32m 48s', 'remaining_time': '4h 36m 4s'}\n",
      "{'loss': 1.7374115, 'token_acc': 0.62276074, 'grad_norm': 1.59588909, 'learning_rate': 3.404e-05, 'memory(GiB)': 21.61, 'train_speed(iter/s)': 0.053189, 'epoch': 1.25, 'global_step/max_steps': '1450/2326', 'percentage': '62.34%', 'elapsed_time': '7h 34m 21s', 'remaining_time': '4h 34m 29s'}\n",
      "Train:  62%|██████▏   | 1450/2326 [7:34:21<4:29:48, 18.48s/it]\n",
      "Train:  62%|██████▏   | 1450/2326 [7:34:21<4:29:48, 18.48s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v10-20250927-234036/checkpoint-1450\n",
      "\n",
      "Train:  62%|██████▏   | 1451/2326 [7:34:41<4:37:39, 19.04s/it]\n",
      "Train:  62%|██████▏   | 1452/2326 [7:35:00<4:36:34, 18.99s/it]\n",
      "Train:  62%|██████▏   | 1453/2326 [7:35:20<4:42:24, 19.41s/it]\n",
      "Train:  63%|██████▎   | 1454/2326 [7:35:39<4:38:32, 19.17s/it]\n",
      "Train:  63%|██████▎   | 1455/2326 [7:35:58<4:36:25, 19.04s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  63%|██████▎   | 1455/2326 [7:35:58<4:36:25, 19.04s/it]\n",
      "Train:  63%|██████▎   | 1455/2326 [7:35:58<4:36:25, 19.04s/it]\n",
      "Train:  63%|██████▎   | 1456/2326 [7:36:16<4:32:33, 18.80s/it]\n",
      "Train:  63%|██████▎   | 1457/2326 [7:36:34<4:31:42, 18.76s/it]\n",
      "Train:  63%|██████▎   | 1458/2326 [7:36:55<4:37:55, 19.21s/it]\n",
      "Train:  63%|██████▎   | 1459/2326 [7:37:13<4:33:28, 18.93s/it]\n",
      "Train:  63%|██████▎   | 1460/2326 [7:37:31<4:31:31, 18.81s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  63%|██████▎   | 1460/2326 [7:37:32<4:31:31, 18.81s/it]\n",
      "Train:  63%|██████▎   | 1460/2326 [7:37:32<4:31:31, 18.81s/it]\n",
      "Train:  63%|██████▎   | 1461/2326 [7:37:50<4:29:43, 18.71s/it]\n",
      "Train:  63%|██████▎   | 1462/2326 [7:38:08<4:26:48, 18.53s/it]\n",
      "Train:  63%|██████▎   | 1463/2326 [7:38:26<4:24:00, 18.35s/it]\n",
      "Train:  63%|██████▎   | 1464/2326 [7:38:45<4:26:24, 18.54s/it]\n",
      "Train:  63%|██████▎   | 1465/2326 [7:39:05<4:31:09, 18.90s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  63%|██████▎   | 1465/2326 [7:39:05<4:31:09, 18.90s/it]\n",
      "Train:  63%|██████▎   | 1465/2326 [7:39:05<4:31:09, 18.90s/it]\n",
      "Train:  63%|██████▎   | 1466/2326 [7:39:24<4:32:02, 18.98s/it]\n",
      "Train:  63%|██████▎   | 1467/2326 [7:39:42<4:28:09, 18.73s/it]\n",
      "Train:  63%|██████▎   | 1468/2326 [7:40:00<4:24:37, 18.51s/it]\n",
      "Train:  63%|██████▎   | 1469/2326 [7:40:19<4:26:28, 18.66s/it]\n",
      "Train:  63%|██████▎   | 1470/2326 [7:40:38<4:26:50, 18.70s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  63%|██████▎   | 1470/2326 [7:40:38<4:26:50, 18.70s/it]\n",
      "Train:  63%|██████▎   | 1470/2326 [7:40:38<4:26:50, 18.70s/it]\n",
      "Train:  63%|██████▎   | 1471/2326 [7:40:56<4:25:48, 18.65s/it]\n",
      "Train:  63%|██████▎   | 1472/2326 [7:41:14<4:22:53, 18.47s/it]\n",
      "Train:  63%|██████▎   | 1473/2326 [7:41:32<4:20:25, 18.32s/it]\n",
      "Train:  63%|██████▎   | 1474/2326 [7:41:51<4:20:46, 18.37s/it]\n",
      "Train:  63%|██████▎   | 1475/2326 [7:42:10<4:25:26, 18.72s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  63%|██████▎   | 1475/2326 [7:42:10<4:25:26, 18.72s/it]\n",
      "Train:  63%|██████▎   | 1475/2326 [7:42:10<4:25:26, 18.72s/it]\n",
      "Train:  63%|██████▎   | 1476/2326 [7:42:30<4:27:01, 18.85s/it]\n",
      "Train:  63%|██████▎   | 1477/2326 [7:42:49<4:29:18, 19.03s/it]\n",
      "Train:  64%|██████▎   | 1478/2326 [7:43:08<4:27:22, 18.92s/it]\n",
      "Train:  64%|██████▎   | 1479/2326 [7:43:26<4:25:06, 18.78s/it]\n",
      "Train:  64%|██████▎   | 1480/2326 [7:43:47<4:31:49, 19.28s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  64%|██████▎   | 1480/2326 [7:43:47<4:31:49, 19.28s/it]\n",
      "Train:  64%|██████▎   | 1480/2326 [7:43:47<4:31:49, 19.28s/it]\n",
      "Train:  64%|██████▎   | 1481/2326 [7:44:06<4:30:21, 19.20s/it]\n",
      "Train:  64%|██████▎   | 1482/2326 [7:44:23<4:24:15, 18.79s/it]\n",
      "Train:  64%|██████▍   | 1483/2326 [7:44:43<4:26:42, 18.98s/it]\n",
      "Train:  64%|██████▍   | 1484/2326 [7:45:01<4:24:14, 18.83s/it]\n",
      "Train:  64%|██████▍   | 1485/2326 [7:45:19<4:18:02, 18.41s/it]\n",
      "                                                              \n",
      "\n",
      "Train:  64%|██████▍   | 1485/2326 [7:45:19<4:18:02, 18.41s/it]\n",
      "Train:  64%|██████▍   | 1485/2326 [7:45:19<4:18:02, 18.41s/it]\n",
      "Train:  64%|██████▍   | 1486/2326 [7:45:37<4:17:29, 18.39s/it]\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import os\n",
    "import sys\n",
    "!pip install git+https://github.com/mobiusml/hqq.git; \n",
    "'''\n",
    "nohup bash -c \" \\\n",
    "CUDA_VISIBLE_DEVICES=0 \\\n",
    "swift sft \\\n",
    "    --model Qwen/Qwen2.5-7B-Instruct \\\n",
    "    --train_type lora \\\n",
    "    --dataset '/mnt/workspace/data_process//final_data/train.json' \\\n",
    "    --torch_dtype bfloat16 \\\n",
    "    --quant_method hqq \\\n",
    "    --quant_bits 4 \\\n",
    "    --num_train_epochs 1 \\\n",
    "    --per_device_train_batch_size 2 \\\n",
    "    --per_device_eval_batch_size 1 \\\n",
    "    --learning_rate 1e-4 \\\n",
    "    --lora_rank 8 \\\n",
    "    --lora_alpha 32 \\\n",
    "    --target_modules all-linear \\\n",
    "    --gradient_accumulation_steps 16 \\\n",
    "    --eval_steps 50 \\\n",
    "    --save_steps 50 \\\n",
    "    --save_total_limit 2 \\\n",
    "    --logging_steps 5 \\\n",
    "    --max_length 1024 \\\n",
    "    --output_dir output \\\n",
    "    --system 'You are a helpful assistant.' \\\n",
    "    --warmup_ratio 0.05 \\\n",
    "    --dataloader_num_workers 4 \\\n",
    "    --model_author swift \\\n",
    "    --model_name swift-robot \\\n",
    "\" &\n",
    "'''\n",
    "def run_swift_sft():\n",
    "    # 记录开始时间\n",
    "    start_time = time.time()\n",
    "    print(f\"开始时间: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(start_time))}\\n\")\n",
    "    \n",
    "    # 构建要执行的命令列表\n",
    "    command_list = [\n",
    "        \"swift\", \"sft\",\n",
    "        \"--model\", \"Qwen/Qwen2.5-7B-Instruct\",\n",
    "        \"--train_type\", \"lora\",\n",
    "        \"--dataset\", \"/mnt/workspace/final_data/train.json\",\n",
    "        \"--torch_dtype\", \"bfloat16\",\n",
    "        \"--quant_method\", \"hqq\",\n",
    "        \"--quant_bits\", \"4\",\n",
    "        \"--num_train_epochs\", \"2\",\n",
    "        \"--per_device_train_batch_size\", \"2\",\n",
    "        \"--per_device_eval_batch_size\", \"1\",\n",
    "        \"--learning_rate\", \"1e-4\",\n",
    "        \"--lora_rank\", \"8\",\n",
    "        \"--lora_alpha\", \"32\",\n",
    "        \"--gradient_accumulation_steps\", \"16\",\n",
    "        \"--eval_steps\", \"50\",\n",
    "        \"--save_steps\", \"50\",\n",
    "        \"--save_total_limit\", \"2\",\n",
    "        \"--logging_steps\", \"5\",\n",
    "        \"--max_length\", \"1024\",\n",
    "        \"--output_dir\", \"output\",\n",
    "        \"--system\", \"You are a helpful assistant.\",\n",
    "        \"--warmup_ratio\", \"0.05\",\n",
    "        \"--dataloader_num_workers\", \"4\",\n",
    "        \"--model_author\", \"swift\",\n",
    "        \"--model_name\", \"swift-robot\"\n",
    "    ]\n",
    "    # 显示命令回显\n",
    "    print(\"即将执行的命令:\")\n",
    "    print(f\"CUDA_VISIBLE_DEVICES=0 { ' '.join(command_list) }\\n\")\n",
    "    print(\"开始执行命令，实时日志如下：\\n\")\n",
    "    \n",
    "    try:\n",
    "        # 设置环境变量\n",
    "        env = dict(os.environ)\n",
    "        env[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "        \n",
    "        # 执行命令并实时输出日志\n",
    "        process = subprocess.Popen(\n",
    "            command_list,\n",
    "            env=env,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.STDOUT,\n",
    "            text=True,\n",
    "            bufsize=1  # 行缓冲\n",
    "        )\n",
    "        \n",
    "        # 实时读取并打印输出\n",
    "        for line in process.stdout:\n",
    "            print(line, end='')  # end='' 避免重复换行\n",
    "            sys.stdout.flush()  # 强制刷新输出缓冲区\n",
    "            \n",
    "        # 等待进程完成并获取返回码\n",
    "        return_code = process.wait()\n",
    "        if return_code != 0:\n",
    "            raise subprocess.CalledProcessError(return_code, command_list)\n",
    "        \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"\\n\\n命令执行出错，返回码: {e.returncode}\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"\\n\\n发生异常: {e}\")\n",
    "        return\n",
    "    \n",
    "    # 记录结束时间\n",
    "    end_time = time.time()\n",
    "    print(f\"\\n\\n结束时间: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(end_time))}\")\n",
    "    \n",
    "    # 计算并输出时间差\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"总执行时间: {timedelta(seconds=int(elapsed_time))}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_swift_sft()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "310ca65c-1fcd-453e-9177-b8667f4d3bd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T00:23:29.602793Z",
     "iopub.status.busy": "2025-09-28T00:23:29.602387Z",
     "iopub.status.idle": "2025-09-28T06:08:50.576060Z",
     "shell.execute_reply": "2025-09-28T06:08:50.575595Z",
     "shell.execute_reply.started": "2025-09-28T00:23:29.602764Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.cloud.aliyuncs.com/pypi/simple\n",
      "Collecting git+https://github.com/mobiusml/hqq.git\n",
      "  Cloning https://github.com/mobiusml/hqq.git to /tmp/pip-req-build-ws2tglxr\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/mobiusml/hqq.git /tmp/pip-req-build-ws2tglxr\n",
      "  Resolved https://github.com/mobiusml/hqq.git to commit 595e5cf665d8632f2f8f59493a3a8f17f6de897d\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.11/site-packages (from hqq==0.2.8) (1.26.4)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.11/site-packages (from hqq==0.2.8) (4.67.1)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.11/site-packages (from hqq==0.2.8) (0.8.1)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/site-packages (from hqq==0.2.8) (1.10.0)\n",
      "Requirement already satisfied: transformers>=4.36.1 in /usr/local/lib/python3.11/site-packages (from hqq==0.2.8) (4.55.2)\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/site-packages (from hqq==0.2.8) (0.34.4)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/site-packages (from hqq==0.2.8) (2.5.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from transformers>=4.36.1->hqq==0.2.8) (3.17.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/site-packages (from transformers>=4.36.1->hqq==0.2.8) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/site-packages (from transformers>=4.36.1->hqq==0.2.8) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/site-packages (from transformers>=4.36.1->hqq==0.2.8) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (from transformers>=4.36.1->hqq==0.2.8) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/site-packages (from transformers>=4.36.1->hqq==0.2.8) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/site-packages (from transformers>=4.36.1->hqq==0.2.8) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/site-packages (from huggingface_hub->hqq==0.2.8) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/site-packages (from huggingface_hub->hqq==0.2.8) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/site-packages (from huggingface_hub->hqq==0.2.8) (1.1.7)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/site-packages (from accelerate->hqq==0.2.8) (7.0.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/site-packages (from accelerate->hqq==0.2.8) (2.3.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->hqq==0.2.8) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->hqq==0.2.8) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->hqq==0.2.8) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->hqq==0.2.8) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->hqq==0.2.8) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->hqq==0.2.8) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->hqq==0.2.8) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->hqq==0.2.8) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->hqq==0.2.8) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->hqq==0.2.8) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->hqq==0.2.8) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->hqq==0.2.8) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->hqq==0.2.8) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->hqq==0.2.8) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.11/site-packages (from torch>=2.0.0->accelerate->hqq==0.2.8) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->accelerate->hqq==0.2.8) (12.8.93)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests->transformers>=4.36.1->hqq==0.2.8) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests->transformers>=4.36.1->hqq==0.2.8) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests->transformers>=4.36.1->hqq==0.2.8) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests->transformers>=4.36.1->hqq==0.2.8) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate->hqq==0.2.8) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/site-packages (from sympy->torch>=2.0.0->accelerate->hqq==0.2.8) (1.3.0)\n",
      "Building wheels for collected packages: hqq\n",
      "  Building wheel for hqq (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for hqq: filename=hqq-0.2.8-py3-none-any.whl size=68442 sha256=7d500b7d9b60200cfb74d7b92b88117223a5966016882a940558f6ec6628ea95\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-w4jfop4a/wheels/c8/7f/00/83a16645b26e30bab00c1d4ce0a17d6b472d8122a55cd47b36\n",
      "Successfully built hqq\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.7.7 has a non-standard dependency specifier torch>=1.9.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: hqq\n",
      "Successfully installed hqq-0.2.8\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "开始时间: 2025-09-28 08:23:45\n",
      "\n",
      "即将执行的命令:\n",
      "CUDA_VISIBLE_DEVICES=0 swift sft --model Qwen/Qwen2.5-7B-Instruct --train_type lora --dataset /mnt/workspace/final_data/train.json --torch_dtype bfloat16 --quant_method hqq --quant_bits 4 --num_train_epochs 1 --per_device_train_batch_size 2 --per_device_eval_batch_size 1 --learning_rate 1e-4 --lora_rank 8 --lora_alpha 32 --gradient_accumulation_steps 16 --eval_steps 50 --save_steps 50 --save_total_limit 2 --logging_steps 5 --max_length 1024 --output_dir output --system You are a helpful assistant. --warmup_ratio 0.05 --dataloader_num_workers 4 --model_author swift --model_name swift-robot\n",
      "\n",
      "开始执行命令，实时日志如下：\n",
      "\n",
      "run sh: `/usr/local/bin/python /usr/local/lib/python3.11/site-packages/swift/cli/sft.py --model Qwen/Qwen2.5-7B-Instruct --train_type lora --dataset /mnt/workspace/final_data/train.json --torch_dtype bfloat16 --quant_method hqq --quant_bits 4 --num_train_epochs 1 --per_device_train_batch_size 2 --per_device_eval_batch_size 1 --learning_rate 1e-4 --lora_rank 8 --lora_alpha 32 --gradient_accumulation_steps 16 --eval_steps 50 --save_steps 50 --save_total_limit 2 --logging_steps 5 --max_length 1024 --output_dir output --system You are a helpful assistant. --warmup_ratio 0.05 --dataloader_num_workers 4 --model_author swift --model_name swift-robot`\n",
      "2025-09-28 08:23:55.583512: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-28 08:23:56.082329: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-28 08:23:57.339480: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "[INFO:swift] Successfully registered `/usr/local/lib/python3.11/site-packages/swift/llm/dataset/data/dataset_info.json`.\n",
      "[INFO:swift] rank: -1, local_rank: -1, world_size: 1, local_world_size: 1\n",
      "[INFO:swift] Downloading the model from ModelScope Hub, model_id: Qwen/Qwen2.5-7B-Instruct\n",
      "[INFO:modelscope] Target directory already exists, skipping creation.\n",
      "[INFO:swift] Loading the model using model_dir: /mnt/workspace/.cache/modelscope/models/Qwen/Qwen2___5-7B-Instruct\n",
      "[INFO:swift] Setting args.lazy_tokenize: False\n",
      "[INFO:swift] output_dir: /mnt/workspace/output/v12-20250928-082402\n",
      "[INFO:swift] Global seed set to 42\n",
      "[INFO:swift] args: TrainArguments(\n",
      "_n_gpu=-1,\n",
      "acc_strategy=token,\n",
      "accelerator_config={'dispatch_batches': False},\n",
      "adafactor=False,\n",
      "adalora_beta1=0.85,\n",
      "adalora_beta2=0.85,\n",
      "adalora_deltaT=1,\n",
      "adalora_init_r=12,\n",
      "adalora_orth_reg_weight=0.5,\n",
      "adalora_target_r=8,\n",
      "adalora_tfinal=0,\n",
      "adalora_tinit=0,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.95,\n",
      "adam_epsilon=1e-08,\n",
      "adapter_act=gelu,\n",
      "adapter_length=128,\n",
      "adapters=[],\n",
      "add_version=True,\n",
      "agent_template=None,\n",
      "aligner_lr=None,\n",
      "attn_impl=None,\n",
      "auto_find_batch_size=False,\n",
      "average_tokens_across_devices=True,\n",
      "batch_eval_metrics=False,\n",
      "bf16=True,\n",
      "bf16_full_eval=False,\n",
      "bnb_4bit_compute_dtype=torch.bfloat16,\n",
      "bnb_4bit_quant_storage=None,\n",
      "bnb_4bit_quant_type=nf4,\n",
      "bnb_4bit_use_double_quant=True,\n",
      "boft_block_num=0,\n",
      "boft_block_size=4,\n",
      "boft_dropout=0.0,\n",
      "boft_n_butterfly_factor=1,\n",
      "cached_dataset=[],\n",
      "channels=None,\n",
      "check_model=True,\n",
      "ckpt_dir=None,\n",
      "columns={},\n",
      "create_checkpoint_symlink=False,\n",
      "custom_dataset_info=[],\n",
      "custom_register_path=[],\n",
      "data_seed=42,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=4,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_prefetch_factor=None,\n",
      "dataset=['/mnt/workspace/final_data/train.json'],\n",
      "dataset_num_proc=1,\n",
      "dataset_shuffle=True,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=18000000,\n",
      "debug=None,\n",
      "deepspeed=None,\n",
      "deepspeed_autotp_size=None,\n",
      "device_map=None,\n",
      "disable_tqdm=None,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "download_mode=reuse_dataset_if_exists,\n",
      "ds3_gather_for_generation=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_dataset=[],\n",
      "eval_dataset_args=None,\n",
      "eval_delay=0,\n",
      "eval_do_concat_batches=True,\n",
      "eval_generation_config=None,\n",
      "eval_limit=None,\n",
      "eval_on_start=False,\n",
      "eval_steps=50.0,\n",
      "eval_strategy=no,\n",
      "eval_use_evalscope=False,\n",
      "eval_use_gather_object=False,\n",
      "external_plugins=[],\n",
      "fourier_n_frequency=2000,\n",
      "fourier_scaling=300.0,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "freeze_aligner=True,\n",
      "freeze_llm=False,\n",
      "freeze_parameters=[],\n",
      "freeze_parameters_ratio=0.0,\n",
      "freeze_parameters_regex=None,\n",
      "freeze_vit=True,\n",
      "fsdp=,\n",
      "fsdp_config=None,\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "galore_cos_threshold=0.4,\n",
      "galore_gamma_proj=2,\n",
      "galore_optim_per_parameter=False,\n",
      "galore_proj_bits=4,\n",
      "galore_proj_group_size=256,\n",
      "galore_proj_quant=False,\n",
      "galore_proj_type=std,\n",
      "galore_quantization=False,\n",
      "galore_queue_size=5,\n",
      "galore_rank=128,\n",
      "galore_scale=1.0,\n",
      "galore_target_modules=None,\n",
      "galore_update_proj_gap=50,\n",
      "galore_with_embedding=False,\n",
      "generation_config=None,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=16,\n",
      "gradient_checkpointing=True,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=False,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hqq_axis=None,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=None,\n",
      "hub_revision=None,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_args_error=False,\n",
      "ignore_data_skip=False,\n",
      "include_for_metrics=[],\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "init_strategy=None,\n",
      "init_weights=True,\n",
      "interleave_prob=None,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "lazy_tokenize=False,\n",
      "learning_rate=0.0001,\n",
      "length_column_name=length,\n",
      "liger_kernel_config=None,\n",
      "lisa_activated_layers=0,\n",
      "lisa_step_interval=20,\n",
      "llamapro_num_groups=None,\n",
      "llamapro_num_new_blocks=4,\n",
      "load_args=False,\n",
      "load_best_model_at_end=False,\n",
      "load_data_args=False,\n",
      "load_from_cache_file=True,\n",
      "local_rank=-1,\n",
      "local_repo_path=None,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/mnt/workspace/output/v12-20250928-082402/runs,\n",
      "logging_first_step=True,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=5,\n",
      "logging_strategy=steps,\n",
      "logprobs=False,\n",
      "lora_alpha=32,\n",
      "lora_bias=none,\n",
      "lora_dropout=0.05,\n",
      "lora_dtype=None,\n",
      "lora_ga_batch_size=2,\n",
      "lora_ga_direction=ArB2r,\n",
      "lora_ga_iters=2,\n",
      "lora_ga_max_length=1024,\n",
      "lora_ga_scale=stable,\n",
      "lora_ga_stable_gamma=16,\n",
      "lora_modules=[],\n",
      "lora_rank=8,\n",
      "lorap_lr_ratio=None,\n",
      "loss_scale=default,\n",
      "loss_type=None,\n",
      "lr_scheduler_kwargs=None,\n",
      "lr_scheduler_type=cosine,\n",
      "max_epochs=None,\n",
      "max_grad_norm=1.0,\n",
      "max_length=1024,\n",
      "max_memory={},\n",
      "max_model_len=None,\n",
      "max_new_tokens=64,\n",
      "max_pixels=None,\n",
      "max_steps=-1,\n",
      "metric=None,\n",
      "metric_for_best_model=loss,\n",
      "model=Qwen/Qwen2.5-7B-Instruct,\n",
      "model_author=['swift'],\n",
      "model_kwargs={},\n",
      "model_name=['swift-robot'],\n",
      "model_revision=None,\n",
      "model_type=qwen2_5,\n",
      "modules_to_save=[],\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "new_special_tokens=[],\n",
      "no_cuda=False,\n",
      "norm_bbox=None,\n",
      "num_beams=1,\n",
      "num_labels=None,\n",
      "num_train_epochs=1.0,\n",
      "optim=adamw_torch,\n",
      "optim_args=None,\n",
      "optim_target_modules=None,\n",
      "optimizer=None,\n",
      "output_dir=/mnt/workspace/output/v12-20250928-082402,\n",
      "overwrite_output_dir=False,\n",
      "packing=False,\n",
      "padding_free=False,\n",
      "padding_side=right,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=1,\n",
      "per_device_train_batch_size=2,\n",
      "predict_with_generate=False,\n",
      "prediction_loss_only=False,\n",
      "problem_type=None,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "quant_bits=4,\n",
      "quant_method=hqq,\n",
      "ray_scope=last,\n",
      "reft_args=None,\n",
      "reft_intervention_type=LoreftIntervention,\n",
      "reft_layer_key=None,\n",
      "reft_layers=None,\n",
      "reft_rank=4,\n",
      "remove_unused_columns=True,\n",
      "repetition_penalty=None,\n",
      "report_to=['tensorboard'],\n",
      "response_prefix=None,\n",
      "restore_callback_states_from_checkpoint=False,\n",
      "resume_from_checkpoint=None,\n",
      "resume_only_model=False,\n",
      "rope_scaling=None,\n",
      "router_aux_loss_coef=0.0,\n",
      "run_name=/mnt/workspace/output/v12-20250928-082402,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=50.0,\n",
      "save_strategy=steps,\n",
      "save_total_limit=2,\n",
      "seed=42,\n",
      "sequence_parallel_size=1,\n",
      "shuffle_buffer_size=1000,\n",
      "skip_memory_metrics=True,\n",
      "sortish_sampler=False,\n",
      "split_dataset_ratio=0.0,\n",
      "stop_words=[],\n",
      "stopping_strategy=first_exhausted,\n",
      "stream=False,\n",
      "streaming=False,\n",
      "strict=False,\n",
      "swanlab_exp_name=None,\n",
      "swanlab_lark_secret=None,\n",
      "swanlab_lark_webhook_url=None,\n",
      "swanlab_mode=cloud,\n",
      "swanlab_project=None,\n",
      "swanlab_token=<SWANLAB_TOKEN>,\n",
      "swanlab_workspace=None,\n",
      "system=You are a helpful assistant.,\n",
      "target_modules=['all-linear'],\n",
      "target_regex=None,\n",
      "task_type=causal_lm,\n",
      "temperature=0.0,\n",
      "template=qwen2_5,\n",
      "template_backend=swift,\n",
      "tf32=None,\n",
      "top_k=None,\n",
      "top_logprobs=None,\n",
      "top_p=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torch_dtype=torch.bfloat16,\n",
      "torch_empty_cache_steps=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "train_dataloader_shuffle=True,\n",
      "train_type=lora,\n",
      "trainable_parameters=[],\n",
      "trainable_parameters_regex=None,\n",
      "truncation_strategy=delete,\n",
      "tuner_backend=peft,\n",
      "use_chat_template=True,\n",
      "use_cpu=False,\n",
      "use_dora=False,\n",
      "use_galore=False,\n",
      "use_hf=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_liger_kernel=False,\n",
      "use_logits_to_keep=None,\n",
      "use_mps_device=False,\n",
      "use_rslora=False,\n",
      "use_swift_lora=False,\n",
      "val_dataset=[],\n",
      "val_dataset_shuffle=False,\n",
      "vera_d_initial=0.1,\n",
      "vera_dropout=0.0,\n",
      "vera_projection_prng_key=0,\n",
      "vera_rank=256,\n",
      "vit_gradient_checkpointing=None,\n",
      "vit_lr=None,\n",
      "warmup_ratio=0.05,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.1,\n",
      "zero_hpz_partition_size=None,\n",
      ")\n",
      "[INFO:swift] Downloading the model from ModelScope Hub, model_id: Qwen/Qwen2.5-7B-Instruct\n",
      "[INFO:modelscope] Target directory already exists, skipping creation.\n",
      "[INFO:swift] Loading the model using model_dir: /mnt/workspace/.cache/modelscope/models/Qwen/Qwen2___5-7B-Instruct\n",
      "[INFO:swift] model_kwargs: {'device_map': 'cuda:0', 'quantization_config': HqqConfig {\n",
      "  \"quant_config\": {\n",
      "    \"offload_meta\": false,\n",
      "    \"scale_quant_params\": null,\n",
      "    \"weight_quant_params\": {\n",
      "      \"axis\": 1,\n",
      "      \"channel_wise\": true,\n",
      "      \"group_size\": 64,\n",
      "      \"nbits\": 4,\n",
      "      \"optimize\": true,\n",
      "      \"round_zero\": true,\n",
      "      \"view_as_float\": false\n",
      "    },\n",
      "    \"zero_quant_params\": null\n",
      "  },\n",
      "  \"quant_method\": \"hqq\",\n",
      "  \"skip_modules\": [\n",
      "    \"lm_head\"\n",
      "  ]\n",
      "}\n",
      "}\n",
      "Downloading Model from https://www.modelscope.cn to directory: /mnt/workspace/.cache/modelscope/models/Qwen/Qwen2.5-7B-Instruct\n",
      "Downloading Model from https://www.modelscope.cn to directory: /mnt/workspace/.cache/modelscope/models/Qwen/Qwen2.5-7B-Instruct\n",
      "\n",
      "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Loading checkpoint shards:  25%|██▌       | 1/4 [00:49<02:27, 49.12s/it]\n",
      "Loading checkpoint shards:  50%|█████     | 2/4 [01:41<01:42, 51.07s/it]\n",
      "Loading checkpoint shards:  75%|███████▌  | 3/4 [02:30<00:50, 50.10s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [03:13<00:00, 47.24s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [03:13<00:00, 48.34s/it]\n",
      "[INFO:swift] model.hf_device_map: {'': device(type='cuda', index=0)}\n",
      "[INFO:swift] model_info: ModelInfo(model_type='qwen2_5', model_dir='/mnt/workspace/.cache/modelscope/models/Qwen/Qwen2___5-7B-Instruct', torch_dtype=torch.bfloat16, max_model_len=32768, quant_method=<QuantizationMethod.HQQ: 'hqq'>, quant_bits=4, rope_scaling=None, is_moe_model=False, config=Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3584,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 18944,\n",
      "  \"layer_types\": [\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\",\n",
      "    \"full_attention\"\n",
      "  ],\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 28,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 4,\n",
      "  \"pad_token_id\": 151643,\n",
      "  \"quantization_config\": {\n",
      "    \"quant_config\": {\n",
      "      \"offload_meta\": false,\n",
      "      \"scale_quant_params\": null,\n",
      "      \"weight_quant_params\": {\n",
      "        \"axis\": 1,\n",
      "        \"channel_wise\": true,\n",
      "        \"group_size\": 64,\n",
      "        \"nbits\": 4,\n",
      "        \"optimize\": true,\n",
      "        \"round_zero\": true,\n",
      "        \"view_as_float\": false\n",
      "      },\n",
      "      \"zero_quant_params\": null\n",
      "    },\n",
      "    \"quant_method\": \"hqq\",\n",
      "    \"skip_modules\": [\n",
      "      \"lm_head\"\n",
      "    ]\n",
      "  },\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.55.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 152064\n",
      "}\n",
      ", task_type='causal_lm', num_labels=None)\n",
      "[INFO:swift] model.generation_config: GenerationConfig {\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": [\n",
      "    151645,\n",
      "    151643\n",
      "  ],\n",
      "  \"max_new_tokens\": 64,\n",
      "  \"pad_token_id\": 151643,\n",
      "  \"repetition_penalty\": 1.05\n",
      "}\n",
      "\n",
      "[INFO:swift] default_system: 'You are a helpful assistant.'\n",
      "[INFO:swift] max_length: 1024\n",
      "[INFO:swift] response_prefix: ''\n",
      "[INFO:swift] agent_template: hermes\n",
      "[INFO:swift] Start time of running main: 2025-09-28 08:27:17.027966\n",
      "[INFO:swift] swift.__version__: 3.7.2\n",
      "[INFO:swift] SelfCognitionPreprocessor has been successfully configured with name: ('swift-robot', 'swift-robot'), author: ('swift', 'swift').\n",
      "\n",
      "Generating train split: 0 examples [00:00, ? examples/s]\n",
      "Generating train split: 37361 examples [00:00, 72611.47 examples/s]\n",
      "Generating train split: 37361 examples [00:00, 72514.90 examples/s]\n",
      "\n",
      "Map:   0%|          | 0/37361 [00:00<?, ? examples/s]\n",
      "Map:  24%|██▍       | 9000/37361 [00:00<00:00, 83496.06 examples/s]\n",
      "Map:  51%|█████     | 19000/37361 [00:00<00:00, 86845.83 examples/s]\n",
      "Map:  78%|███████▊  | 29000/37361 [00:00<00:00, 87191.96 examples/s]\n",
      "Map: 100%|██████████| 37361/37361 [00:00<00:00, 84293.64 examples/s]\n",
      "[INFO:swift] train_dataset: Dataset({\n",
      "    features: ['messages'],\n",
      "    num_rows: 37361\n",
      "})\n",
      "[INFO:swift] val_dataset: None\n",
      "\n",
      "Map:   0%|          | 0/37361 [00:00<?, ? examples/s][INFO:swift] Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/dataset/preprocessor/core.py\", line 183, in batched_preprocess\n",
      "    row = self.preprocess(row)\n",
      "          ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/dataset/utils.py\", line 283, in preprocess\n",
      "    encoded = self.template.encode(row, return_length=True)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/template/base.py\", line 500, in encode\n",
      "    encoded = self._encode_truncated(inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/template/base.py\", line 1209, in _encode_truncated\n",
      "    raise MaxLengthError(f'Current length of row({length}) is larger'\n",
      "swift.llm.template.base.MaxLengthError: Current length of row(1608) is larger than the max_length(1024).\n",
      "\n",
      "[WARNING:swift] 👆👆👆There are errors in the dataset, the data will be deleted\n",
      "[INFO:swift] Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/dataset/preprocessor/core.py\", line 183, in batched_preprocess\n",
      "    row = self.preprocess(row)\n",
      "          ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/dataset/utils.py\", line 283, in preprocess\n",
      "    encoded = self.template.encode(row, return_length=True)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/template/base.py\", line 500, in encode\n",
      "    encoded = self._encode_truncated(inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/template/base.py\", line 1209, in _encode_truncated\n",
      "    raise MaxLengthError(f'Current length of row({length}) is larger'\n",
      "swift.llm.template.base.MaxLengthError: Current length of row(4405) is larger than the max_length(1024).\n",
      "\n",
      "[WARNING:swift] 👆👆👆There are errors in the dataset, the data will be deleted\n",
      "[INFO:swift] Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/dataset/preprocessor/core.py\", line 183, in batched_preprocess\n",
      "    row = self.preprocess(row)\n",
      "          ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/dataset/utils.py\", line 283, in preprocess\n",
      "    encoded = self.template.encode(row, return_length=True)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/template/base.py\", line 500, in encode\n",
      "    encoded = self._encode_truncated(inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/template/base.py\", line 1209, in _encode_truncated\n",
      "    raise MaxLengthError(f'Current length of row({length}) is larger'\n",
      "swift.llm.template.base.MaxLengthError: Current length of row(1133) is larger than the max_length(1024).\n",
      "\n",
      "[WARNING:swift] 👆👆👆There are errors in the dataset, the data will be deleted\n",
      "\n",
      "Map:   3%|▎         | 1000/37361 [00:00<00:25, 1435.76 examples/s][INFO:swift] Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/dataset/preprocessor/core.py\", line 183, in batched_preprocess\n",
      "    row = self.preprocess(row)\n",
      "          ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/dataset/utils.py\", line 283, in preprocess\n",
      "    encoded = self.template.encode(row, return_length=True)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/template/base.py\", line 500, in encode\n",
      "    encoded = self._encode_truncated(inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/template/base.py\", line 1209, in _encode_truncated\n",
      "    raise MaxLengthError(f'Current length of row({length}) is larger'\n",
      "swift.llm.template.base.MaxLengthError: Current length of row(1078) is larger than the max_length(1024).\n",
      "\n",
      "[WARNING:swift] 👆👆👆There are errors in the dataset, the data will be deleted\n",
      "[INFO:swift] Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/dataset/preprocessor/core.py\", line 183, in batched_preprocess\n",
      "    row = self.preprocess(row)\n",
      "          ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/dataset/utils.py\", line 283, in preprocess\n",
      "    encoded = self.template.encode(row, return_length=True)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/template/base.py\", line 500, in encode\n",
      "    encoded = self._encode_truncated(inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/template/base.py\", line 1209, in _encode_truncated\n",
      "    raise MaxLengthError(f'Current length of row({length}) is larger'\n",
      "swift.llm.template.base.MaxLengthError: Current length of row(2218) is larger than the max_length(1024).\n",
      "\n",
      "[WARNING:swift] 👆👆👆There are errors in the dataset, the data will be deleted\n",
      "[INFO:swift] Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/dataset/preprocessor/core.py\", line 183, in batched_preprocess\n",
      "    row = self.preprocess(row)\n",
      "          ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/dataset/utils.py\", line 283, in preprocess\n",
      "    encoded = self.template.encode(row, return_length=True)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/template/base.py\", line 500, in encode\n",
      "    encoded = self._encode_truncated(inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/template/base.py\", line 1209, in _encode_truncated\n",
      "    raise MaxLengthError(f'Current length of row({length}) is larger'\n",
      "swift.llm.template.base.MaxLengthError: Current length of row(3702) is larger than the max_length(1024).\n",
      "\n",
      "[WARNING:swift] 👆👆👆There are errors in the dataset, the data will be deleted\n",
      "[INFO:swift] Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/dataset/preprocessor/core.py\", line 183, in batched_preprocess\n",
      "    row = self.preprocess(row)\n",
      "          ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/dataset/utils.py\", line 283, in preprocess\n",
      "    encoded = self.template.encode(row, return_length=True)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/template/base.py\", line 500, in encode\n",
      "    encoded = self._encode_truncated(inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/template/base.py\", line 1209, in _encode_truncated\n",
      "    raise MaxLengthError(f'Current length of row({length}) is larger'\n",
      "swift.llm.template.base.MaxLengthError: Current length of row(1223) is larger than the max_length(1024).\n",
      "\n",
      "[WARNING:swift] 👆👆👆There are errors in the dataset, the data will be deleted\n",
      "[INFO:swift] Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/dataset/preprocessor/core.py\", line 183, in batched_preprocess\n",
      "    row = self.preprocess(row)\n",
      "          ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/dataset/utils.py\", line 283, in preprocess\n",
      "    encoded = self.template.encode(row, return_length=True)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/template/base.py\", line 500, in encode\n",
      "    encoded = self._encode_truncated(inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/template/base.py\", line 1209, in _encode_truncated\n",
      "    raise MaxLengthError(f'Current length of row({length}) is larger'\n",
      "swift.llm.template.base.MaxLengthError: Current length of row(3340) is larger than the max_length(1024).\n",
      "\n",
      "[WARNING:swift] 👆👆👆There are errors in the dataset, the data will be deleted\n",
      "\n",
      "Map:   5%|▌         | 2000/37361 [00:01<00:24, 1432.28 examples/s][INFO:swift] Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/dataset/preprocessor/core.py\", line 183, in batched_preprocess\n",
      "    row = self.preprocess(row)\n",
      "          ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/dataset/utils.py\", line 283, in preprocess\n",
      "    encoded = self.template.encode(row, return_length=True)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/template/base.py\", line 500, in encode\n",
      "    encoded = self._encode_truncated(inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/template/base.py\", line 1209, in _encode_truncated\n",
      "    raise MaxLengthError(f'Current length of row({length}) is larger'\n",
      "swift.llm.template.base.MaxLengthError: Current length of row(1263) is larger than the max_length(1024).\n",
      "\n",
      "[WARNING:swift] 👆👆👆There are errors in the dataset, the data will be deleted\n",
      "[INFO:swift] Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/dataset/preprocessor/core.py\", line 183, in batched_preprocess\n",
      "    row = self.preprocess(row)\n",
      "          ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/dataset/utils.py\", line 283, in preprocess\n",
      "    encoded = self.template.encode(row, return_length=True)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/template/base.py\", line 500, in encode\n",
      "    encoded = self._encode_truncated(inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/site-packages/swift/llm/template/base.py\", line 1209, in _encode_truncated\n",
      "    raise MaxLengthError(f'Current length of row({length}) is larger'\n",
      "swift.llm.template.base.MaxLengthError: Current length of row(2641) is larger than the max_length(1024).\n",
      "\n",
      "[WARNING:swift] 👆👆👆There are errors in the dataset, the data will be deleted\n",
      "\n",
      "Map:   8%|▊         | 3000/37361 [00:02<00:24, 1408.14 examples/s]\n",
      "Map:  11%|█         | 4000/37361 [00:02<00:23, 1417.41 examples/s]\n",
      "Map:  13%|█▎        | 5000/37361 [00:03<00:22, 1432.65 examples/s]\n",
      "Map:  16%|█▌        | 6000/37361 [00:04<00:21, 1459.87 examples/s]\n",
      "Map:  19%|█▊        | 7000/37361 [00:04<00:20, 1473.52 examples/s]\n",
      "Map:  21%|██▏       | 8000/37361 [00:05<00:19, 1477.66 examples/s]\n",
      "Map:  24%|██▍       | 9000/37361 [00:06<00:19, 1480.36 examples/s]\n",
      "Map:  27%|██▋       | 10000/37361 [00:06<00:18, 1464.55 examples/s]\n",
      "Map:  29%|██▉       | 11000/37361 [00:07<00:17, 1470.89 examples/s]\n",
      "Map:  32%|███▏      | 12000/37361 [00:08<00:17, 1465.26 examples/s]\n",
      "Map:  35%|███▍      | 13000/37361 [00:08<00:16, 1464.65 examples/s]\n",
      "Map:  37%|███▋      | 14000/37361 [00:09<00:15, 1469.71 examples/s]\n",
      "Map:  40%|████      | 15000/37361 [00:10<00:15, 1463.01 examples/s]\n",
      "Map:  43%|████▎     | 16000/37361 [00:11<00:14, 1437.75 examples/s]\n",
      "Map:  46%|████▌     | 17000/37361 [00:11<00:14, 1432.31 examples/s]\n",
      "Map:  48%|████▊     | 18000/37361 [00:12<00:13, 1449.33 examples/s]\n",
      "Map:  51%|█████     | 19000/37361 [00:13<00:13, 1319.92 examples/s]\n",
      "Map:  54%|█████▎    | 20000/37361 [00:13<00:12, 1353.09 examples/s]\n",
      "Map:  56%|█████▌    | 21000/37361 [00:14<00:11, 1398.36 examples/s]\n",
      "Map:  59%|█████▉    | 22000/37361 [00:15<00:10, 1417.30 examples/s]\n",
      "Map:  62%|██████▏   | 23000/37361 [00:16<00:10, 1430.68 examples/s]\n",
      "Map:  64%|██████▍   | 24000/37361 [00:16<00:09, 1431.00 examples/s]\n",
      "Map:  67%|██████▋   | 25000/37361 [00:17<00:08, 1429.63 examples/s]\n",
      "Map:  70%|██████▉   | 26000/37361 [00:18<00:07, 1437.96 examples/s]\n",
      "Map:  72%|███████▏  | 27000/37361 [00:18<00:07, 1460.86 examples/s]\n",
      "Map:  75%|███████▍  | 28000/37361 [00:19<00:06, 1471.27 examples/s]\n",
      "Map:  78%|███████▊  | 29000/37361 [00:20<00:05, 1480.29 examples/s]\n",
      "Map:  80%|████████  | 30000/37361 [00:20<00:05, 1453.02 examples/s]\n",
      "Map:  83%|████████▎ | 31000/37361 [00:21<00:04, 1446.42 examples/s]\n",
      "Map:  86%|████████▌ | 32000/37361 [00:22<00:03, 1415.15 examples/s]\n",
      "Map:  88%|████████▊ | 33000/37361 [00:22<00:03, 1414.80 examples/s]\n",
      "Map:  91%|█████████ | 34000/37361 [00:23<00:02, 1428.54 examples/s]\n",
      "Map:  94%|█████████▎| 35000/37361 [00:24<00:01, 1424.25 examples/s]\n",
      "Map:  96%|█████████▋| 36000/37361 [00:25<00:00, 1439.67 examples/s]\n",
      "Map:  99%|█████████▉| 37000/37361 [00:25<00:00, 1444.67 examples/s]\n",
      "Map: 100%|██████████| 37361/37361 [00:25<00:00, 1446.11 examples/s]\n",
      "Map: 100%|██████████| 37361/37361 [00:26<00:00, 1433.46 examples/s]\n",
      "[INFO:swift] Dataset filtered, origin length: 37361, filtered dataset length: 37186\n",
      "[INFO:swift] [INPUT_IDS] [151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 99601, 56568, 101909, 106045, 104391, 103998, 37945, 100345, 101924, 103936, 107485, 99912, 9370, 100182, 101898, 28311, 70108, 3837, 19, 16, 92015, 3837, 91777, 20412, 100347, 99389, 102395, 102072, 3837, 104373, 85336, 101071, 106012, 101743, 120449, 100575, 37945, 56007, 18830, 101743, 120449, 100575, 105184, 101368, 20412, 99387, 100535, 151645, 198, 151644, 77091, 198, 101743, 120449, 100575, 73670, 110966, 42192, 100406, 99389, 102395, 3837, 104047, 18830, 102395, 64952, 102395, 99508, 102395, 100406, 101368, 3837, 103929, 101368, 102410, 20412, 102395, 45995, 101304, 100631, 113801, 3837, 101898, 56568, 112189, 99190, 102395, 106307, 33108, 99414, 71304, 104857, 101071, 3837, 114671, 113422, 87256, 71817, 101899, 1773, 99604, 113422, 100771, 101970, 101368, 3837, 101924, 85106, 100345, 101960, 106141, 104883, 26939, 105327, 44991, 100043, 100634, 71817, 72448, 101931, 9370, 101071, 3837, 109095, 32664, 99769, 101899, 1773, 104043, 101924, 101254, 85106, 104466, 118681, 5373, 101906, 99287, 100718, 114331, 99257, 5373, 101254, 104579, 108851, 116283, 101474, 64272, 106232, 5373, 100259, 107663, 33108, 42140, 100399, 103265, 1773, 151645]\n",
      "[INFO:swift] [INPUT] <|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "现在你是一个肿瘤学科医生，请根据患者的问题给出实际的医疗建议：\n",
      "男，41岁，老是出现血尿的情况，昨天去检查说是膀胱癌，请问有膀胱癌早期症状是怎样的<|im_end|>\n",
      "<|im_start|>assistant\n",
      "膀胱癌可以表现为无痛血尿，也可以有尿频尿急尿痛症状，你的症状有可能是尿路感染或者结石，建议你去医院做尿常规和彩超仔细检查，查明病因再进行治疗。不同病因引起不同的症状，患者需要根据自身病情尽快到正规三甲医院进行系统规范的检查，这样才能对症治疗。此外患者日常需要规律作息、做好防寒保暖工作、日常饮食多吃清淡稀软的食物、勤通风和多喝热水。<|im_end|>\n",
      "[INFO:swift] [LABELS_IDS] [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 101743, 120449, 100575, 73670, 110966, 42192, 100406, 99389, 102395, 3837, 104047, 18830, 102395, 64952, 102395, 99508, 102395, 100406, 101368, 3837, 103929, 101368, 102410, 20412, 102395, 45995, 101304, 100631, 113801, 3837, 101898, 56568, 112189, 99190, 102395, 106307, 33108, 99414, 71304, 104857, 101071, 3837, 114671, 113422, 87256, 71817, 101899, 1773, 99604, 113422, 100771, 101970, 101368, 3837, 101924, 85106, 100345, 101960, 106141, 104883, 26939, 105327, 44991, 100043, 100634, 71817, 72448, 101931, 9370, 101071, 3837, 109095, 32664, 99769, 101899, 1773, 104043, 101924, 101254, 85106, 104466, 118681, 5373, 101906, 99287, 100718, 114331, 99257, 5373, 101254, 104579, 108851, 116283, 101474, 64272, 106232, 5373, 100259, 107663, 33108, 42140, 100399, 103265, 1773, 151645]\n",
      "[INFO:swift] [LABELS] [-100 * 66]膀胱癌可以表现为无痛血尿，也可以有尿频尿急尿痛症状，你的症状有可能是尿路感染或者结石，建议你去医院做尿常规和彩超仔细检查，查明病因再进行治疗。不同病因引起不同的症状，患者需要根据自身病情尽快到正规三甲医院进行系统规范的检查，这样才能对症治疗。此外患者日常需要规律作息、做好防寒保暖工作、日常饮食多吃清淡稀软的食物、勤通风和多喝热水。<|im_end|>\n",
      "[INFO:swift] Dataset Token Length: 190.039477±81.113077, min=47.000000, max=1019.000000, size=37186\n",
      "[INFO:swift] The TrainArguments will be saved in: /mnt/workspace/output/v12-20250928-082402/args.json\n",
      "/usr/local/lib/python3.11/site-packages/awq/__init__.py:21: DeprecationWarning: \n",
      "I have left this message as the final dev message to help you transition.\n",
      "\n",
      "Important Notice:\n",
      "- AutoAWQ is officially deprecated and will no longer be maintained.\n",
      "- The last tested configuration used Torch 2.6.0 and Transformers 4.51.3.\n",
      "- If future versions of Transformers break AutoAWQ compatibility, please report the issue to the Transformers project.\n",
      "\n",
      "Alternative:\n",
      "- AutoAWQ has been adopted by the vLLM Project: https://github.com/vllm-project/llm-compressor\n",
      "\n",
      "For further inquiries, feel free to reach out:\n",
      "- X: https://x.com/casper_hansen_\n",
      "- LinkedIn: https://www.linkedin.com/in/casper-hansen-804005170/\n",
      "\n",
      "  warnings.warn(_FINAL_DEV_MESSAGE, category=DeprecationWarning, stacklevel=1)\n",
      "[INFO:swift] lora_config: LoraConfig(task_type='CAUSAL_LM', peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='/mnt/workspace/.cache/modelscope/models/Qwen/Qwen2___5-7B-Instruct', revision=None, inference_mode=False, r=8, target_modules={'v_proj', 'k_proj', 'down_proj', 'o_proj', 'q_proj', 'up_proj', 'gate_proj'}, exclude_modules=None, lora_alpha=32, lora_dropout=0.05, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=[], init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', trainable_token_indices=None, loftq_config={}, eva_config=None, corda_config=None, use_dora=False, use_qalora=False, qalora_group_size=16, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False), lora_bias=False, target_parameters=None, lora_dtype=None, lorap_lr_ratio=None, lorap_emb_lr=1e-06)\n",
      "[INFO:swift] model: PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): Qwen2ForCausalLM(\n",
      "      (model): Qwen2Model(\n",
      "        (embed_tokens): Embedding(152064, 3584)\n",
      "        (layers): ModuleList(\n",
      "          (0-27): 28 x Qwen2DecoderLayer(\n",
      "            (self_attn): Qwen2Attention(\n",
      "              (q_proj): lora.HqqLoraLinear(\n",
      "                (base_layer): HQQLinear(in_features=3584, out_features=3584, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=3584, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (k_proj): lora.HqqLoraLinear(\n",
      "                (base_layer): HQQLinear(in_features=3584, out_features=512, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=512, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (v_proj): lora.HqqLoraLinear(\n",
      "                (base_layer): HQQLinear(in_features=3584, out_features=512, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=512, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (o_proj): lora.HqqLoraLinear(\n",
      "                (base_layer): HQQLinear(in_features=3584, out_features=3584, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=3584, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "            )\n",
      "            (mlp): Qwen2MLP(\n",
      "              (gate_proj): lora.HqqLoraLinear(\n",
      "                (base_layer): HQQLinear(in_features=3584, out_features=18944, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=18944, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (up_proj): lora.HqqLoraLinear(\n",
      "                (base_layer): HQQLinear(in_features=3584, out_features=18944, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=3584, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=18944, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (down_proj): lora.HqqLoraLinear(\n",
      "                (base_layer): HQQLinear(in_features=18944, out_features=3584, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=18944, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=3584, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "            (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "          )\n",
      "        )\n",
      "        (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "        (rotary_emb): Qwen2RotaryEmbedding()\n",
      "      )\n",
      "      (lm_head): Linear(in_features=3584, out_features=152064, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[INFO:swift] model_parameter_info: PeftModelForCausalLM: 4373.1574M Params (20.1851M Trainable [0.4616%]), 0.0001M Buffers.\n",
      "/usr/local/lib/python3.11/site-packages/swift/trainers/mixin.py:94: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(\n",
      "/usr/local/lib/python3.11/site-packages/deepspeed/ops/op_builder/builder.py:18: DeprecationWarning: The distutils.sysconfig module is deprecated, use sysconfig instead\n",
      "  import distutils.sysconfig\n",
      "[2025-09-28 08:27:46,406] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "df: /root/.triton/autotune: 没有那个文件或目录\n",
      "[2025-09-28 08:27:47,974] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\n",
      "[INFO:swift] use_reentrant: True\n",
      "[INFO:swift] The logging file will be saved in: /mnt/workspace/output/v12-20250928-082402/logging.jsonl\n",
      "\n",
      "Train:   0%|          | 0/1163 [00:00<?, ?it/s][INFO:swift] use_logits_to_keep: True\n",
      "\n",
      "Train:   0%|          | 1/1163 [00:18<6:05:39, 18.88s/it]\n",
      "                                                         \n",
      "\n",
      "Train:   0%|          | 1/1163 [00:18<6:05:39, 18.88s/it]\n",
      "Train:   0%|          | 1/1163 [00:18<6:05:39, 18.88s/it]\n",
      "Train:   0%|          | 2/1163 [00:36<5:50:04, 18.09s/it]\n",
      "Train:   0%|          | 3/1163 [00:54<5:49:20, 18.07s/it]\n",
      "Train:   0%|          | 4/1163 [01:11<5:40:09, 17.61s/it]\n",
      "Train:   0%|          | 5/1163 [01:28<5:37:33, 17.49s/it]\n",
      "                                                         \n",
      "\n",
      "Train:   0%|          | 5/1163 [01:28<5:37:33, 17.49s/it]\n",
      "Train:   0%|          | 5/1163 [01:28<5:37:33, 17.49s/it]\n",
      "Train:   1%|          | 6/1163 [01:46<5:37:14, 17.49s/it]\n",
      "Train:   1%|          | 7/1163 [02:03<5:36:04, 17.44s/it]\n",
      "Train:   1%|          | 8/1163 [02:21<5:37:09, 17.51s/it]\n",
      "Train:   1%|          | 9/1163 [02:39<5:40:05, 17.68s/it]\n",
      "Train:   1%|          | 10/1163 [02:56<5:39:03, 17.64s/it]\n",
      "                                                          \n",
      "\n",
      "Train:   1%|          | 10/1163 [02:56<5:39:03, 17.64s/it]\n",
      "Train:   1%|          | 10/1163 [02:56<5:39:03, 17.64s/it]\n",
      "Train:   1%|          | 11/1163 [03:14<5:39:49, 17.70s/it]\n",
      "Train:   1%|          | 12/1163 [03:32<5:39:27, 17.70s/it]\n",
      "Train:   1%|          | 13/1163 [03:50<5:45:04, 18.00s/it]\n",
      "Train:   1%|          | 14/1163 [04:08<5:43:42, 17.95s/it]\n",
      "Train:   1%|▏         | 15/1163 [04:26<5:39:46, 17.76s/it]\n",
      "                                                          \n",
      "\n",
      "Train:   1%|▏         | 15/1163 [04:26<5:39:46, 17.76s/it]\n",
      "Train:   1%|▏         | 15/1163 [04:26<5:39:46, 17.76s/it]\n",
      "Train:   1%|▏         | 16/1163 [04:43<5:35:49, 17.57s/it]\n",
      "Train:   1%|▏         | 17/1163 [05:01<5:39:34, 17.78s/it]\n",
      "Train:   2%|▏         | 18/1163 [05:19<5:40:28, 17.84s/it]\n",
      "Train:   2%|▏         | 19/1163 [05:36<5:34:22, 17.54s/it]\n",
      "Train:   2%|▏         | 20/1163 [05:53<5:32:04, 17.43s/it]\n",
      "                                                          \n",
      "\n",
      "Train:   2%|▏         | 20/1163 [05:53<5:32:04, 17.43s/it]\n",
      "Train:   2%|▏         | 20/1163 [05:53<5:32:04, 17.43s/it]\n",
      "Train:   2%|▏         | 21/1163 [06:11<5:34:27, 17.57s/it]\n",
      "Train:   2%|▏         | 22/1163 [06:29<5:35:23, 17.64s/it]\n",
      "Train:   2%|▏         | 23/1163 [06:45<5:29:56, 17.37s/it]\n",
      "Train:   2%|▏         | 24/1163 [07:03<5:28:38, 17.31s/it]\n",
      "Train:   2%|▏         | 25/1163 [07:20<5:26:13, 17.20s/it]\n",
      "                                                          \n",
      "\n",
      "Train:   2%|▏         | 25/1163 [07:20<5:26:13, 17.20s/it]\n",
      "Train:   2%|▏         | 25/1163 [07:20<5:26:13, 17.20s/it]\n",
      "Train:   2%|▏         | 26/1163 [07:36<5:23:43, 17.08s/it]\n",
      "Train:   2%|▏         | 27/1163 [07:55<5:31:52, 17.53s/it]\n",
      "Train:   2%|▏         | 28/1163 [08:14<5:39:03, 17.92s/it]\n",
      "Train:   2%|▏         | 29/1163 [08:31<5:34:30, 17.70s/it]\n",
      "Train:   3%|▎         | 30/1163 [08:50<5:41:52, 18.10s/it]\n",
      "                                                          \n",
      "\n",
      "Train:   3%|▎         | 30/1163 [08:50<5:41:52, 18.10s/it]\n",
      "Train:   3%|▎         | 30/1163 [08:50<5:41:52, 18.10s/it]\n",
      "Train:   3%|▎         | 31/1163 [09:07<5:34:08, 17.71s/it]\n",
      "Train:   3%|▎         | 32/1163 [09:24<5:28:45, 17.44s/it]\n",
      "Train:   3%|▎         | 33/1163 [09:41<5:26:13, 17.32s/it]\n",
      "Train:   3%|▎         | 34/1163 [09:57<5:21:44, 17.10s/it]\n",
      "Train:   3%|▎         | 35/1163 [10:14<5:20:55, 17.07s/it]\n",
      "                                                          \n",
      "\n",
      "Train:   3%|▎         | 35/1163 [10:14<5:20:55, 17.07s/it]\n",
      "Train:   3%|▎         | 35/1163 [10:14<5:20:55, 17.07s/it]\n",
      "Train:   3%|▎         | 36/1163 [10:32<5:22:34, 17.17s/it]\n",
      "Train:   3%|▎         | 37/1163 [10:49<5:24:12, 17.28s/it]\n",
      "Train:   3%|▎         | 38/1163 [11:07<5:26:08, 17.39s/it]\n",
      "Train:   3%|▎         | 39/1163 [11:24<5:25:57, 17.40s/it]\n",
      "Train:   3%|▎         | 40/1163 [11:43<5:31:27, 17.71s/it]\n",
      "                                                          \n",
      "\n",
      "Train:   3%|▎         | 40/1163 [11:43<5:31:27, 17.71s/it]\n",
      "Train:   3%|▎         | 40/1163 [11:43<5:31:27, 17.71s/it]\n",
      "Train:   4%|▎         | 41/1163 [12:00<5:27:04, 17.49s/it]\n",
      "Train:   4%|▎         | 42/1163 [12:17<5:27:53, 17.55s/it]\n",
      "Train:   4%|▎         | 43/1163 [12:35<5:30:16, 17.69s/it]\n",
      "Train:   4%|▍         | 44/1163 [12:53<5:29:06, 17.65s/it]\n",
      "Train:   4%|▍         | 45/1163 [13:10<5:27:41, 17.59s/it]\n",
      "                                                          \n",
      "\n",
      "Train:   4%|▍         | 45/1163 [13:10<5:27:41, 17.59s/it]\n",
      "Train:   4%|▍         | 45/1163 [13:10<5:27:41, 17.59s/it]\n",
      "Train:   4%|▍         | 46/1163 [13:28<5:28:25, 17.64s/it]\n",
      "Train:   4%|▍         | 47/1163 [13:45<5:25:55, 17.52s/it]\n",
      "Train:   4%|▍         | 48/1163 [14:03<5:25:21, 17.51s/it]\n",
      "Train:   4%|▍         | 49/1163 [14:20<5:23:06, 17.40s/it]\n",
      "Train:   4%|▍         | 50/1163 [14:37<5:22:44, 17.40s/it]\n",
      "                                                          \n",
      "\n",
      "Train:   4%|▍         | 50/1163 [14:37<5:22:44, 17.40s/it]\n",
      "Train:   4%|▍         | 50/1163 [14:37<5:22:44, 17.40s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v12-20250928-082402/checkpoint-50\n",
      "\n",
      "Train:   4%|▍         | 51/1163 [14:57<5:32:35, 17.95s/it]\n",
      "Train:   4%|▍         | 52/1163 [15:14<5:28:56, 17.76s/it]\n",
      "Train:   5%|▍         | 53/1163 [15:31<5:25:17, 17.58s/it]\n",
      "Train:   5%|▍         | 54/1163 [15:48<5:21:34, 17.40s/it]\n",
      "Train:   5%|▍         | 55/1163 [16:05<5:20:31, 17.36s/it]\n",
      "                                                          \n",
      "\n",
      "Train:   5%|▍         | 55/1163 [16:05<5:20:31, 17.36s/it]\n",
      "Train:   5%|▍         | 55/1163 [16:05<5:20:31, 17.36s/it]\n",
      "Train:   5%|▍         | 56/1163 [16:22<5:18:44, 17.28s/it]\n",
      "Train:   5%|▍         | 57/1163 [16:41<5:24:24, 17.60s/it]\n",
      "Train:   5%|▍         | 58/1163 [16:59<5:28:29, 17.84s/it]\n",
      "Train:   5%|▌         | 59/1163 [17:16<5:23:23, 17.58s/it]\n",
      "Train:   5%|▌         | 60/1163 [17:33<5:20:06, 17.41s/it]\n",
      "                                                          \n",
      "\n",
      "Train:   5%|▌         | 60/1163 [17:33<5:20:06, 17.41s/it]\n",
      "Train:   5%|▌         | 60/1163 [17:33<5:20:06, 17.41s/it]\n",
      "Train:   5%|▌         | 61/1163 [17:50<5:18:45, 17.36s/it]\n",
      "Train:   5%|▌         | 62/1163 [18:09<5:25:30, 17.74s/it]\n",
      "Train:   5%|▌         | 63/1163 [18:26<5:22:31, 17.59s/it]\n",
      "Train:   6%|▌         | 64/1163 [18:43<5:19:09, 17.42s/it]\n",
      "Train:   6%|▌         | 65/1163 [19:01<5:18:26, 17.40s/it]\n",
      "                                                          \n",
      "\n",
      "Train:   6%|▌         | 65/1163 [19:01<5:18:26, 17.40s/it]\n",
      "Train:   6%|▌         | 65/1163 [19:01<5:18:26, 17.40s/it]\n",
      "Train:   6%|▌         | 66/1163 [19:17<5:14:53, 17.22s/it]\n",
      "Train:   6%|▌         | 67/1163 [19:35<5:14:14, 17.20s/it]\n",
      "Train:   6%|▌         | 68/1163 [19:52<5:13:03, 17.15s/it]\n",
      "Train:   6%|▌         | 69/1163 [20:10<5:20:34, 17.58s/it]\n",
      "Train:   6%|▌         | 70/1163 [20:28<5:19:22, 17.53s/it]\n",
      "                                                          \n",
      "\n",
      "Train:   6%|▌         | 70/1163 [20:28<5:19:22, 17.53s/it]\n",
      "Train:   6%|▌         | 70/1163 [20:28<5:19:22, 17.53s/it]\n",
      "Train:   6%|▌         | 71/1163 [20:45<5:18:15, 17.49s/it]\n",
      "Train:   6%|▌         | 72/1163 [21:02<5:14:39, 17.30s/it]\n",
      "Train:   6%|▋         | 73/1163 [21:19<5:13:03, 17.23s/it]\n",
      "Train:   6%|▋         | 74/1163 [21:36<5:13:38, 17.28s/it]\n",
      "Train:   6%|▋         | 75/1163 [21:55<5:20:48, 17.69s/it]\n",
      "                                                          \n",
      "\n",
      "Train:   6%|▋         | 75/1163 [21:55<5:20:48, 17.69s/it]\n",
      "Train:   6%|▋         | 75/1163 [21:55<5:20:48, 17.69s/it]\n",
      "Train:   7%|▋         | 76/1163 [22:12<5:15:26, 17.41s/it]\n",
      "Train:   7%|▋         | 77/1163 [22:28<5:09:58, 17.13s/it]\n",
      "Train:   7%|▋         | 78/1163 [22:45<5:10:04, 17.15s/it]\n",
      "Train:   7%|▋         | 79/1163 [23:03<5:10:58, 17.21s/it]\n",
      "Train:   7%|▋         | 80/1163 [23:20<5:09:52, 17.17s/it]\n",
      "                                                          \n",
      "\n",
      "Train:   7%|▋         | 80/1163 [23:20<5:09:52, 17.17s/it]\n",
      "Train:   7%|▋         | 80/1163 [23:20<5:09:52, 17.17s/it]\n",
      "Train:   7%|▋         | 81/1163 [23:40<5:24:10, 17.98s/it]\n",
      "Train:   7%|▋         | 82/1163 [23:58<5:26:33, 18.13s/it]\n",
      "Train:   7%|▋         | 83/1163 [24:16<5:22:41, 17.93s/it]\n",
      "Train:   7%|▋         | 84/1163 [24:33<5:20:30, 17.82s/it]\n",
      "Train:   7%|▋         | 85/1163 [24:50<5:15:53, 17.58s/it]\n",
      "                                                          \n",
      "\n",
      "Train:   7%|▋         | 85/1163 [24:50<5:15:53, 17.58s/it]\n",
      "Train:   7%|▋         | 85/1163 [24:50<5:15:53, 17.58s/it]\n",
      "Train:   7%|▋         | 86/1163 [25:08<5:16:07, 17.61s/it]\n",
      "Train:   7%|▋         | 87/1163 [25:25<5:13:29, 17.48s/it]\n",
      "Train:   8%|▊         | 88/1163 [25:43<5:12:50, 17.46s/it]\n",
      "Train:   8%|▊         | 89/1163 [26:00<5:12:10, 17.44s/it]\n",
      "Train:   8%|▊         | 90/1163 [26:17<5:10:21, 17.35s/it]\n",
      "                                                          \n",
      "\n",
      "Train:   8%|▊         | 90/1163 [26:17<5:10:21, 17.35s/it]\n",
      "Train:   8%|▊         | 90/1163 [26:17<5:10:21, 17.35s/it]\n",
      "Train:   8%|▊         | 91/1163 [26:35<5:11:32, 17.44s/it]\n",
      "Train:   8%|▊         | 92/1163 [26:52<5:09:40, 17.35s/it]\n",
      "Train:   8%|▊         | 93/1163 [27:09<5:09:50, 17.37s/it]\n",
      "Train:   8%|▊         | 94/1163 [27:27<5:09:01, 17.34s/it]\n",
      "Train:   8%|▊         | 95/1163 [27:43<5:05:01, 17.14s/it]\n",
      "                                                          \n",
      "\n",
      "Train:   8%|▊         | 95/1163 [27:43<5:05:01, 17.14s/it]\n",
      "Train:   8%|▊         | 95/1163 [27:43<5:05:01, 17.14s/it]\n",
      "Train:   8%|▊         | 96/1163 [28:01<5:07:04, 17.27s/it]\n",
      "Train:   8%|▊         | 97/1163 [28:18<5:08:42, 17.38s/it]\n",
      "Train:   8%|▊         | 98/1163 [28:36<5:07:18, 17.31s/it]\n",
      "Train:   9%|▊         | 99/1163 [28:53<5:08:54, 17.42s/it]\n",
      "Train:   9%|▊         | 100/1163 [29:11<5:08:53, 17.44s/it]\n",
      "                                                           \n",
      "\n",
      "Train:   9%|▊         | 100/1163 [29:11<5:08:53, 17.44s/it]\n",
      "Train:   9%|▊         | 100/1163 [29:11<5:08:53, 17.44s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v12-20250928-082402/checkpoint-100\n",
      "\n",
      "Train:   9%|▊         | 101/1163 [29:29<5:14:34, 17.77s/it]\n",
      "Train:   9%|▉         | 102/1163 [29:47<5:12:16, 17.66s/it]\n",
      "Train:   9%|▉         | 103/1163 [30:04<5:09:23, 17.51s/it]\n",
      "Train:   9%|▉         | 104/1163 [30:21<5:09:26, 17.53s/it]\n",
      "Train:   9%|▉         | 105/1163 [30:38<5:05:24, 17.32s/it]\n",
      "                                                           \n",
      "\n",
      "Train:   9%|▉         | 105/1163 [30:38<5:05:24, 17.32s/it]\n",
      "Train:   9%|▉         | 105/1163 [30:38<5:05:24, 17.32s/it]\n",
      "Train:   9%|▉         | 106/1163 [30:55<5:04:25, 17.28s/it]\n",
      "Train:   9%|▉         | 107/1163 [31:13<5:06:32, 17.42s/it]\n",
      "Train:   9%|▉         | 108/1163 [31:30<5:05:19, 17.36s/it]\n",
      "Train:   9%|▉         | 109/1163 [31:47<5:03:26, 17.27s/it]\n",
      "Train:   9%|▉         | 110/1163 [32:06<5:11:40, 17.76s/it]\n",
      "                                                           \n",
      "\n",
      "Train:   9%|▉         | 110/1163 [32:06<5:11:40, 17.76s/it]\n",
      "Train:   9%|▉         | 110/1163 [32:06<5:11:40, 17.76s/it]\n",
      "Train:  10%|▉         | 111/1163 [32:24<5:10:45, 17.72s/it]\n",
      "Train:  10%|▉         | 112/1163 [32:41<5:07:04, 17.53s/it]\n",
      "Train:  10%|▉         | 113/1163 [32:58<5:05:59, 17.49s/it]\n",
      "Train:  10%|▉         | 114/1163 [33:17<5:09:47, 17.72s/it]\n",
      "Train:  10%|▉         | 115/1163 [33:34<5:09:25, 17.71s/it]\n",
      "                                                           \n",
      "\n",
      "Train:  10%|▉         | 115/1163 [33:34<5:09:25, 17.71s/it]\n",
      "Train:  10%|▉         | 115/1163 [33:34<5:09:25, 17.71s/it]\n",
      "Train:  10%|▉         | 116/1163 [33:52<5:06:15, 17.55s/it]\n",
      "Train:  10%|█         | 117/1163 [34:10<5:08:16, 17.68s/it]\n",
      "Train:  10%|█         | 118/1163 [34:27<5:05:19, 17.53s/it]\n",
      "Train:  10%|█         | 119/1163 [34:45<5:09:30, 17.79s/it]\n",
      "Train:  10%|█         | 120/1163 [35:03<5:09:36, 17.81s/it]\n",
      "                                                           \n",
      "\n",
      "Train:  10%|█         | 120/1163 [35:03<5:09:36, 17.81s/it]\n",
      "Train:  10%|█         | 120/1163 [35:03<5:09:36, 17.81s/it]\n",
      "Train:  10%|█         | 121/1163 [35:20<5:06:00, 17.62s/it]\n",
      "Train:  10%|█         | 122/1163 [35:38<5:04:26, 17.55s/it]\n",
      "Train:  11%|█         | 123/1163 [35:55<5:04:16, 17.55s/it]\n",
      "Train:  11%|█         | 124/1163 [36:12<5:01:36, 17.42s/it]\n",
      "Train:  11%|█         | 125/1163 [36:30<5:01:46, 17.44s/it]\n",
      "                                                           \n",
      "\n",
      "Train:  11%|█         | 125/1163 [36:30<5:01:46, 17.44s/it]\n",
      "Train:  11%|█         | 125/1163 [36:30<5:01:46, 17.44s/it]\n",
      "Train:  11%|█         | 126/1163 [36:47<4:58:46, 17.29s/it]\n",
      "Train:  11%|█         | 127/1163 [37:03<4:54:15, 17.04s/it]\n",
      "Train:  11%|█         | 128/1163 [37:20<4:54:14, 17.06s/it]\n",
      "Train:  11%|█         | 129/1163 [37:38<4:55:08, 17.13s/it]\n",
      "Train:  11%|█         | 130/1163 [37:55<4:55:24, 17.16s/it]\n",
      "                                                           \n",
      "\n",
      "Train:  11%|█         | 130/1163 [37:55<4:55:24, 17.16s/it]\n",
      "Train:  11%|█         | 130/1163 [37:55<4:55:24, 17.16s/it]\n",
      "Train:  11%|█▏        | 131/1163 [38:12<4:57:32, 17.30s/it]\n",
      "Train:  11%|█▏        | 132/1163 [38:29<4:54:48, 17.16s/it]\n",
      "Train:  11%|█▏        | 133/1163 [38:47<4:56:54, 17.30s/it]\n",
      "Train:  12%|█▏        | 134/1163 [39:04<4:54:24, 17.17s/it]\n",
      "Train:  12%|█▏        | 135/1163 [39:20<4:51:14, 17.00s/it]\n",
      "                                                           \n",
      "\n",
      "Train:  12%|█▏        | 135/1163 [39:20<4:51:14, 17.00s/it]\n",
      "Train:  12%|█▏        | 135/1163 [39:20<4:51:14, 17.00s/it]\n",
      "Train:  12%|█▏        | 136/1163 [39:40<5:05:30, 17.85s/it]\n",
      "Train:  12%|█▏        | 137/1163 [39:58<5:05:59, 17.89s/it]\n",
      "Train:  12%|█▏        | 138/1163 [40:16<5:04:35, 17.83s/it]\n",
      "Train:  12%|█▏        | 139/1163 [40:33<5:02:10, 17.71s/it]\n",
      "Train:  12%|█▏        | 140/1163 [40:50<4:57:19, 17.44s/it]\n",
      "                                                           \n",
      "{'loss': 2.74990797, 'token_acc': 0.46405553, 'grad_norm': 1.9871192, 'learning_rate': 1.69e-06, 'memory(GiB)': 12.28, 'train_speed(iter/s)': 0.051848, 'epoch': 0.0, 'global_step/max_steps': '1/1163', 'percentage': '0.09%', 'elapsed_time': '18s', 'remaining_time': '6h 5m 42s'}\n",
      "{'loss': 2.65003419, 'token_acc': 0.50111044, 'grad_norm': 2.33577919, 'learning_rate': 8.47e-06, 'memory(GiB)': 14.38, 'train_speed(iter/s)': 0.056147, 'epoch': 0.0, 'global_step/max_steps': '5/1163', 'percentage': '0.43%', 'elapsed_time': '1m 28s', 'remaining_time': '5h 42m 10s'}\n",
      "{'loss': 2.73675652, 'token_acc': 0.47889366, 'grad_norm': 2.27483797, 'learning_rate': 1.695e-05, 'memory(GiB)': 14.38, 'train_speed(iter/s)': 0.056445, 'epoch': 0.01, 'global_step/max_steps': '10/1163', 'percentage': '0.86%', 'elapsed_time': '2m 56s', 'remaining_time': '5h 39m 40s'}\n",
      "{'loss': 2.68061104, 'token_acc': 0.48015259, 'grad_norm': 1.7751677, 'learning_rate': 2.542e-05, 'memory(GiB)': 19.21, 'train_speed(iter/s)': 0.056279, 'epoch': 0.01, 'global_step/max_steps': '15/1163', 'percentage': '1.29%', 'elapsed_time': '4m 26s', 'remaining_time': '5h 39m 27s'}\n",
      "{'loss': 2.45956745, 'token_acc': 0.49886533, 'grad_norm': 0.98108637, 'learning_rate': 3.39e-05, 'memory(GiB)': 19.21, 'train_speed(iter/s)': 0.05651, 'epoch': 0.02, 'global_step/max_steps': '20/1163', 'percentage': '1.72%', 'elapsed_time': '5m 53s', 'remaining_time': '5h 36m 43s'}\n",
      "{'loss': 2.40233803, 'token_acc': 0.5077202, 'grad_norm': 0.66250002, 'learning_rate': 4.237e-05, 'memory(GiB)': 19.21, 'train_speed(iter/s)': 0.056758, 'epoch': 0.02, 'global_step/max_steps': '25/1163', 'percentage': '2.15%', 'elapsed_time': '7m 20s', 'remaining_time': '5h 33m 51s'}\n",
      "{'loss': 2.23717537, 'token_acc': 0.53156983, 'grad_norm': 0.60379034, 'learning_rate': 5.085e-05, 'memory(GiB)': 19.21, 'train_speed(iter/s)': 0.056506, 'epoch': 0.03, 'global_step/max_steps': '30/1163', 'percentage': '2.58%', 'elapsed_time': '8m 50s', 'remaining_time': '5h 33m 55s'}\n",
      "{'loss': 2.25157776, 'token_acc': 0.53044504, 'grad_norm': 0.66584194, 'learning_rate': 5.932e-05, 'memory(GiB)': 19.21, 'train_speed(iter/s)': 0.056897, 'epoch': 0.03, 'global_step/max_steps': '35/1163', 'percentage': '3.01%', 'elapsed_time': '10m 14s', 'remaining_time': '5h 30m 12s'}\n",
      "{'loss': 2.20866833, 'token_acc': 0.53918746, 'grad_norm': 0.56222451, 'learning_rate': 6.78e-05, 'memory(GiB)': 19.21, 'train_speed(iter/s)': 0.056851, 'epoch': 0.03, 'global_step/max_steps': '40/1163', 'percentage': '3.44%', 'elapsed_time': '11m 43s', 'remaining_time': '5h 29m 1s'}\n",
      "{'loss': 2.18296299, 'token_acc': 0.53652588, 'grad_norm': 0.62154949, 'learning_rate': 7.627e-05, 'memory(GiB)': 19.21, 'train_speed(iter/s)': 0.056871, 'epoch': 0.04, 'global_step/max_steps': '45/1163', 'percentage': '3.87%', 'elapsed_time': '13m 10s', 'remaining_time': '5h 27m 28s'}\n",
      "{'loss': 2.25099869, 'token_acc': 0.52399954, 'grad_norm': 0.77211022, 'learning_rate': 8.475e-05, 'memory(GiB)': 19.21, 'train_speed(iter/s)': 0.056928, 'epoch': 0.04, 'global_step/max_steps': '50/1163', 'percentage': '4.30%', 'elapsed_time': '14m 37s', 'remaining_time': '5h 25m 42s'}\n",
      "{'loss': 2.28427963, 'token_acc': 0.51810223, 'grad_norm': 0.6200915, 'learning_rate': 9.322e-05, 'memory(GiB)': 19.21, 'train_speed(iter/s)': 0.056921, 'epoch': 0.05, 'global_step/max_steps': '55/1163', 'percentage': '4.73%', 'elapsed_time': '16m 5s', 'remaining_time': '5h 24m 17s'}\n",
      "{'loss': 2.31992664, 'token_acc': 0.51050054, 'grad_norm': 0.63767481, 'learning_rate': 0.0001, 'memory(GiB)': 19.21, 'train_speed(iter/s)': 0.056921, 'epoch': 0.05, 'global_step/max_steps': '60/1163', 'percentage': '5.16%', 'elapsed_time': '17m 33s', 'remaining_time': '5h 22m 50s'}\n",
      "{'loss': 2.08425999, 'token_acc': 0.56167951, 'grad_norm': 0.63820356, 'learning_rate': 9.999e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056939, 'epoch': 0.06, 'global_step/max_steps': '65/1163', 'percentage': '5.59%', 'elapsed_time': '19m 1s', 'remaining_time': '5h 21m 16s'}\n",
      "{'loss': 2.17064362, 'token_acc': 0.53307825, 'grad_norm': 0.71902442, 'learning_rate': 9.998e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056977, 'epoch': 0.06, 'global_step/max_steps': '70/1163', 'percentage': '6.02%', 'elapsed_time': '20m 28s', 'remaining_time': '5h 19m 36s'}\n",
      "{'loss': 2.11188698, 'token_acc': 0.54856268, 'grad_norm': 0.62324876, 'learning_rate': 9.995e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056994, 'epoch': 0.06, 'global_step/max_steps': '75/1163', 'percentage': '6.45%', 'elapsed_time': '21m 55s', 'remaining_time': '5h 18m 4s'}\n",
      "{'loss': 2.14850197, 'token_acc': 0.53991658, 'grad_norm': 0.82648653, 'learning_rate': 9.991e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.057111, 'epoch': 0.07, 'global_step/max_steps': '80/1163', 'percentage': '6.88%', 'elapsed_time': '23m 20s', 'remaining_time': '5h 15m 57s'}\n",
      "{'loss': 2.13760929, 'token_acc': 0.54447249, 'grad_norm': 0.70583057, 'learning_rate': 9.986e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.057002, 'epoch': 0.07, 'global_step/max_steps': '85/1163', 'percentage': '7.31%', 'elapsed_time': '24m 50s', 'remaining_time': '5h 15m 6s'}\n",
      "{'loss': 2.22320824, 'token_acc': 0.52792293, 'grad_norm': 0.66285992, 'learning_rate': 9.981e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.057034, 'epoch': 0.08, 'global_step/max_steps': '90/1163', 'percentage': '7.74%', 'elapsed_time': '26m 17s', 'remaining_time': '5h 13m 28s'}\n",
      "{'loss': 2.11386604, 'token_acc': 0.54708647, 'grad_norm': 0.84323692, 'learning_rate': 9.974e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.057087, 'epoch': 0.08, 'global_step/max_steps': '95/1163', 'percentage': '8.17%', 'elapsed_time': '27m 43s', 'remaining_time': '5h 11m 43s'}\n",
      "{'loss': 2.16720486, 'token_acc': 0.54657303, 'grad_norm': 0.89103162, 'learning_rate': 9.966e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.057089, 'epoch': 0.09, 'global_step/max_steps': '100/1163', 'percentage': '8.60%', 'elapsed_time': '29m 11s', 'remaining_time': '5h 10m 15s'}\n",
      "{'loss': 2.28880119, 'token_acc': 0.51764565, 'grad_norm': 0.8413713, 'learning_rate': 9.957e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.057091, 'epoch': 0.09, 'global_step/max_steps': '105/1163', 'percentage': '9.03%', 'elapsed_time': '30m 38s', 'remaining_time': '5h 8m 47s'}\n",
      "{'loss': 2.22982254, 'token_acc': 0.52940851, 'grad_norm': 0.73098648, 'learning_rate': 9.947e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.057075, 'epoch': 0.09, 'global_step/max_steps': '110/1163', 'percentage': '9.46%', 'elapsed_time': '32m 6s', 'remaining_time': '5h 7m 25s'}\n",
      "{'loss': 2.10955772, 'token_acc': 0.55227525, 'grad_norm': 0.8283807, 'learning_rate': 9.937e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.057062, 'epoch': 0.1, 'global_step/max_steps': '115/1163', 'percentage': '9.89%', 'elapsed_time': '33m 34s', 'remaining_time': '5h 6m 2s'}\n",
      "{'loss': 2.15940132, 'token_acc': 0.54345405, 'grad_norm': 0.81666589, 'learning_rate': 9.925e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.057036, 'epoch': 0.1, 'global_step/max_steps': '120/1163', 'percentage': '10.32%', 'elapsed_time': '35m 3s', 'remaining_time': '5h 4m 43s'}\n",
      "{'loss': 2.12369766, 'token_acc': 0.54878727, 'grad_norm': 0.91694725, 'learning_rate': 9.912e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.05706, 'epoch': 0.11, 'global_step/max_steps': '125/1163', 'percentage': '10.75%', 'elapsed_time': '36m 30s', 'remaining_time': '5h 3m 7s'}\n",
      "{'loss': 2.15447063, 'token_acc': 0.54230346, 'grad_norm': 0.89927959, 'learning_rate': 9.898e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.057126, 'epoch': 0.11, 'global_step/max_steps': '130/1163', 'percentage': '11.18%', 'elapsed_time': '37m 55s', 'remaining_time': '5h 1m 19s'}\n",
      "{'loss': 2.11216831, 'token_acc': 0.54776286, 'grad_norm': 0.86018765, 'learning_rate': 9.884e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.057174, 'epoch': 0.12, 'global_step/max_steps': '135/1163', 'percentage': '11.61%', 'elapsed_time': '39m 20s', 'remaining_time': '4h 59m 37s'}\n",
      "{'loss': 2.20208378, 'token_acc': 0.532607, 'grad_norm': 0.87098563, 'learning_rate': 9.868e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.057121, 'epoch': 0.12, 'global_step/max_steps': '140/1163', 'percentage': '12.04%', 'elapsed_time': '40m 50s', 'remaining_time': '4h 58m 26s'}\n",
      "Train:  12%|█▏        | 140/1163 [40:50<4:57:19, 17.44s/it]\n",
      "Train:  12%|█▏        | 140/1163 [40:50<4:57:19, 17.44s/it]\n",
      "Train:  12%|█▏        | 141/1163 [41:09<5:04:47, 17.89s/it]\n",
      "Train:  12%|█▏        | 142/1163 [41:26<5:00:00, 17.63s/it]\n",
      "Train:  12%|█▏        | 143/1163 [41:44<4:59:22, 17.61s/it]\n",
      "Train:  12%|█▏        | 144/1163 [42:01<4:56:55, 17.48s/it]\n",
      "Train:  12%|█▏        | 145/1163 [42:18<4:52:58, 17.27s/it]\n",
      "                                                           \n",
      "\n",
      "Train:  12%|█▏        | 145/1163 [42:18<4:52:58, 17.27s/it]\n",
      "Train:  12%|█▏        | 145/1163 [42:18<4:52:58, 17.27s/it]\n",
      "Train:  13%|█▎        | 146/1163 [42:35<4:52:05, 17.23s/it]\n",
      "Train:  13%|█▎        | 147/1163 [42:53<4:58:15, 17.61s/it]\n",
      "Train:  13%|█▎        | 148/1163 [43:12<5:02:20, 17.87s/it]\n",
      "Train:  13%|█▎        | 149/1163 [43:29<5:00:39, 17.79s/it]\n",
      "Train:  13%|█▎        | 150/1163 [43:47<5:02:10, 17.90s/it]\n",
      "                                                           \n",
      "\n",
      "Train:  13%|█▎        | 150/1163 [43:47<5:02:10, 17.90s/it]\n",
      "Train:  13%|█▎        | 150/1163 [43:47<5:02:10, 17.90s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v12-20250928-082402/checkpoint-150\n",
      "\n",
      "Train:  13%|█▎        | 151/1163 [44:06<5:06:34, 18.18s/it]\n",
      "Train:  13%|█▎        | 152/1163 [44:24<5:01:58, 17.92s/it]\n",
      "Train:  13%|█▎        | 153/1163 [44:42<5:03:59, 18.06s/it]\n",
      "Train:  13%|█▎        | 154/1163 [45:01<5:07:16, 18.27s/it]\n",
      "Train:  13%|█▎        | 155/1163 [45:18<5:01:31, 17.95s/it]\n",
      "                                                           \n",
      "\n",
      "Train:  13%|█▎        | 155/1163 [45:18<5:01:31, 17.95s/it]\n",
      "Train:  13%|█▎        | 155/1163 [45:18<5:01:31, 17.95s/it]\n",
      "Train:  13%|█▎        | 156/1163 [45:36<5:00:23, 17.90s/it]\n",
      "Train:  13%|█▎        | 157/1163 [45:54<5:01:54, 18.01s/it]\n",
      "Train:  14%|█▎        | 158/1163 [46:12<5:01:27, 18.00s/it]\n",
      "Train:  14%|█▎        | 159/1163 [46:31<5:04:05, 18.17s/it]\n",
      "Train:  14%|█▍        | 160/1163 [46:48<4:58:33, 17.86s/it]\n",
      "                                                           \n",
      "\n",
      "Train:  14%|█▍        | 160/1163 [46:48<4:58:33, 17.86s/it]\n",
      "Train:  14%|█▍        | 160/1163 [46:48<4:58:33, 17.86s/it]\n",
      "Train:  14%|█▍        | 161/1163 [47:05<4:57:02, 17.79s/it]\n",
      "Train:  14%|█▍        | 162/1163 [47:22<4:53:56, 17.62s/it]\n",
      "Train:  14%|█▍        | 163/1163 [47:40<4:52:31, 17.55s/it]\n",
      "Train:  14%|█▍        | 164/1163 [47:58<4:53:50, 17.65s/it]\n",
      "Train:  14%|█▍        | 165/1163 [48:15<4:51:23, 17.52s/it]\n",
      "                                                           \n",
      "\n",
      "Train:  14%|█▍        | 165/1163 [48:15<4:51:23, 17.52s/it]\n",
      "Train:  14%|█▍        | 165/1163 [48:15<4:51:23, 17.52s/it]\n",
      "Train:  14%|█▍        | 166/1163 [48:32<4:50:08, 17.46s/it]\n",
      "Train:  14%|█▍        | 167/1163 [48:51<4:55:46, 17.82s/it]\n",
      "Train:  14%|█▍        | 168/1163 [49:08<4:53:18, 17.69s/it]\n",
      "Train:  15%|█▍        | 169/1163 [49:25<4:47:44, 17.37s/it]\n",
      "Train:  15%|█▍        | 170/1163 [49:42<4:47:50, 17.39s/it]\n",
      "                                                           \n",
      "\n",
      "Train:  15%|█▍        | 170/1163 [49:42<4:47:50, 17.39s/it]\n",
      "Train:  15%|█▍        | 170/1163 [49:42<4:47:50, 17.39s/it]\n",
      "Train:  15%|█▍        | 171/1163 [49:59<4:43:46, 17.16s/it]\n",
      "Train:  15%|█▍        | 172/1163 [50:18<4:54:36, 17.84s/it]\n",
      "Train:  15%|█▍        | 173/1163 [50:37<4:56:16, 17.96s/it]\n",
      "Train:  15%|█▍        | 174/1163 [50:54<4:52:54, 17.77s/it]\n",
      "Train:  15%|█▌        | 175/1163 [51:11<4:49:24, 17.58s/it]\n",
      "                                                           \n",
      "\n",
      "Train:  15%|█▌        | 175/1163 [51:11<4:49:24, 17.58s/it]\n",
      "Train:  15%|█▌        | 175/1163 [51:11<4:49:24, 17.58s/it]\n",
      "Train:  15%|█▌        | 176/1163 [51:28<4:47:33, 17.48s/it]\n",
      "Train:  15%|█▌        | 177/1163 [51:45<4:43:01, 17.22s/it]\n",
      "Train:  15%|█▌        | 178/1163 [52:03<4:46:52, 17.47s/it]\n",
      "Train:  15%|█▌        | 179/1163 [52:20<4:44:37, 17.36s/it]\n",
      "Train:  15%|█▌        | 180/1163 [52:38<4:45:39, 17.44s/it]\n",
      "                                                           \n",
      "\n",
      "Train:  15%|█▌        | 180/1163 [52:38<4:45:39, 17.44s/it]\n",
      "Train:  15%|█▌        | 180/1163 [52:38<4:45:39, 17.44s/it]\n",
      "Train:  16%|█▌        | 181/1163 [52:56<4:47:31, 17.57s/it]\n",
      "Train:  16%|█▌        | 182/1163 [53:13<4:45:08, 17.44s/it]\n",
      "Train:  16%|█▌        | 183/1163 [53:29<4:40:46, 17.19s/it]\n",
      "Train:  16%|█▌        | 184/1163 [53:46<4:39:47, 17.15s/it]\n",
      "Train:  16%|█▌        | 185/1163 [54:04<4:42:01, 17.30s/it]\n",
      "                                                           \n",
      "\n",
      "Train:  16%|█▌        | 185/1163 [54:04<4:42:01, 17.30s/it]\n",
      "Train:  16%|█▌        | 185/1163 [54:04<4:42:01, 17.30s/it]\n",
      "Train:  16%|█▌        | 186/1163 [54:21<4:41:56, 17.32s/it]\n",
      "Train:  16%|█▌        | 187/1163 [54:39<4:43:27, 17.43s/it]\n",
      "Train:  16%|█▌        | 188/1163 [54:57<4:43:10, 17.43s/it]\n",
      "Train:  16%|█▋        | 189/1163 [55:14<4:40:54, 17.30s/it]\n",
      "Train:  16%|█▋        | 190/1163 [55:31<4:41:41, 17.37s/it]\n",
      "                                                           \n",
      "\n",
      "Train:  16%|█▋        | 190/1163 [55:31<4:41:41, 17.37s/it]\n",
      "Train:  16%|█▋        | 190/1163 [55:31<4:41:41, 17.37s/it]\n",
      "Train:  16%|█▋        | 191/1163 [55:50<4:49:18, 17.86s/it]\n",
      "Train:  17%|█▋        | 192/1163 [56:07<4:46:07, 17.68s/it]\n",
      "Train:  17%|█▋        | 193/1163 [56:24<4:41:03, 17.38s/it]\n",
      "Train:  17%|█▋        | 194/1163 [56:42<4:43:58, 17.58s/it]\n",
      "Train:  17%|█▋        | 195/1163 [57:00<4:42:57, 17.54s/it]\n",
      "                                                           \n",
      "\n",
      "Train:  17%|█▋        | 195/1163 [57:00<4:42:57, 17.54s/it]\n",
      "Train:  17%|█▋        | 195/1163 [57:00<4:42:57, 17.54s/it]\n",
      "Train:  17%|█▋        | 196/1163 [57:17<4:42:03, 17.50s/it]\n",
      "Train:  17%|█▋        | 197/1163 [57:34<4:40:32, 17.43s/it]\n",
      "Train:  17%|█▋        | 198/1163 [57:51<4:38:01, 17.29s/it]\n",
      "Train:  17%|█▋        | 199/1163 [58:09<4:38:32, 17.34s/it]\n",
      "Train:  17%|█▋        | 200/1163 [58:25<4:35:25, 17.16s/it]\n",
      "                                                           \n",
      "\n",
      "Train:  17%|█▋        | 200/1163 [58:25<4:35:25, 17.16s/it]\n",
      "Train:  17%|█▋        | 200/1163 [58:25<4:35:25, 17.16s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v12-20250928-082402/checkpoint-200\n",
      "\n",
      "Train:  17%|█▋        | 201/1163 [58:44<4:42:52, 17.64s/it]\n",
      "Train:  17%|█▋        | 202/1163 [59:02<4:41:35, 17.58s/it]\n",
      "Train:  17%|█▋        | 203/1163 [59:19<4:38:30, 17.41s/it]\n",
      "Train:  18%|█▊        | 204/1163 [59:36<4:36:38, 17.31s/it]\n",
      "Train:  18%|█▊        | 205/1163 [59:53<4:35:22, 17.25s/it]\n",
      "                                                           \n",
      "\n",
      "Train:  18%|█▊        | 205/1163 [59:53<4:35:22, 17.25s/it]\n",
      "Train:  18%|█▊        | 205/1163 [59:53<4:35:22, 17.25s/it]\n",
      "Train:  18%|█▊        | 206/1163 [1:00:10<4:33:54, 17.17s/it]\n",
      "Train:  18%|█▊        | 207/1163 [1:00:27<4:33:42, 17.18s/it]\n",
      "Train:  18%|█▊        | 208/1163 [1:00:44<4:33:54, 17.21s/it]\n",
      "Train:  18%|█▊        | 209/1163 [1:01:03<4:40:56, 17.67s/it]\n",
      "Train:  18%|█▊        | 210/1163 [1:01:21<4:40:23, 17.65s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  18%|█▊        | 210/1163 [1:01:21<4:40:23, 17.65s/it]\n",
      "Train:  18%|█▊        | 210/1163 [1:01:21<4:40:23, 17.65s/it]\n",
      "Train:  18%|█▊        | 211/1163 [1:01:37<4:36:05, 17.40s/it]\n",
      "Train:  18%|█▊        | 212/1163 [1:01:54<4:31:55, 17.16s/it]\n",
      "Train:  18%|█▊        | 213/1163 [1:02:10<4:28:18, 16.95s/it]\n",
      "Train:  18%|█▊        | 214/1163 [1:02:27<4:27:40, 16.92s/it]\n",
      "Train:  18%|█▊        | 215/1163 [1:02:47<4:39:52, 17.71s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  18%|█▊        | 215/1163 [1:02:47<4:39:52, 17.71s/it]\n",
      "Train:  18%|█▊        | 215/1163 [1:02:47<4:39:52, 17.71s/it]\n",
      "Train:  19%|█▊        | 216/1163 [1:03:05<4:41:19, 17.82s/it]\n",
      "Train:  19%|█▊        | 217/1163 [1:03:22<4:39:39, 17.74s/it]\n",
      "Train:  19%|█▊        | 218/1163 [1:03:39<4:35:50, 17.51s/it]\n",
      "Train:  19%|█▉        | 219/1163 [1:03:58<4:39:30, 17.77s/it]\n",
      "Train:  19%|█▉        | 220/1163 [1:04:14<4:33:19, 17.39s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  19%|█▉        | 220/1163 [1:04:14<4:33:19, 17.39s/it]\n",
      "Train:  19%|█▉        | 220/1163 [1:04:14<4:33:19, 17.39s/it]\n",
      "Train:  19%|█▉        | 221/1163 [1:04:32<4:32:24, 17.35s/it]\n",
      "Train:  19%|█▉        | 222/1163 [1:04:50<4:35:17, 17.55s/it]\n",
      "Train:  19%|█▉        | 223/1163 [1:05:08<4:36:40, 17.66s/it]\n",
      "Train:  19%|█▉        | 224/1163 [1:05:26<4:38:29, 17.80s/it]\n",
      "Train:  19%|█▉        | 225/1163 [1:05:44<4:41:47, 18.03s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  19%|█▉        | 225/1163 [1:05:44<4:41:47, 18.03s/it]\n",
      "Train:  19%|█▉        | 225/1163 [1:05:44<4:41:47, 18.03s/it]\n",
      "Train:  19%|█▉        | 226/1163 [1:06:03<4:44:00, 18.19s/it]\n",
      "Train:  20%|█▉        | 227/1163 [1:06:20<4:39:16, 17.90s/it]\n",
      "Train:  20%|█▉        | 228/1163 [1:06:37<4:32:22, 17.48s/it]\n",
      "Train:  20%|█▉        | 229/1163 [1:06:53<4:29:16, 17.30s/it]\n",
      "Train:  20%|█▉        | 230/1163 [1:07:11<4:29:13, 17.31s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  20%|█▉        | 230/1163 [1:07:11<4:29:13, 17.31s/it]\n",
      "Train:  20%|█▉        | 230/1163 [1:07:11<4:29:13, 17.31s/it]\n",
      "Train:  20%|█▉        | 231/1163 [1:07:31<4:41:47, 18.14s/it]\n",
      "Train:  20%|█▉        | 232/1163 [1:07:49<4:39:44, 18.03s/it]\n",
      "Train:  20%|██        | 233/1163 [1:08:06<4:35:44, 17.79s/it]\n",
      "Train:  20%|██        | 234/1163 [1:08:23<4:30:41, 17.48s/it]\n",
      "Train:  20%|██        | 235/1163 [1:08:40<4:30:28, 17.49s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  20%|██        | 235/1163 [1:08:40<4:30:28, 17.49s/it]\n",
      "Train:  20%|██        | 235/1163 [1:08:40<4:30:28, 17.49s/it]\n",
      "Train:  20%|██        | 236/1163 [1:08:58<4:30:42, 17.52s/it]\n",
      "Train:  20%|██        | 237/1163 [1:09:15<4:27:55, 17.36s/it]\n",
      "Train:  20%|██        | 238/1163 [1:09:32<4:29:34, 17.49s/it]\n",
      "Train:  21%|██        | 239/1163 [1:09:49<4:27:05, 17.34s/it]\n",
      "Train:  21%|██        | 240/1163 [1:10:07<4:27:39, 17.40s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  21%|██        | 240/1163 [1:10:07<4:27:39, 17.40s/it]\n",
      "Train:  21%|██        | 240/1163 [1:10:07<4:27:39, 17.40s/it]\n",
      "Train:  21%|██        | 241/1163 [1:10:28<4:42:48, 18.40s/it]\n",
      "Train:  21%|██        | 242/1163 [1:10:45<4:37:52, 18.10s/it]\n",
      "Train:  21%|██        | 243/1163 [1:11:02<4:31:29, 17.71s/it]\n",
      "Train:  21%|██        | 244/1163 [1:11:19<4:26:15, 17.38s/it]\n",
      "Train:  21%|██        | 245/1163 [1:11:35<4:23:08, 17.20s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  21%|██        | 245/1163 [1:11:35<4:23:08, 17.20s/it]\n",
      "Train:  21%|██        | 245/1163 [1:11:35<4:23:08, 17.20s/it]\n",
      "Train:  21%|██        | 246/1163 [1:11:54<4:28:53, 17.59s/it]\n",
      "Train:  21%|██        | 247/1163 [1:12:12<4:29:51, 17.68s/it]\n",
      "Train:  21%|██▏       | 248/1163 [1:12:29<4:28:48, 17.63s/it]\n",
      "Train:  21%|██▏       | 249/1163 [1:12:47<4:28:44, 17.64s/it]\n",
      "Train:  21%|██▏       | 250/1163 [1:13:04<4:27:25, 17.57s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  21%|██▏       | 250/1163 [1:13:04<4:27:25, 17.57s/it]\n",
      "Train:  21%|██▏       | 250/1163 [1:13:04<4:27:25, 17.57s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v12-20250928-082402/checkpoint-250\n",
      "\n",
      "Train:  22%|██▏       | 251/1163 [1:13:23<4:32:45, 17.94s/it]\n",
      "Train:  22%|██▏       | 252/1163 [1:13:40<4:29:19, 17.74s/it]\n",
      "Train:  22%|██▏       | 253/1163 [1:13:57<4:22:27, 17.30s/it]\n",
      "Train:  22%|██▏       | 254/1163 [1:14:15<4:26:47, 17.61s/it]\n",
      "Train:  22%|██▏       | 255/1163 [1:14:31<4:21:04, 17.25s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  22%|██▏       | 255/1163 [1:14:31<4:21:04, 17.25s/it]\n",
      "Train:  22%|██▏       | 255/1163 [1:14:31<4:21:04, 17.25s/it]\n",
      "Train:  22%|██▏       | 256/1163 [1:14:48<4:20:04, 17.20s/it]\n",
      "Train:  22%|██▏       | 257/1163 [1:15:06<4:20:22, 17.24s/it]\n",
      "Train:  22%|██▏       | 258/1163 [1:15:24<4:22:52, 17.43s/it]\n",
      "Train:  22%|██▏       | 259/1163 [1:15:42<4:24:51, 17.58s/it]\n",
      "Train:  22%|██▏       | 260/1163 [1:15:59<4:25:57, 17.67s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  22%|██▏       | 260/1163 [1:16:00<4:25:57, 17.67s/it]\n",
      "Train:  22%|██▏       | 260/1163 [1:16:00<4:25:57, 17.67s/it]\n",
      "Train:  22%|██▏       | 261/1163 [1:16:16<4:21:44, 17.41s/it]\n",
      "Train:  23%|██▎       | 262/1163 [1:16:37<4:35:11, 18.33s/it]\n",
      "Train:  23%|██▎       | 263/1163 [1:16:54<4:31:21, 18.09s/it]\n",
      "Train:  23%|██▎       | 264/1163 [1:17:12<4:28:25, 17.92s/it]\n",
      "Train:  23%|██▎       | 265/1163 [1:17:30<4:29:30, 18.01s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  23%|██▎       | 265/1163 [1:17:30<4:29:30, 18.01s/it]\n",
      "Train:  23%|██▎       | 265/1163 [1:17:30<4:29:30, 18.01s/it]\n",
      "Train:  23%|██▎       | 266/1163 [1:17:47<4:24:53, 17.72s/it]\n",
      "Train:  23%|██▎       | 267/1163 [1:18:04<4:20:58, 17.48s/it]\n",
      "Train:  23%|██▎       | 268/1163 [1:18:21<4:17:22, 17.25s/it]\n",
      "Train:  23%|██▎       | 269/1163 [1:18:39<4:20:04, 17.45s/it]\n",
      "Train:  23%|██▎       | 270/1163 [1:18:57<4:22:13, 17.62s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  23%|██▎       | 270/1163 [1:18:57<4:22:13, 17.62s/it]\n",
      "Train:  23%|██▎       | 270/1163 [1:18:57<4:22:13, 17.62s/it]\n",
      "Train:  23%|██▎       | 271/1163 [1:19:15<4:27:08, 17.97s/it]\n",
      "Train:  23%|██▎       | 272/1163 [1:19:32<4:21:16, 17.59s/it]\n",
      "Train:  23%|██▎       | 273/1163 [1:19:50<4:22:24, 17.69s/it]\n",
      "Train:  24%|██▎       | 274/1163 [1:20:07<4:19:37, 17.52s/it]\n",
      "Train:  24%|██▎       | 275/1163 [1:20:24<4:17:13, 17.38s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  24%|██▎       | 275/1163 [1:20:24<4:17:13, 17.38s/it]\n",
      "Train:  24%|██▎       | 275/1163 [1:20:24<4:17:13, 17.38s/it]\n",
      "Train:  24%|██▎       | 276/1163 [1:20:42<4:17:33, 17.42s/it]\n",
      "Train:  24%|██▍       | 277/1163 [1:21:02<4:27:52, 18.14s/it]\n",
      "Train:  24%|██▍       | 278/1163 [1:21:19<4:24:43, 17.95s/it]\n",
      "Train:  24%|██▍       | 279/1163 [1:21:36<4:20:38, 17.69s/it]\n",
      "Train:  24%|██▍       | 280/1163 [1:21:54<4:19:27, 17.63s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  24%|██▍       | 280/1163 [1:21:54<4:19:27, 17.63s/it]\n",
      "Train:  24%|██▍       | 280/1163 [1:21:54<4:19:27, 17.63s/it]\n",
      "Train:  24%|██▍       | 281/1163 [1:22:10<4:15:12, 17.36s/it]\n",
      "Train:  24%|██▍       | 282/1163 [1:22:29<4:20:27, 17.74s/it]\n",
      "Train:  24%|██▍       | 283/1163 [1:22:46<4:18:56, 17.66s/it]\n",
      "Train:  24%|██▍       | 284/1163 [1:23:05<4:21:31, 17.85s/it]\n",
      "Train:  25%|██▍       | 285/1163 [1:23:22<4:17:42, 17.61s/it]\n",
      "                                                             \n",
      "{'loss': 2.1206398, 'token_acc': 0.55249869, 'grad_norm': 0.97559947, 'learning_rate': 9.851e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.057122, 'epoch': 0.12, 'global_step/max_steps': '145/1163', 'percentage': '12.47%', 'elapsed_time': '42m 18s', 'remaining_time': '4h 56m 58s'}\n",
      "{'loss': 2.035182, 'token_acc': 0.56572675, 'grad_norm': 0.81886345, 'learning_rate': 9.833e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.057071, 'epoch': 0.13, 'global_step/max_steps': '150/1163', 'percentage': '12.90%', 'elapsed_time': '43m 47s', 'remaining_time': '4h 55m 47s'}\n",
      "{'loss': 2.10171204, 'token_acc': 0.55247119, 'grad_norm': 0.91443443, 'learning_rate': 9.815e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.05701, 'epoch': 0.13, 'global_step/max_steps': '155/1163', 'percentage': '13.33%', 'elapsed_time': '45m 18s', 'remaining_time': '4h 54m 38s'}\n",
      "{'loss': 2.05485802, 'token_acc': 0.5562627, 'grad_norm': 0.97561347, 'learning_rate': 9.795e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056969, 'epoch': 0.14, 'global_step/max_steps': '160/1163', 'percentage': '13.76%', 'elapsed_time': '46m 48s', 'remaining_time': '4h 53m 23s'}\n",
      "{'loss': 2.04879532, 'token_acc': 0.56501348, 'grad_norm': 0.90737891, 'learning_rate': 9.774e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056978, 'epoch': 0.14, 'global_step/max_steps': '165/1163', 'percentage': '14.19%', 'elapsed_time': '48m 15s', 'remaining_time': '4h 51m 53s'}\n",
      "{'loss': 2.25097065, 'token_acc': 0.52474809, 'grad_norm': 0.96078593, 'learning_rate': 9.753e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056984, 'epoch': 0.15, 'global_step/max_steps': '170/1163', 'percentage': '14.62%', 'elapsed_time': '49m 42s', 'remaining_time': '4h 50m 23s'}\n",
      "{'loss': 2.15797367, 'token_acc': 0.53229508, 'grad_norm': 0.91163039, 'learning_rate': 9.73e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056965, 'epoch': 0.15, 'global_step/max_steps': '175/1163', 'percentage': '15.05%', 'elapsed_time': '51m 11s', 'remaining_time': '4h 49m 1s'}\n",
      "{'loss': 2.07495003, 'token_acc': 0.56196265, 'grad_norm': 1.01661289, 'learning_rate': 9.707e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056986, 'epoch': 0.15, 'global_step/max_steps': '180/1163', 'percentage': '15.48%', 'elapsed_time': '52m 38s', 'remaining_time': '4h 47m 27s'}\n",
      "{'loss': 2.13197403, 'token_acc': 0.54819853, 'grad_norm': 1.04737401, 'learning_rate': 9.682e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.057011, 'epoch': 0.16, 'global_step/max_steps': '185/1163', 'percentage': '15.91%', 'elapsed_time': '54m 4s', 'remaining_time': '4h 45m 52s'}\n",
      "{'loss': 2.00014668, 'token_acc': 0.57845188, 'grad_norm': 0.93285483, 'learning_rate': 9.657e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.057023, 'epoch': 0.16, 'global_step/max_steps': '190/1163', 'percentage': '16.34%', 'elapsed_time': '55m 31s', 'remaining_time': '4h 44m 21s'}\n",
      "{'loss': 2.14719296, 'token_acc': 0.53716578, 'grad_norm': 1.02525663, 'learning_rate': 9.63e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.05701, 'epoch': 0.17, 'global_step/max_steps': '195/1163', 'percentage': '16.77%', 'elapsed_time': '57m 0s', 'remaining_time': '4h 42m 57s'}\n",
      "{'loss': 2.23284912, 'token_acc': 0.52580061, 'grad_norm': 1.01159549, 'learning_rate': 9.603e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.05704, 'epoch': 0.17, 'global_step/max_steps': '200/1163', 'percentage': '17.20%', 'elapsed_time': '58m 25s', 'remaining_time': '4h 41m 20s'}\n",
      "{'loss': 2.12713432, 'token_acc': 0.5451517, 'grad_norm': 0.94278604, 'learning_rate': 9.575e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.057045, 'epoch': 0.18, 'global_step/max_steps': '205/1163', 'percentage': '17.63%', 'elapsed_time': '59m 53s', 'remaining_time': '4h 39m 51s'}\n",
      "{'loss': 2.14714622, 'token_acc': 0.5423237, 'grad_norm': 0.88190615, 'learning_rate': 9.545e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.057042, 'epoch': 0.18, 'global_step/max_steps': '210/1163', 'percentage': '18.06%', 'elapsed_time': '1h 1m 21s', 'remaining_time': '4h 38m 25s'}\n",
      "{'loss': 2.13372936, 'token_acc': 0.54483867, 'grad_norm': 0.80580592, 'learning_rate': 9.515e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.057063, 'epoch': 0.19, 'global_step/max_steps': '215/1163', 'percentage': '18.49%', 'elapsed_time': '1h 2m 47s', 'remaining_time': '4h 36m 51s'}\n",
      "{'loss': 1.99617214, 'token_acc': 0.57706314, 'grad_norm': 1.10244668, 'learning_rate': 9.484e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.057065, 'epoch': 0.19, 'global_step/max_steps': '220/1163', 'percentage': '18.92%', 'elapsed_time': '1h 4m 14s', 'remaining_time': '4h 35m 23s'}\n",
      "{'loss': 2.04541855, 'token_acc': 0.56446285, 'grad_norm': 1.11021626, 'learning_rate': 9.452e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.057032, 'epoch': 0.19, 'global_step/max_steps': '225/1163', 'percentage': '19.35%', 'elapsed_time': '1h 5m 44s', 'remaining_time': '4h 34m 5s'}\n",
      "{'loss': 2.14887276, 'token_acc': 0.53793807, 'grad_norm': 1.05620849, 'learning_rate': 9.42e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.057049, 'epoch': 0.2, 'global_step/max_steps': '230/1163', 'percentage': '19.78%', 'elapsed_time': '1h 7m 11s', 'remaining_time': '4h 32m 32s'}\n",
      "{'loss': 2.07160492, 'token_acc': 0.55541428, 'grad_norm': 1.04763103, 'learning_rate': 9.386e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.057025, 'epoch': 0.2, 'global_step/max_steps': '235/1163', 'percentage': '20.21%', 'elapsed_time': '1h 8m 40s', 'remaining_time': '4h 31m 11s'}\n",
      "{'loss': 2.02327366, 'token_acc': 0.57505227, 'grad_norm': 0.95398772, 'learning_rate': 9.351e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.057036, 'epoch': 0.21, 'global_step/max_steps': '240/1163', 'percentage': '20.64%', 'elapsed_time': '1h 10m 7s', 'remaining_time': '4h 29m 41s'}\n",
      "{'loss': 2.10967636, 'token_acc': 0.55579834, 'grad_norm': 1.05733132, 'learning_rate': 9.316e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.057027, 'epoch': 0.21, 'global_step/max_steps': '245/1163', 'percentage': '21.07%', 'elapsed_time': '1h 11m 35s', 'remaining_time': '4h 28m 16s'}\n",
      "{'loss': 2.07353878, 'token_acc': 0.55881199, 'grad_norm': 1.07678926, 'learning_rate': 9.279e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.05701, 'epoch': 0.22, 'global_step/max_steps': '250/1163', 'percentage': '21.50%', 'elapsed_time': '1h 13m 4s', 'remaining_time': '4h 26m 53s'}\n",
      "{'loss': 2.09861507, 'token_acc': 0.55217259, 'grad_norm': 0.99624324, 'learning_rate': 9.242e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.057018, 'epoch': 0.22, 'global_step/max_steps': '255/1163', 'percentage': '21.93%', 'elapsed_time': '1h 14m 31s', 'remaining_time': '4h 25m 23s'}\n",
      "{'loss': 2.10893993, 'token_acc': 0.54681669, 'grad_norm': 1.08332884, 'learning_rate': 9.204e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.057013, 'epoch': 0.22, 'global_step/max_steps': '260/1163', 'percentage': '22.36%', 'elapsed_time': '1h 15m 59s', 'remaining_time': '4h 23m 57s'}\n",
      "{'loss': 2.11379185, 'token_acc': 0.54373546, 'grad_norm': 0.91942996, 'learning_rate': 9.165e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056978, 'epoch': 0.23, 'global_step/max_steps': '265/1163', 'percentage': '22.79%', 'elapsed_time': '1h 17m 30s', 'remaining_time': '4h 22m 39s'}\n",
      "{'loss': 2.03465328, 'token_acc': 0.57246256, 'grad_norm': 0.97628522, 'learning_rate': 9.125e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056991, 'epoch': 0.23, 'global_step/max_steps': '270/1163', 'percentage': '23.22%', 'elapsed_time': '1h 18m 57s', 'remaining_time': '4h 21m 7s'}\n",
      "{'loss': 1.9867588, 'token_acc': 0.57242555, 'grad_norm': 1.02465928, 'learning_rate': 9.085e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056993, 'epoch': 0.24, 'global_step/max_steps': '275/1163', 'percentage': '23.65%', 'elapsed_time': '1h 20m 24s', 'remaining_time': '4h 19m 39s'}\n",
      "{'loss': 1.99809361, 'token_acc': 0.57132041, 'grad_norm': 1.11685288, 'learning_rate': 9.043e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056974, 'epoch': 0.24, 'global_step/max_steps': '280/1163', 'percentage': '24.08%', 'elapsed_time': '1h 21m 54s', 'remaining_time': '4h 18m 17s'}\n",
      "{'loss': 2.00496807, 'token_acc': 0.57242701, 'grad_norm': 1.18235135, 'learning_rate': 9.001e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056969, 'epoch': 0.25, 'global_step/max_steps': '285/1163', 'percentage': '24.51%', 'elapsed_time': '1h 23m 22s', 'remaining_time': '4h 16m 50s'}\n",
      "Train:  25%|██▍       | 285/1163 [1:23:22<4:17:42, 17.61s/it]\n",
      "Train:  25%|██▍       | 285/1163 [1:23:22<4:17:42, 17.61s/it]\n",
      "Train:  25%|██▍       | 286/1163 [1:23:39<4:15:57, 17.51s/it]\n",
      "Train:  25%|██▍       | 287/1163 [1:23:57<4:15:57, 17.53s/it]\n",
      "Train:  25%|██▍       | 288/1163 [1:24:15<4:17:39, 17.67s/it]\n",
      "Train:  25%|██▍       | 289/1163 [1:24:34<4:23:38, 18.10s/it]\n",
      "Train:  25%|██▍       | 290/1163 [1:24:51<4:19:48, 17.86s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  25%|██▍       | 290/1163 [1:24:51<4:19:48, 17.86s/it]\n",
      "Train:  25%|██▍       | 290/1163 [1:24:51<4:19:48, 17.86s/it]\n",
      "Train:  25%|██▌       | 291/1163 [1:25:08<4:17:22, 17.71s/it]\n",
      "Train:  25%|██▌       | 292/1163 [1:25:26<4:15:53, 17.63s/it]\n",
      "Train:  25%|██▌       | 293/1163 [1:25:43<4:13:45, 17.50s/it]\n",
      "Train:  25%|██▌       | 294/1163 [1:26:01<4:14:34, 17.58s/it]\n",
      "Train:  25%|██▌       | 295/1163 [1:26:18<4:13:57, 17.56s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  25%|██▌       | 295/1163 [1:26:18<4:13:57, 17.56s/it]\n",
      "Train:  25%|██▌       | 295/1163 [1:26:18<4:13:57, 17.56s/it]\n",
      "Train:  25%|██▌       | 296/1163 [1:26:37<4:18:30, 17.89s/it]\n",
      "Train:  26%|██▌       | 297/1163 [1:26:54<4:15:19, 17.69s/it]\n",
      "Train:  26%|██▌       | 298/1163 [1:27:11<4:11:52, 17.47s/it]\n",
      "Train:  26%|██▌       | 299/1163 [1:27:28<4:09:27, 17.32s/it]\n",
      "Train:  26%|██▌       | 300/1163 [1:27:46<4:09:39, 17.36s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  26%|██▌       | 300/1163 [1:27:46<4:09:39, 17.36s/it]\n",
      "Train:  26%|██▌       | 300/1163 [1:27:46<4:09:39, 17.36s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v12-20250928-082402/checkpoint-300\n",
      "\n",
      "Train:  26%|██▌       | 301/1163 [1:28:04<4:14:49, 17.74s/it]\n",
      "Train:  26%|██▌       | 302/1163 [1:28:22<4:16:09, 17.85s/it]\n",
      "Train:  26%|██▌       | 303/1163 [1:28:39<4:12:24, 17.61s/it]\n",
      "Train:  26%|██▌       | 304/1163 [1:28:57<4:11:49, 17.59s/it]\n",
      "Train:  26%|██▌       | 305/1163 [1:29:14<4:10:13, 17.50s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  26%|██▌       | 305/1163 [1:29:14<4:10:13, 17.50s/it]\n",
      "Train:  26%|██▌       | 305/1163 [1:29:14<4:10:13, 17.50s/it]\n",
      "Train:  26%|██▋       | 306/1163 [1:29:32<4:09:05, 17.44s/it]\n",
      "Train:  26%|██▋       | 307/1163 [1:29:49<4:10:01, 17.52s/it]\n",
      "Train:  26%|██▋       | 308/1163 [1:30:07<4:11:26, 17.65s/it]\n",
      "Train:  27%|██▋       | 309/1163 [1:30:26<4:15:22, 17.94s/it]\n",
      "Train:  27%|██▋       | 310/1163 [1:30:43<4:13:00, 17.80s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  27%|██▋       | 310/1163 [1:30:43<4:13:00, 17.80s/it]\n",
      "Train:  27%|██▋       | 310/1163 [1:30:43<4:13:00, 17.80s/it]\n",
      "Train:  27%|██▋       | 311/1163 [1:31:01<4:10:36, 17.65s/it]\n",
      "Train:  27%|██▋       | 312/1163 [1:31:18<4:10:21, 17.65s/it]\n",
      "Train:  27%|██▋       | 313/1163 [1:31:36<4:10:28, 17.68s/it]\n",
      "Train:  27%|██▋       | 314/1163 [1:31:53<4:08:49, 17.58s/it]\n",
      "Train:  27%|██▋       | 315/1163 [1:32:11<4:07:37, 17.52s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  27%|██▋       | 315/1163 [1:32:11<4:07:37, 17.52s/it]\n",
      "Train:  27%|██▋       | 315/1163 [1:32:11<4:07:37, 17.52s/it]\n",
      "Train:  27%|██▋       | 316/1163 [1:32:28<4:04:56, 17.35s/it]\n",
      "Train:  27%|██▋       | 317/1163 [1:32:45<4:03:55, 17.30s/it]\n",
      "Train:  27%|██▋       | 318/1163 [1:33:02<4:03:25, 17.28s/it]\n",
      "Train:  27%|██▋       | 319/1163 [1:33:19<4:03:15, 17.29s/it]\n",
      "Train:  28%|██▊       | 320/1163 [1:33:36<4:01:53, 17.22s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  28%|██▊       | 320/1163 [1:33:36<4:01:53, 17.22s/it]\n",
      "Train:  28%|██▊       | 320/1163 [1:33:36<4:01:53, 17.22s/it]\n",
      "Train:  28%|██▊       | 321/1163 [1:33:54<4:01:52, 17.24s/it]\n",
      "Train:  28%|██▊       | 322/1163 [1:34:11<4:03:09, 17.35s/it]\n",
      "Train:  28%|██▊       | 323/1163 [1:34:29<4:04:18, 17.45s/it]\n",
      "Train:  28%|██▊       | 324/1163 [1:34:47<4:05:22, 17.55s/it]\n",
      "Train:  28%|██▊       | 325/1163 [1:35:04<4:04:07, 17.48s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  28%|██▊       | 325/1163 [1:35:04<4:04:07, 17.48s/it]\n",
      "Train:  28%|██▊       | 325/1163 [1:35:04<4:04:07, 17.48s/it]\n",
      "Train:  28%|██▊       | 326/1163 [1:35:23<4:10:29, 17.96s/it]\n",
      "Train:  28%|██▊       | 327/1163 [1:35:40<4:05:05, 17.59s/it]\n",
      "Train:  28%|██▊       | 328/1163 [1:35:57<4:04:27, 17.57s/it]\n",
      "Train:  28%|██▊       | 329/1163 [1:36:18<4:16:59, 18.49s/it]\n",
      "Train:  28%|██▊       | 330/1163 [1:36:36<4:12:54, 18.22s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  28%|██▊       | 330/1163 [1:36:36<4:12:54, 18.22s/it]\n",
      "Train:  28%|██▊       | 330/1163 [1:36:36<4:12:54, 18.22s/it]\n",
      "Train:  28%|██▊       | 331/1163 [1:36:53<4:09:35, 18.00s/it]\n",
      "Train:  29%|██▊       | 332/1163 [1:37:10<4:05:49, 17.75s/it]\n",
      "Train:  29%|██▊       | 333/1163 [1:37:27<4:01:26, 17.45s/it]\n",
      "Train:  29%|██▊       | 334/1163 [1:37:44<3:58:31, 17.26s/it]\n",
      "Train:  29%|██▉       | 335/1163 [1:38:01<3:58:25, 17.28s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  29%|██▉       | 335/1163 [1:38:01<3:58:25, 17.28s/it]\n",
      "Train:  29%|██▉       | 335/1163 [1:38:01<3:58:25, 17.28s/it]\n",
      "Train:  29%|██▉       | 336/1163 [1:38:19<4:02:13, 17.57s/it]\n",
      "Train:  29%|██▉       | 337/1163 [1:38:37<4:01:25, 17.54s/it]\n",
      "Train:  29%|██▉       | 338/1163 [1:38:56<4:06:06, 17.90s/it]\n",
      "Train:  29%|██▉       | 339/1163 [1:39:13<4:01:41, 17.60s/it]\n",
      "Train:  29%|██▉       | 340/1163 [1:39:30<3:59:35, 17.47s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  29%|██▉       | 340/1163 [1:39:30<3:59:35, 17.47s/it]\n",
      "Train:  29%|██▉       | 340/1163 [1:39:30<3:59:35, 17.47s/it]\n",
      "Train:  29%|██▉       | 341/1163 [1:39:47<4:00:07, 17.53s/it]\n",
      "Train:  29%|██▉       | 342/1163 [1:40:04<3:57:03, 17.32s/it]\n",
      "Train:  29%|██▉       | 343/1163 [1:40:22<3:58:20, 17.44s/it]\n",
      "Train:  30%|██▉       | 344/1163 [1:40:39<3:58:13, 17.45s/it]\n",
      "Train:  30%|██▉       | 345/1163 [1:40:58<4:03:46, 17.88s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  30%|██▉       | 345/1163 [1:40:58<4:03:46, 17.88s/it]\n",
      "Train:  30%|██▉       | 345/1163 [1:40:58<4:03:46, 17.88s/it]\n",
      "Train:  30%|██▉       | 346/1163 [1:41:17<4:04:56, 17.99s/it]\n",
      "Train:  30%|██▉       | 347/1163 [1:41:35<4:06:26, 18.12s/it]\n",
      "Train:  30%|██▉       | 348/1163 [1:41:51<3:59:27, 17.63s/it]\n",
      "Train:  30%|███       | 349/1163 [1:42:10<4:01:48, 17.82s/it]\n",
      "Train:  30%|███       | 350/1163 [1:42:27<3:59:46, 17.70s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  30%|███       | 350/1163 [1:42:27<3:59:46, 17.70s/it]\n",
      "Train:  30%|███       | 350/1163 [1:42:27<3:59:46, 17.70s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v12-20250928-082402/checkpoint-350\n",
      "\n",
      "Train:  30%|███       | 351/1163 [1:42:46<4:06:02, 18.18s/it]\n",
      "Train:  30%|███       | 352/1163 [1:43:03<4:00:56, 17.82s/it]\n",
      "Train:  30%|███       | 353/1163 [1:43:21<3:57:51, 17.62s/it]\n",
      "Train:  30%|███       | 354/1163 [1:43:38<3:58:05, 17.66s/it]\n",
      "Train:  31%|███       | 355/1163 [1:43:55<3:54:47, 17.43s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  31%|███       | 355/1163 [1:43:55<3:54:47, 17.43s/it]\n",
      "Train:  31%|███       | 355/1163 [1:43:55<3:54:47, 17.43s/it]\n",
      "Train:  31%|███       | 356/1163 [1:44:12<3:53:26, 17.36s/it]\n",
      "Train:  31%|███       | 357/1163 [1:44:29<3:51:32, 17.24s/it]\n",
      "Train:  31%|███       | 358/1163 [1:44:46<3:49:20, 17.09s/it]\n",
      "Train:  31%|███       | 359/1163 [1:45:03<3:47:37, 16.99s/it]\n",
      "Train:  31%|███       | 360/1163 [1:45:20<3:47:41, 17.01s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  31%|███       | 360/1163 [1:45:20<3:47:41, 17.01s/it]\n",
      "Train:  31%|███       | 360/1163 [1:45:20<3:47:41, 17.01s/it]\n",
      "Train:  31%|███       | 361/1163 [1:45:37<3:48:56, 17.13s/it]\n",
      "Train:  31%|███       | 362/1163 [1:45:55<3:49:15, 17.17s/it]\n",
      "Train:  31%|███       | 363/1163 [1:46:14<3:57:19, 17.80s/it]\n",
      "Train:  31%|███▏      | 364/1163 [1:46:32<3:56:33, 17.76s/it]\n",
      "Train:  31%|███▏      | 365/1163 [1:46:49<3:55:10, 17.68s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  31%|███▏      | 365/1163 [1:46:49<3:55:10, 17.68s/it]\n",
      "Train:  31%|███▏      | 365/1163 [1:46:49<3:55:10, 17.68s/it]\n",
      "Train:  31%|███▏      | 366/1163 [1:47:06<3:51:09, 17.40s/it]\n",
      "Train:  32%|███▏      | 367/1163 [1:47:22<3:47:18, 17.13s/it]\n",
      "Train:  32%|███▏      | 368/1163 [1:47:40<3:48:58, 17.28s/it]\n",
      "Train:  32%|███▏      | 369/1163 [1:47:58<3:52:36, 17.58s/it]\n",
      "Train:  32%|███▏      | 370/1163 [1:48:16<3:52:17, 17.58s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  32%|███▏      | 370/1163 [1:48:16<3:52:17, 17.58s/it]\n",
      "Train:  32%|███▏      | 370/1163 [1:48:16<3:52:17, 17.58s/it]\n",
      "Train:  32%|███▏      | 371/1163 [1:48:33<3:51:19, 17.52s/it]\n",
      "Train:  32%|███▏      | 372/1163 [1:48:50<3:48:33, 17.34s/it]\n",
      "Train:  32%|███▏      | 373/1163 [1:49:07<3:46:00, 17.17s/it]\n",
      "Train:  32%|███▏      | 374/1163 [1:49:25<3:48:08, 17.35s/it]\n",
      "Train:  32%|███▏      | 375/1163 [1:49:42<3:46:18, 17.23s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  32%|███▏      | 375/1163 [1:49:42<3:46:18, 17.23s/it]\n",
      "Train:  32%|███▏      | 375/1163 [1:49:42<3:46:18, 17.23s/it]\n",
      "Train:  32%|███▏      | 376/1163 [1:49:59<3:48:19, 17.41s/it]\n",
      "Train:  32%|███▏      | 377/1163 [1:50:17<3:49:47, 17.54s/it]\n",
      "Train:  33%|███▎      | 378/1163 [1:50:35<3:52:08, 17.74s/it]\n",
      "Train:  33%|███▎      | 379/1163 [1:50:54<3:54:39, 17.96s/it]\n",
      "Train:  33%|███▎      | 380/1163 [1:51:11<3:52:36, 17.82s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  33%|███▎      | 380/1163 [1:51:11<3:52:36, 17.82s/it]\n",
      "Train:  33%|███▎      | 380/1163 [1:51:11<3:52:36, 17.82s/it]\n",
      "Train:  33%|███▎      | 381/1163 [1:51:28<3:47:56, 17.49s/it]\n",
      "Train:  33%|███▎      | 382/1163 [1:51:47<3:52:51, 17.89s/it]\n",
      "Train:  33%|███▎      | 383/1163 [1:52:06<3:57:04, 18.24s/it]\n",
      "Train:  33%|███▎      | 384/1163 [1:52:23<3:51:22, 17.82s/it]\n",
      "Train:  33%|███▎      | 385/1163 [1:52:41<3:53:02, 17.97s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  33%|███▎      | 385/1163 [1:52:41<3:53:02, 17.97s/it]\n",
      "Train:  33%|███▎      | 385/1163 [1:52:41<3:53:02, 17.97s/it]\n",
      "Train:  33%|███▎      | 386/1163 [1:52:59<3:53:14, 18.01s/it]\n",
      "Train:  33%|███▎      | 387/1163 [1:53:16<3:49:02, 17.71s/it]\n",
      "Train:  33%|███▎      | 388/1163 [1:53:34<3:46:54, 17.57s/it]\n",
      "Train:  33%|███▎      | 389/1163 [1:53:51<3:45:26, 17.48s/it]\n",
      "Train:  34%|███▎      | 390/1163 [1:54:07<3:41:59, 17.23s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  34%|███▎      | 390/1163 [1:54:07<3:41:59, 17.23s/it]\n",
      "Train:  34%|███▎      | 390/1163 [1:54:07<3:41:59, 17.23s/it]\n",
      "Train:  34%|███▎      | 391/1163 [1:54:24<3:40:02, 17.10s/it]\n",
      "Train:  34%|███▎      | 392/1163 [1:54:41<3:39:36, 17.09s/it]\n",
      "Train:  34%|███▍      | 393/1163 [1:54:58<3:38:43, 17.04s/it]\n",
      "Train:  34%|███▍      | 394/1163 [1:55:15<3:37:38, 16.98s/it]\n",
      "Train:  34%|███▍      | 395/1163 [1:55:33<3:40:29, 17.23s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  34%|███▍      | 395/1163 [1:55:33<3:40:29, 17.23s/it]\n",
      "Train:  34%|███▍      | 395/1163 [1:55:33<3:40:29, 17.23s/it]\n",
      "Train:  34%|███▍      | 396/1163 [1:55:50<3:38:48, 17.12s/it]\n",
      "Train:  34%|███▍      | 397/1163 [1:56:08<3:41:00, 17.31s/it]\n",
      "Train:  34%|███▍      | 398/1163 [1:56:25<3:40:38, 17.30s/it]\n",
      "Train:  34%|███▍      | 399/1163 [1:56:42<3:41:46, 17.42s/it]\n",
      "Train:  34%|███▍      | 400/1163 [1:57:00<3:40:47, 17.36s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  34%|███▍      | 400/1163 [1:57:00<3:40:47, 17.36s/it]\n",
      "Train:  34%|███▍      | 400/1163 [1:57:00<3:40:47, 17.36s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v12-20250928-082402/checkpoint-400\n",
      "\n",
      "Train:  34%|███▍      | 401/1163 [1:57:20<3:51:15, 18.21s/it]\n",
      "Train:  35%|███▍      | 402/1163 [1:57:37<3:46:16, 17.84s/it]\n",
      "Train:  35%|███▍      | 403/1163 [1:57:54<3:44:54, 17.76s/it]\n",
      "Train:  35%|███▍      | 404/1163 [1:58:13<3:46:49, 17.93s/it]\n",
      "Train:  35%|███▍      | 405/1163 [1:58:30<3:44:17, 17.75s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  35%|███▍      | 405/1163 [1:58:30<3:44:17, 17.75s/it]\n",
      "Train:  35%|███▍      | 405/1163 [1:58:30<3:44:17, 17.75s/it]\n",
      "Train:  35%|███▍      | 406/1163 [1:58:47<3:42:33, 17.64s/it]\n",
      "Train:  35%|███▍      | 407/1163 [1:59:05<3:41:59, 17.62s/it]\n",
      "Train:  35%|███▌      | 408/1163 [1:59:24<3:45:36, 17.93s/it]\n",
      "Train:  35%|███▌      | 409/1163 [1:59:42<3:46:40, 18.04s/it]\n",
      "Train:  35%|███▌      | 410/1163 [1:59:59<3:42:23, 17.72s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  35%|███▌      | 410/1163 [1:59:59<3:42:23, 17.72s/it]\n",
      "Train:  35%|███▌      | 410/1163 [1:59:59<3:42:23, 17.72s/it]\n",
      "Train:  35%|███▌      | 411/1163 [2:00:16<3:38:46, 17.45s/it]\n",
      "Train:  35%|███▌      | 412/1163 [2:00:34<3:41:30, 17.70s/it]\n",
      "Train:  36%|███▌      | 413/1163 [2:00:52<3:40:09, 17.61s/it]\n",
      "Train:  36%|███▌      | 414/1163 [2:01:10<3:41:45, 17.76s/it]\n",
      "Train:  36%|███▌      | 415/1163 [2:01:27<3:39:19, 17.59s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  36%|███▌      | 415/1163 [2:01:27<3:39:19, 17.59s/it]\n",
      "Train:  36%|███▌      | 415/1163 [2:01:27<3:39:19, 17.59s/it]\n",
      "Train:  36%|███▌      | 416/1163 [2:01:46<3:45:22, 18.10s/it]\n",
      "Train:  36%|███▌      | 417/1163 [2:02:03<3:38:44, 17.59s/it]\n",
      "Train:  36%|███▌      | 418/1163 [2:02:19<3:35:30, 17.36s/it]\n",
      "Train:  36%|███▌      | 419/1163 [2:02:37<3:36:43, 17.48s/it]\n",
      "Train:  36%|███▌      | 420/1163 [2:02:55<3:36:34, 17.49s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  36%|███▌      | 420/1163 [2:02:55<3:36:34, 17.49s/it]\n",
      "Train:  36%|███▌      | 420/1163 [2:02:55<3:36:34, 17.49s/it]\n",
      "Train:  36%|███▌      | 421/1163 [2:03:12<3:36:26, 17.50s/it]\n",
      "Train:  36%|███▋      | 422/1163 [2:03:31<3:39:51, 17.80s/it]\n",
      "Train:  36%|███▋      | 423/1163 [2:03:48<3:36:49, 17.58s/it]\n",
      "Train:  36%|███▋      | 424/1163 [2:04:05<3:34:18, 17.40s/it]\n",
      "Train:  37%|███▋      | 425/1163 [2:04:22<3:35:00, 17.48s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  37%|███▋      | 425/1163 [2:04:22<3:35:00, 17.48s/it]\n",
      "Train:  37%|███▋      | 425/1163 [2:04:22<3:35:00, 17.48s/it]\n",
      "Train:  37%|███▋      | 426/1163 [2:04:40<3:33:48, 17.41s/it]\n",
      "Train:  37%|███▋      | 427/1163 [2:04:57<3:34:04, 17.45s/it]\n",
      "Train:  37%|███▋      | 428/1163 [2:05:14<3:31:57, 17.30s/it]\n",
      "Train:  37%|███▋      | 429/1163 [2:05:32<3:33:48, 17.48s/it]\n",
      "Train:  37%|███▋      | 430/1163 [2:05:49<3:31:33, 17.32s/it]\n",
      "                                                             \n",
      "{'loss': 2.16804752, 'token_acc': 0.54389344, 'grad_norm': 1.26073551, 'learning_rate': 8.958e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056952, 'epoch': 0.25, 'global_step/max_steps': '290/1163', 'percentage': '24.94%', 'elapsed_time': '1h 24m 51s', 'remaining_time': '4h 15m 27s'}\n",
      "{'loss': 1.99512386, 'token_acc': 0.57661004, 'grad_norm': 1.02263045, 'learning_rate': 8.914e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056958, 'epoch': 0.25, 'global_step/max_steps': '295/1163', 'percentage': '25.37%', 'elapsed_time': '1h 26m 18s', 'remaining_time': '4h 13m 58s'}\n",
      "{'loss': 2.1291666, 'token_acc': 0.54228142, 'grad_norm': 1.03843689, 'learning_rate': 8.87e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056964, 'epoch': 0.26, 'global_step/max_steps': '300/1163', 'percentage': '25.80%', 'elapsed_time': '1h 27m 46s', 'remaining_time': '4h 12m 28s'}\n",
      "{'loss': 2.10303478, 'token_acc': 0.55117468, 'grad_norm': 0.90961856, 'learning_rate': 8.824e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056955, 'epoch': 0.26, 'global_step/max_steps': '305/1163', 'percentage': '26.23%', 'elapsed_time': '1h 29m 14s', 'remaining_time': '4h 11m 3s'}\n",
      "{'loss': 2.14464397, 'token_acc': 0.54732751, 'grad_norm': 1.23855257, 'learning_rate': 8.778e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056942, 'epoch': 0.27, 'global_step/max_steps': '310/1163', 'percentage': '26.66%', 'elapsed_time': '1h 30m 43s', 'remaining_time': '4h 9m 39s'}\n",
      "{'loss': 2.01810608, 'token_acc': 0.56857925, 'grad_norm': 1.23398733, 'learning_rate': 8.731e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056945, 'epoch': 0.27, 'global_step/max_steps': '315/1163', 'percentage': '27.09%', 'elapsed_time': '1h 32m 11s', 'remaining_time': '4h 8m 10s'}\n",
      "{'loss': 2.09357548, 'token_acc': 0.55656986, 'grad_norm': 1.06794071, 'learning_rate': 8.683e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056966, 'epoch': 0.28, 'global_step/max_steps': '320/1163', 'percentage': '27.52%', 'elapsed_time': '1h 33m 36s', 'remaining_time': '4h 6m 37s'}\n",
      "{'loss': 2.02187042, 'token_acc': 0.56704895, 'grad_norm': 1.19116354, 'learning_rate': 8.635e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056967, 'epoch': 0.28, 'global_step/max_steps': '325/1163', 'percentage': '27.94%', 'elapsed_time': '1h 35m 4s', 'remaining_time': '4h 5m 9s'}\n",
      "{'loss': 2.2272068, 'token_acc': 0.53728594, 'grad_norm': 1.17909801, 'learning_rate': 8.585e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.05693, 'epoch': 0.28, 'global_step/max_steps': '330/1163', 'percentage': '28.37%', 'elapsed_time': '1h 36m 36s', 'remaining_time': '4h 3m 50s'}\n",
      "{'loss': 1.905093, 'token_acc': 0.58841773, 'grad_norm': 1.13946784, 'learning_rate': 8.536e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056952, 'epoch': 0.29, 'global_step/max_steps': '335/1163', 'percentage': '28.80%', 'elapsed_time': '1h 38m 1s', 'remaining_time': '4h 2m 17s'}\n",
      "{'loss': 2.11088009, 'token_acc': 0.55013408, 'grad_norm': 1.14692163, 'learning_rate': 8.485e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056945, 'epoch': 0.29, 'global_step/max_steps': '340/1163', 'percentage': '29.23%', 'elapsed_time': '1h 39m 30s', 'remaining_time': '4h 0m 51s'}\n",
      "{'loss': 1.97739811, 'token_acc': 0.57454412, 'grad_norm': 0.97687554, 'learning_rate': 8.434e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056938, 'epoch': 0.3, 'global_step/max_steps': '345/1163', 'percentage': '29.66%', 'elapsed_time': '1h 40m 58s', 'remaining_time': '3h 59m 25s'}\n",
      "{'loss': 2.06907921, 'token_acc': 0.55627448, 'grad_norm': 1.08071351, 'learning_rate': 8.381e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056929, 'epoch': 0.3, 'global_step/max_steps': '350/1163', 'percentage': '30.09%', 'elapsed_time': '1h 42m 27s', 'remaining_time': '3h 58m 0s'}\n",
      "{'loss': 2.09404392, 'token_acc': 0.5589527, 'grad_norm': 1.33335912, 'learning_rate': 8.329e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056926, 'epoch': 0.31, 'global_step/max_steps': '355/1163', 'percentage': '30.52%', 'elapsed_time': '1h 43m 55s', 'remaining_time': '3h 56m 32s'}\n",
      "{'loss': 1.93526173, 'token_acc': 0.58630795, 'grad_norm': 1.05518961, 'learning_rate': 8.275e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056954, 'epoch': 0.31, 'global_step/max_steps': '360/1163', 'percentage': '30.95%', 'elapsed_time': '1h 45m 20s', 'remaining_time': '3h 54m 58s'}\n",
      "{'loss': 1.97805653, 'token_acc': 0.57539766, 'grad_norm': 1.03354621, 'learning_rate': 8.221e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056943, 'epoch': 0.31, 'global_step/max_steps': '365/1163', 'percentage': '31.38%', 'elapsed_time': '1h 46m 49s', 'remaining_time': '3h 53m 33s'}\n",
      "{'loss': 1.97184887, 'token_acc': 0.57015794, 'grad_norm': 1.0936265, 'learning_rate': 8.166e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056952, 'epoch': 0.32, 'global_step/max_steps': '370/1163', 'percentage': '31.81%', 'elapsed_time': '1h 48m 16s', 'remaining_time': '3h 52m 3s'}\n",
      "{'loss': 2.04221287, 'token_acc': 0.56698257, 'grad_norm': 1.1561687, 'learning_rate': 8.111e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056969, 'epoch': 0.32, 'global_step/max_steps': '375/1163', 'percentage': '32.24%', 'elapsed_time': '1h 49m 42s', 'remaining_time': '3h 50m 31s'}\n",
      "{'loss': 1.97194958, 'token_acc': 0.57887654, 'grad_norm': 0.97449541, 'learning_rate': 8.055e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056951, 'epoch': 0.33, 'global_step/max_steps': '380/1163', 'percentage': '32.67%', 'elapsed_time': '1h 51m 11s', 'remaining_time': '3h 49m 7s'}\n",
      "{'loss': 2.05603046, 'token_acc': 0.55865139, 'grad_norm': 0.95542729, 'learning_rate': 7.998e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056935, 'epoch': 0.33, 'global_step/max_steps': '385/1163', 'percentage': '33.10%', 'elapsed_time': '1h 52m 41s', 'remaining_time': '3h 47m 43s'}\n",
      "{'loss': 1.97323418, 'token_acc': 0.57723351, 'grad_norm': 1.25345099, 'learning_rate': 7.941e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056948, 'epoch': 0.34, 'global_step/max_steps': '390/1163', 'percentage': '33.53%', 'elapsed_time': '1h 54m 7s', 'remaining_time': '3h 46m 12s'}\n",
      "{'loss': 2.02131443, 'token_acc': 0.57078375, 'grad_norm': 1.10866535, 'learning_rate': 7.883e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056967, 'epoch': 0.34, 'global_step/max_steps': '395/1163', 'percentage': '33.96%', 'elapsed_time': '1h 55m 33s', 'remaining_time': '3h 44m 40s'}\n",
      "{'loss': 2.02035179, 'token_acc': 0.57074749, 'grad_norm': 1.20818949, 'learning_rate': 7.825e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056975, 'epoch': 0.34, 'global_step/max_steps': '400/1163', 'percentage': '34.39%', 'elapsed_time': '1h 57m 0s', 'remaining_time': '3h 43m 11s'}\n",
      "{'loss': 2.02529659, 'token_acc': 0.56629093, 'grad_norm': 1.08706915, 'learning_rate': 7.766e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056954, 'epoch': 0.35, 'global_step/max_steps': '405/1163', 'percentage': '34.82%', 'elapsed_time': '1h 58m 30s', 'remaining_time': '3h 41m 48s'}\n",
      "{'loss': 2.03842773, 'token_acc': 0.56122023, 'grad_norm': 1.30224645, 'learning_rate': 7.706e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056945, 'epoch': 0.35, 'global_step/max_steps': '410/1163', 'percentage': '35.25%', 'elapsed_time': '1h 59m 59s', 'remaining_time': '3h 40m 22s'}\n",
      "{'loss': 2.07365532, 'token_acc': 0.55624828, 'grad_norm': 1.2383585, 'learning_rate': 7.646e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056945, 'epoch': 0.36, 'global_step/max_steps': '415/1163', 'percentage': '35.68%', 'elapsed_time': '2h 1m 27s', 'remaining_time': '3h 38m 54s'}\n",
      "{'loss': 2.05797348, 'token_acc': 0.55938655, 'grad_norm': 1.18203592, 'learning_rate': 7.586e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056945, 'epoch': 0.36, 'global_step/max_steps': '420/1163', 'percentage': '36.11%', 'elapsed_time': '2h 2m 55s', 'remaining_time': '3h 37m 26s'}\n",
      "{'loss': 1.99815521, 'token_acc': 0.56666112, 'grad_norm': 1.49480736, 'learning_rate': 7.525e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056946, 'epoch': 0.37, 'global_step/max_steps': '425/1163', 'percentage': '36.54%', 'elapsed_time': '2h 4m 22s', 'remaining_time': '3h 35m 58s'}\n",
      "{'loss': 1.98778801, 'token_acc': 0.56744711, 'grad_norm': 1.19634819, 'learning_rate': 7.463e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056955, 'epoch': 0.37, 'global_step/max_steps': '430/1163', 'percentage': '36.97%', 'elapsed_time': '2h 5m 49s', 'remaining_time': '3h 34m 29s'}\n",
      "Train:  37%|███▋      | 430/1163 [2:05:49<3:31:33, 17.32s/it]\n",
      "Train:  37%|███▋      | 430/1163 [2:05:49<3:31:33, 17.32s/it]\n",
      "Train:  37%|███▋      | 431/1163 [2:06:06<3:30:59, 17.30s/it]\n",
      "Train:  37%|███▋      | 432/1163 [2:06:24<3:32:09, 17.41s/it]\n",
      "Train:  37%|███▋      | 433/1163 [2:06:41<3:31:25, 17.38s/it]\n",
      "Train:  37%|███▋      | 434/1163 [2:06:59<3:31:29, 17.41s/it]\n",
      "Train:  37%|███▋      | 435/1163 [2:07:16<3:32:13, 17.49s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  37%|███▋      | 435/1163 [2:07:16<3:32:13, 17.49s/it]\n",
      "Train:  37%|███▋      | 435/1163 [2:07:16<3:32:13, 17.49s/it]\n",
      "Train:  37%|███▋      | 436/1163 [2:07:34<3:34:06, 17.67s/it]\n",
      "Train:  38%|███▊      | 437/1163 [2:07:51<3:30:06, 17.36s/it]\n",
      "Train:  38%|███▊      | 438/1163 [2:08:09<3:31:58, 17.54s/it]\n",
      "Train:  38%|███▊      | 439/1163 [2:08:27<3:31:39, 17.54s/it]\n",
      "Train:  38%|███▊      | 440/1163 [2:08:43<3:28:58, 17.34s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  38%|███▊      | 440/1163 [2:08:43<3:28:58, 17.34s/it]\n",
      "Train:  38%|███▊      | 440/1163 [2:08:43<3:28:58, 17.34s/it]\n",
      "Train:  38%|███▊      | 441/1163 [2:09:01<3:28:53, 17.36s/it]\n",
      "Train:  38%|███▊      | 442/1163 [2:09:17<3:25:37, 17.11s/it]\n",
      "Train:  38%|███▊      | 443/1163 [2:09:36<3:30:33, 17.55s/it]\n",
      "Train:  38%|███▊      | 444/1163 [2:09:54<3:31:23, 17.64s/it]\n",
      "Train:  38%|███▊      | 445/1163 [2:10:12<3:34:53, 17.96s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  38%|███▊      | 445/1163 [2:10:12<3:34:53, 17.96s/it]\n",
      "Train:  38%|███▊      | 445/1163 [2:10:12<3:34:53, 17.96s/it]\n",
      "Train:  38%|███▊      | 446/1163 [2:10:30<3:34:26, 17.94s/it]\n",
      "Train:  38%|███▊      | 447/1163 [2:10:47<3:31:00, 17.68s/it]\n",
      "Train:  39%|███▊      | 448/1163 [2:11:05<3:29:32, 17.58s/it]\n",
      "Train:  39%|███▊      | 449/1163 [2:11:23<3:30:43, 17.71s/it]\n",
      "Train:  39%|███▊      | 450/1163 [2:11:40<3:28:48, 17.57s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  39%|███▊      | 450/1163 [2:11:40<3:28:48, 17.57s/it]\n",
      "Train:  39%|███▊      | 450/1163 [2:11:40<3:28:48, 17.57s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v12-20250928-082402/checkpoint-450\n",
      "\n",
      "Train:  39%|███▉      | 451/1163 [2:11:59<3:34:07, 18.04s/it]\n",
      "Train:  39%|███▉      | 452/1163 [2:12:18<3:37:03, 18.32s/it]\n",
      "Train:  39%|███▉      | 453/1163 [2:12:35<3:32:53, 17.99s/it]\n",
      "Train:  39%|███▉      | 454/1163 [2:12:53<3:30:30, 17.82s/it]\n",
      "Train:  39%|███▉      | 455/1163 [2:13:12<3:34:29, 18.18s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  39%|███▉      | 455/1163 [2:13:12<3:34:29, 18.18s/it]\n",
      "Train:  39%|███▉      | 455/1163 [2:13:12<3:34:29, 18.18s/it]\n",
      "Train:  39%|███▉      | 456/1163 [2:13:30<3:32:53, 18.07s/it]\n",
      "Train:  39%|███▉      | 457/1163 [2:13:50<3:39:22, 18.64s/it]\n",
      "Train:  39%|███▉      | 458/1163 [2:14:07<3:34:02, 18.22s/it]\n",
      "Train:  39%|███▉      | 459/1163 [2:14:24<3:30:38, 17.95s/it]\n",
      "Train:  40%|███▉      | 460/1163 [2:14:41<3:26:32, 17.63s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  40%|███▉      | 460/1163 [2:14:41<3:26:32, 17.63s/it]\n",
      "Train:  40%|███▉      | 460/1163 [2:14:41<3:26:32, 17.63s/it]\n",
      "Train:  40%|███▉      | 461/1163 [2:14:59<3:26:33, 17.65s/it]\n",
      "Train:  40%|███▉      | 462/1163 [2:15:16<3:25:03, 17.55s/it]\n",
      "Train:  40%|███▉      | 463/1163 [2:15:35<3:30:21, 18.03s/it]\n",
      "Train:  40%|███▉      | 464/1163 [2:15:52<3:25:50, 17.67s/it]\n",
      "Train:  40%|███▉      | 465/1163 [2:16:10<3:26:01, 17.71s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  40%|███▉      | 465/1163 [2:16:10<3:26:01, 17.71s/it]\n",
      "Train:  40%|███▉      | 465/1163 [2:16:10<3:26:01, 17.71s/it]\n",
      "Train:  40%|████      | 466/1163 [2:16:27<3:22:39, 17.44s/it]\n",
      "Train:  40%|████      | 467/1163 [2:16:43<3:19:20, 17.19s/it]\n",
      "Train:  40%|████      | 468/1163 [2:16:59<3:14:55, 16.83s/it]\n",
      "Train:  40%|████      | 469/1163 [2:17:19<3:24:47, 17.71s/it]\n",
      "Train:  40%|████      | 470/1163 [2:17:35<3:20:13, 17.34s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  40%|████      | 470/1163 [2:17:35<3:20:13, 17.34s/it]\n",
      "Train:  40%|████      | 470/1163 [2:17:35<3:20:13, 17.34s/it]\n",
      "Train:  40%|████      | 471/1163 [2:17:57<3:35:39, 18.70s/it]\n",
      "Train:  41%|████      | 472/1163 [2:18:14<3:28:58, 18.15s/it]\n",
      "Train:  41%|████      | 473/1163 [2:18:32<3:27:20, 18.03s/it]\n",
      "Train:  41%|████      | 474/1163 [2:18:51<3:29:50, 18.27s/it]\n",
      "Train:  41%|████      | 475/1163 [2:19:08<3:27:27, 18.09s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  41%|████      | 475/1163 [2:19:08<3:27:27, 18.09s/it]\n",
      "Train:  41%|████      | 475/1163 [2:19:08<3:27:27, 18.09s/it]\n",
      "Train:  41%|████      | 476/1163 [2:19:27<3:30:08, 18.35s/it]\n",
      "Train:  41%|████      | 477/1163 [2:19:45<3:27:06, 18.11s/it]\n",
      "Train:  41%|████      | 478/1163 [2:20:03<3:26:47, 18.11s/it]\n",
      "Train:  41%|████      | 479/1163 [2:20:20<3:22:59, 17.81s/it]\n",
      "Train:  41%|████▏     | 480/1163 [2:20:38<3:23:48, 17.90s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  41%|████▏     | 480/1163 [2:20:38<3:23:48, 17.90s/it]\n",
      "Train:  41%|████▏     | 480/1163 [2:20:38<3:23:48, 17.90s/it]\n",
      "Train:  41%|████▏     | 481/1163 [2:20:55<3:19:30, 17.55s/it]\n",
      "Train:  41%|████▏     | 482/1163 [2:21:12<3:16:13, 17.29s/it]\n",
      "Train:  42%|████▏     | 483/1163 [2:21:29<3:17:20, 17.41s/it]\n",
      "Train:  42%|████▏     | 484/1163 [2:21:47<3:15:59, 17.32s/it]\n",
      "Train:  42%|████▏     | 485/1163 [2:22:03<3:13:23, 17.11s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  42%|████▏     | 485/1163 [2:22:03<3:13:23, 17.11s/it]\n",
      "Train:  42%|████▏     | 485/1163 [2:22:03<3:13:23, 17.11s/it]\n",
      "Train:  42%|████▏     | 486/1163 [2:22:20<3:13:01, 17.11s/it]\n",
      "Train:  42%|████▏     | 487/1163 [2:22:38<3:15:38, 17.36s/it]\n",
      "Train:  42%|████▏     | 488/1163 [2:22:56<3:16:35, 17.47s/it]\n",
      "Train:  42%|████▏     | 489/1163 [2:23:13<3:14:11, 17.29s/it]\n",
      "Train:  42%|████▏     | 490/1163 [2:23:30<3:12:48, 17.19s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  42%|████▏     | 490/1163 [2:23:30<3:12:48, 17.19s/it]\n",
      "Train:  42%|████▏     | 490/1163 [2:23:30<3:12:48, 17.19s/it]\n",
      "Train:  42%|████▏     | 491/1163 [2:23:47<3:11:46, 17.12s/it]\n",
      "Train:  42%|████▏     | 492/1163 [2:24:04<3:12:25, 17.21s/it]\n",
      "Train:  42%|████▏     | 493/1163 [2:24:21<3:11:44, 17.17s/it]\n",
      "Train:  42%|████▏     | 494/1163 [2:24:39<3:12:55, 17.30s/it]\n",
      "Train:  43%|████▎     | 495/1163 [2:24:57<3:14:47, 17.50s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  43%|████▎     | 495/1163 [2:24:57<3:14:47, 17.50s/it]\n",
      "Train:  43%|████▎     | 495/1163 [2:24:57<3:14:47, 17.50s/it]\n",
      "Train:  43%|████▎     | 496/1163 [2:25:14<3:14:47, 17.52s/it]\n",
      "Train:  43%|████▎     | 497/1163 [2:25:32<3:14:24, 17.51s/it]\n",
      "Train:  43%|████▎     | 498/1163 [2:25:51<3:18:33, 17.91s/it]\n",
      "Train:  43%|████▎     | 499/1163 [2:26:10<3:21:33, 18.21s/it]\n",
      "Train:  43%|████▎     | 500/1163 [2:26:27<3:17:08, 17.84s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  43%|████▎     | 500/1163 [2:26:27<3:17:08, 17.84s/it]\n",
      "Train:  43%|████▎     | 500/1163 [2:26:27<3:17:08, 17.84s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v12-20250928-082402/checkpoint-500\n",
      "\n",
      "Train:  43%|████▎     | 501/1163 [2:26:46<3:21:39, 18.28s/it]\n",
      "Train:  43%|████▎     | 502/1163 [2:27:03<3:16:35, 17.85s/it]\n",
      "Train:  43%|████▎     | 503/1163 [2:27:20<3:13:58, 17.63s/it]\n",
      "Train:  43%|████▎     | 504/1163 [2:27:38<3:15:21, 17.79s/it]\n",
      "Train:  43%|████▎     | 505/1163 [2:27:55<3:12:36, 17.56s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  43%|████▎     | 505/1163 [2:27:55<3:12:36, 17.56s/it]\n",
      "Train:  43%|████▎     | 505/1163 [2:27:55<3:12:36, 17.56s/it]\n",
      "Train:  44%|████▎     | 506/1163 [2:28:15<3:18:32, 18.13s/it]\n",
      "Train:  44%|████▎     | 507/1163 [2:28:32<3:17:21, 18.05s/it]\n",
      "Train:  44%|████▎     | 508/1163 [2:28:51<3:18:50, 18.22s/it]\n",
      "Train:  44%|████▍     | 509/1163 [2:29:08<3:14:26, 17.84s/it]\n",
      "Train:  44%|████▍     | 510/1163 [2:29:25<3:12:19, 17.67s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  44%|████▍     | 510/1163 [2:29:25<3:12:19, 17.67s/it]\n",
      "Train:  44%|████▍     | 510/1163 [2:29:25<3:12:19, 17.67s/it]\n",
      "Train:  44%|████▍     | 511/1163 [2:29:42<3:09:23, 17.43s/it]\n",
      "Train:  44%|████▍     | 512/1163 [2:30:00<3:09:45, 17.49s/it]\n",
      "Train:  44%|████▍     | 513/1163 [2:30:17<3:09:50, 17.52s/it]\n",
      "Train:  44%|████▍     | 514/1163 [2:30:36<3:13:05, 17.85s/it]\n",
      "Train:  44%|████▍     | 515/1163 [2:30:56<3:18:35, 18.39s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  44%|████▍     | 515/1163 [2:30:56<3:18:35, 18.39s/it]\n",
      "Train:  44%|████▍     | 515/1163 [2:30:56<3:18:35, 18.39s/it]\n",
      "Train:  44%|████▍     | 516/1163 [2:31:13<3:16:14, 18.20s/it]\n",
      "Train:  44%|████▍     | 517/1163 [2:31:31<3:14:56, 18.11s/it]\n",
      "Train:  45%|████▍     | 518/1163 [2:31:49<3:12:43, 17.93s/it]\n",
      "Train:  45%|████▍     | 519/1163 [2:32:06<3:11:17, 17.82s/it]\n",
      "Train:  45%|████▍     | 520/1163 [2:32:24<3:10:46, 17.80s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  45%|████▍     | 520/1163 [2:32:24<3:10:46, 17.80s/it]\n",
      "Train:  45%|████▍     | 520/1163 [2:32:24<3:10:46, 17.80s/it]\n",
      "Train:  45%|████▍     | 521/1163 [2:32:41<3:08:05, 17.58s/it]\n",
      "Train:  45%|████▍     | 522/1163 [2:32:59<3:08:04, 17.60s/it]\n",
      "Train:  45%|████▍     | 523/1163 [2:33:18<3:11:51, 17.99s/it]\n",
      "Train:  45%|████▌     | 524/1163 [2:33:36<3:11:42, 18.00s/it]\n",
      "Train:  45%|████▌     | 525/1163 [2:33:53<3:09:35, 17.83s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  45%|████▌     | 525/1163 [2:33:53<3:09:35, 17.83s/it]\n",
      "Train:  45%|████▌     | 525/1163 [2:33:53<3:09:35, 17.83s/it]\n",
      "Train:  45%|████▌     | 526/1163 [2:34:10<3:05:23, 17.46s/it]\n",
      "Train:  45%|████▌     | 527/1163 [2:34:27<3:04:01, 17.36s/it]\n",
      "Train:  45%|████▌     | 528/1163 [2:34:44<3:01:48, 17.18s/it]\n",
      "Train:  45%|████▌     | 529/1163 [2:35:03<3:09:10, 17.90s/it]\n",
      "Train:  46%|████▌     | 530/1163 [2:35:20<3:05:42, 17.60s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  46%|████▌     | 530/1163 [2:35:20<3:05:42, 17.60s/it]\n",
      "Train:  46%|████▌     | 530/1163 [2:35:20<3:05:42, 17.60s/it]\n",
      "Train:  46%|████▌     | 531/1163 [2:35:38<3:06:53, 17.74s/it]\n",
      "Train:  46%|████▌     | 532/1163 [2:35:55<3:04:29, 17.54s/it]\n",
      "Train:  46%|████▌     | 533/1163 [2:36:14<3:07:14, 17.83s/it]\n",
      "Train:  46%|████▌     | 534/1163 [2:36:31<3:04:25, 17.59s/it]\n",
      "Train:  46%|████▌     | 535/1163 [2:36:48<3:02:26, 17.43s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  46%|████▌     | 535/1163 [2:36:48<3:02:26, 17.43s/it]\n",
      "Train:  46%|████▌     | 535/1163 [2:36:48<3:02:26, 17.43s/it]\n",
      "Train:  46%|████▌     | 536/1163 [2:37:06<3:04:28, 17.65s/it]\n",
      "Train:  46%|████▌     | 537/1163 [2:37:23<3:02:13, 17.47s/it]\n",
      "Train:  46%|████▋     | 538/1163 [2:37:40<3:00:35, 17.34s/it]\n",
      "Train:  46%|████▋     | 539/1163 [2:37:57<2:57:59, 17.11s/it]\n",
      "Train:  46%|████▋     | 540/1163 [2:38:13<2:56:29, 17.00s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  46%|████▋     | 540/1163 [2:38:13<2:56:29, 17.00s/it]\n",
      "Train:  46%|████▋     | 540/1163 [2:38:13<2:56:29, 17.00s/it]\n",
      "Train:  47%|████▋     | 541/1163 [2:38:31<2:58:59, 17.27s/it]\n",
      "Train:  47%|████▋     | 542/1163 [2:38:49<3:00:26, 17.43s/it]\n",
      "Train:  47%|████▋     | 543/1163 [2:39:06<2:58:56, 17.32s/it]\n",
      "Train:  47%|████▋     | 544/1163 [2:39:23<2:58:28, 17.30s/it]\n",
      "Train:  47%|████▋     | 545/1163 [2:39:42<3:00:51, 17.56s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  47%|████▋     | 545/1163 [2:39:42<3:00:51, 17.56s/it]\n",
      "Train:  47%|████▋     | 545/1163 [2:39:42<3:00:51, 17.56s/it]\n",
      "Train:  47%|████▋     | 546/1163 [2:39:59<2:58:48, 17.39s/it]\n",
      "Train:  47%|████▋     | 547/1163 [2:40:15<2:56:59, 17.24s/it]\n",
      "Train:  47%|████▋     | 548/1163 [2:40:32<2:55:37, 17.13s/it]\n",
      "Train:  47%|████▋     | 549/1163 [2:40:49<2:54:59, 17.10s/it]\n",
      "Train:  47%|████▋     | 550/1163 [2:41:07<2:55:26, 17.17s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  47%|████▋     | 550/1163 [2:41:07<2:55:26, 17.17s/it]\n",
      "Train:  47%|████▋     | 550/1163 [2:41:07<2:55:26, 17.17s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v12-20250928-082402/checkpoint-550\n",
      "\n",
      "Train:  47%|████▋     | 551/1163 [2:41:26<3:00:29, 17.70s/it]\n",
      "Train:  47%|████▋     | 552/1163 [2:41:43<2:59:08, 17.59s/it]\n",
      "Train:  48%|████▊     | 553/1163 [2:42:01<2:59:49, 17.69s/it]\n",
      "Train:  48%|████▊     | 554/1163 [2:42:18<2:58:24, 17.58s/it]\n",
      "Train:  48%|████▊     | 555/1163 [2:42:35<2:57:09, 17.48s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  48%|████▊     | 555/1163 [2:42:35<2:57:09, 17.48s/it]\n",
      "Train:  48%|████▊     | 555/1163 [2:42:35<2:57:09, 17.48s/it]\n",
      "Train:  48%|████▊     | 556/1163 [2:42:55<3:04:11, 18.21s/it]\n",
      "Train:  48%|████▊     | 557/1163 [2:43:13<3:01:30, 17.97s/it]\n",
      "Train:  48%|████▊     | 558/1163 [2:43:30<3:00:13, 17.87s/it]\n",
      "Train:  48%|████▊     | 559/1163 [2:43:49<3:00:47, 17.96s/it]\n",
      "Train:  48%|████▊     | 560/1163 [2:44:06<2:59:54, 17.90s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  48%|████▊     | 560/1163 [2:44:06<2:59:54, 17.90s/it]\n",
      "Train:  48%|████▊     | 560/1163 [2:44:06<2:59:54, 17.90s/it]\n",
      "Train:  48%|████▊     | 561/1163 [2:44:25<3:02:09, 18.16s/it]\n",
      "Train:  48%|████▊     | 562/1163 [2:44:43<3:02:28, 18.22s/it]\n",
      "Train:  48%|████▊     | 563/1163 [2:45:01<3:00:13, 18.02s/it]\n",
      "Train:  48%|████▊     | 564/1163 [2:45:18<2:57:10, 17.75s/it]\n",
      "Train:  49%|████▊     | 565/1163 [2:45:36<2:57:17, 17.79s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  49%|████▊     | 565/1163 [2:45:36<2:57:17, 17.79s/it]\n",
      "Train:  49%|████▊     | 565/1163 [2:45:36<2:57:17, 17.79s/it]\n",
      "Train:  49%|████▊     | 566/1163 [2:45:53<2:55:49, 17.67s/it]\n",
      "Train:  49%|████▉     | 567/1163 [2:46:11<2:54:10, 17.53s/it]\n",
      "Train:  49%|████▉     | 568/1163 [2:46:27<2:51:28, 17.29s/it]\n",
      "Train:  49%|████▉     | 569/1163 [2:46:45<2:51:08, 17.29s/it]\n",
      "Train:  49%|████▉     | 570/1163 [2:47:02<2:50:01, 17.20s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  49%|████▉     | 570/1163 [2:47:02<2:50:01, 17.20s/it]\n",
      "Train:  49%|████▉     | 570/1163 [2:47:02<2:50:01, 17.20s/it]\n",
      "Train:  49%|████▉     | 571/1163 [2:47:19<2:49:26, 17.17s/it]\n",
      "Train:  49%|████▉     | 572/1163 [2:47:36<2:49:12, 17.18s/it]\n",
      "Train:  49%|████▉     | 573/1163 [2:47:53<2:48:39, 17.15s/it]\n",
      "Train:  49%|████▉     | 574/1163 [2:48:11<2:50:34, 17.38s/it]\n",
      "Train:  49%|████▉     | 575/1163 [2:48:28<2:49:02, 17.25s/it]\n",
      "                                                             \n",
      "{'loss': 1.98279152, 'token_acc': 0.57145357, 'grad_norm': 1.37313008, 'learning_rate': 7.401e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056958, 'epoch': 0.37, 'global_step/max_steps': '435/1163', 'percentage': '37.40%', 'elapsed_time': '2h 7m 16s', 'remaining_time': '3h 33m 0s'}\n",
      "{'loss': 1.86945915, 'token_acc': 0.59107064, 'grad_norm': 1.15157497, 'learning_rate': 7.338e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056963, 'epoch': 0.38, 'global_step/max_steps': '440/1163', 'percentage': '37.83%', 'elapsed_time': '2h 8m 43s', 'remaining_time': '3h 31m 31s'}\n",
      "{'loss': 2.03949699, 'token_acc': 0.56584537, 'grad_norm': 0.94051254, 'learning_rate': 7.275e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056954, 'epoch': 0.38, 'global_step/max_steps': '445/1163', 'percentage': '38.26%', 'elapsed_time': '2h 10m 12s', 'remaining_time': '3h 30m 6s'}\n",
      "{'loss': 1.94417248, 'token_acc': 0.57932986, 'grad_norm': 1.26108301, 'learning_rate': 7.211e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056955, 'epoch': 0.39, 'global_step/max_steps': '450/1163', 'percentage': '38.69%', 'elapsed_time': '2h 11m 40s', 'remaining_time': '3h 28m 37s'}\n",
      "{'loss': 1.99532871, 'token_acc': 0.57739344, 'grad_norm': 1.11096048, 'learning_rate': 7.147e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056927, 'epoch': 0.39, 'global_step/max_steps': '455/1163', 'percentage': '39.12%', 'elapsed_time': '2h 13m 12s', 'remaining_time': '3h 27m 16s'}\n",
      "{'loss': 1.88367691, 'token_acc': 0.59144629, 'grad_norm': 1.34318197, 'learning_rate': 7.083e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056917, 'epoch': 0.4, 'global_step/max_steps': '460/1163', 'percentage': '39.55%', 'elapsed_time': '2h 14m 41s', 'remaining_time': '3h 25m 50s'}\n",
      "{'loss': 1.93264637, 'token_acc': 0.58543234, 'grad_norm': 1.16214037, 'learning_rate': 7.018e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.05691, 'epoch': 0.4, 'global_step/max_steps': '465/1163', 'percentage': '39.98%', 'elapsed_time': '2h 16m 10s', 'remaining_time': '3h 24m 24s'}\n",
      "{'loss': 1.99707165, 'token_acc': 0.56948749, 'grad_norm': 1.36412144, 'learning_rate': 6.953e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056926, 'epoch': 0.4, 'global_step/max_steps': '470/1163', 'percentage': '40.41%', 'elapsed_time': '2h 17m 35s', 'remaining_time': '3h 22m 53s'}\n",
      "{'loss': 1.93294353, 'token_acc': 0.58467023, 'grad_norm': 1.28237331, 'learning_rate': 6.887e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.05689, 'epoch': 0.41, 'global_step/max_steps': '475/1163', 'percentage': '40.84%', 'elapsed_time': '2h 19m 8s', 'remaining_time': '3h 21m 32s'}\n",
      "{'loss': 2.03681698, 'token_acc': 0.56119938, 'grad_norm': 1.15812361, 'learning_rate': 6.821e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056877, 'epoch': 0.41, 'global_step/max_steps': '480/1163', 'percentage': '41.27%', 'elapsed_time': '2h 20m 38s', 'remaining_time': '3h 20m 7s'}\n",
      "{'loss': 1.94521408, 'token_acc': 0.58596808, 'grad_norm': 1.24735379, 'learning_rate': 6.755e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056898, 'epoch': 0.42, 'global_step/max_steps': '485/1163', 'percentage': '41.70%', 'elapsed_time': '2h 22m 3s', 'remaining_time': '3h 18m 35s'}\n",
      "{'loss': 1.95601864, 'token_acc': 0.58127543, 'grad_norm': 1.15553236, 'learning_rate': 6.688e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056906, 'epoch': 0.42, 'global_step/max_steps': '490/1163', 'percentage': '42.13%', 'elapsed_time': '2h 23m 30s', 'remaining_time': '3h 17m 5s'}\n",
      "{'loss': 1.95937786, 'token_acc': 0.5811174, 'grad_norm': 1.22359765, 'learning_rate': 6.621e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056912, 'epoch': 0.43, 'global_step/max_steps': '495/1163', 'percentage': '42.56%', 'elapsed_time': '2h 24m 57s', 'remaining_time': '3h 15m 36s'}\n",
      "{'loss': 1.9640274, 'token_acc': 0.58257797, 'grad_norm': 1.42487133, 'learning_rate': 6.553e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056899, 'epoch': 0.43, 'global_step/max_steps': '500/1163', 'percentage': '42.99%', 'elapsed_time': '2h 26m 27s', 'remaining_time': '3h 14m 11s'}\n",
      "{'loss': 1.98623676, 'token_acc': 0.56763879, 'grad_norm': 1.181113, 'learning_rate': 6.485e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056895, 'epoch': 0.43, 'global_step/max_steps': '505/1163', 'percentage': '43.42%', 'elapsed_time': '2h 27m 55s', 'remaining_time': '3h 12m 44s'}\n",
      "{'loss': 2.06040783, 'token_acc': 0.55504383, 'grad_norm': 1.07508647, 'learning_rate': 6.417e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056881, 'epoch': 0.44, 'global_step/max_steps': '510/1163', 'percentage': '43.85%', 'elapsed_time': '2h 29m 25s', 'remaining_time': '3h 11m 19s'}\n",
      "{'loss': 1.96764431, 'token_acc': 0.57249186, 'grad_norm': 1.14918447, 'learning_rate': 6.349e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056865, 'epoch': 0.44, 'global_step/max_steps': '515/1163', 'percentage': '44.28%', 'elapsed_time': '2h 30m 56s', 'remaining_time': '3h 9m 54s'}\n",
      "{'loss': 1.85876637, 'token_acc': 0.59484632, 'grad_norm': 1.35979652, 'learning_rate': 6.28e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056862, 'epoch': 0.45, 'global_step/max_steps': '520/1163', 'percentage': '44.71%', 'elapsed_time': '2h 32m 24s', 'remaining_time': '3h 8m 27s'}\n",
      "{'loss': 1.93120651, 'token_acc': 0.58791823, 'grad_norm': 1.19194877, 'learning_rate': 6.211e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056855, 'epoch': 0.45, 'global_step/max_steps': '525/1163', 'percentage': '45.14%', 'elapsed_time': '2h 33m 53s', 'remaining_time': '3h 7m 1s'}\n",
      "{'loss': 1.95128441, 'token_acc': 0.58999147, 'grad_norm': 1.28185856, 'learning_rate': 6.142e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056861, 'epoch': 0.46, 'global_step/max_steps': '530/1163', 'percentage': '45.57%', 'elapsed_time': '2h 35m 20s', 'remaining_time': '3h 5m 31s'}\n",
      "{'loss': 1.95260105, 'token_acc': 0.58093832, 'grad_norm': 1.38057423, 'learning_rate': 6.073e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056862, 'epoch': 0.46, 'global_step/max_steps': '535/1163', 'percentage': '46.00%', 'elapsed_time': '2h 36m 48s', 'remaining_time': '3h 4m 3s'}\n",
      "{'loss': 2.02926502, 'token_acc': 0.56713059, 'grad_norm': 1.34859943, 'learning_rate': 6.003e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056876, 'epoch': 0.46, 'global_step/max_steps': '540/1163', 'percentage': '46.43%', 'elapsed_time': '2h 38m 13s', 'remaining_time': '3h 2m 33s'}\n",
      "{'loss': 2.11937656, 'token_acc': 0.5476266, 'grad_norm': 1.14983726, 'learning_rate': 5.934e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056875, 'epoch': 0.47, 'global_step/max_steps': '545/1163', 'percentage': '46.86%', 'elapsed_time': '2h 39m 42s', 'remaining_time': '3h 1m 5s'}\n",
      "{'loss': 1.844907, 'token_acc': 0.60606233, 'grad_norm': 1.31721652, 'learning_rate': 5.864e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056891, 'epoch': 0.47, 'global_step/max_steps': '550/1163', 'percentage': '47.29%', 'elapsed_time': '2h 41m 7s', 'remaining_time': '2h 59m 34s'}\n",
      "{'loss': 1.98441429, 'token_acc': 0.57682017, 'grad_norm': 1.47761405, 'learning_rate': 5.793e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056886, 'epoch': 0.48, 'global_step/max_steps': '555/1163', 'percentage': '47.72%', 'elapsed_time': '2h 42m 35s', 'remaining_time': '2h 58m 7s'}\n",
      "{'loss': 2.03393078, 'token_acc': 0.56710494, 'grad_norm': 1.22794724, 'learning_rate': 5.723e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056869, 'epoch': 0.48, 'global_step/max_steps': '560/1163', 'percentage': '48.15%', 'elapsed_time': '2h 44m 6s', 'remaining_time': '2h 56m 42s'}\n",
      "{'loss': 2.12467232, 'token_acc': 0.5458513, 'grad_norm': 1.12392533, 'learning_rate': 5.653e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056859, 'epoch': 0.49, 'global_step/max_steps': '565/1163', 'percentage': '48.58%', 'elapsed_time': '2h 45m 36s', 'remaining_time': '2h 55m 16s'}\n",
      "{'loss': 1.96645222, 'token_acc': 0.57726549, 'grad_norm': 1.51962101, 'learning_rate': 5.582e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056872, 'epoch': 0.49, 'global_step/max_steps': '570/1163', 'percentage': '49.01%', 'elapsed_time': '2h 47m 2s', 'remaining_time': '2h 53m 46s'}\n",
      "{'loss': 1.92859173, 'token_acc': 0.58423712, 'grad_norm': 1.37134147, 'learning_rate': 5.511e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056881, 'epoch': 0.49, 'global_step/max_steps': '575/1163', 'percentage': '49.44%', 'elapsed_time': '2h 48m 28s', 'remaining_time': '2h 52m 16s'}\n",
      "Train:  49%|████▉     | 575/1163 [2:48:28<2:49:02, 17.25s/it]\n",
      "Train:  49%|████▉     | 575/1163 [2:48:28<2:49:02, 17.25s/it]\n",
      "Train:  50%|████▉     | 576/1163 [2:48:45<2:49:40, 17.34s/it]\n",
      "Train:  50%|████▉     | 577/1163 [2:49:02<2:47:09, 17.11s/it]\n",
      "Train:  50%|████▉     | 578/1163 [2:49:20<2:48:40, 17.30s/it]\n",
      "Train:  50%|████▉     | 579/1163 [2:49:37<2:48:04, 17.27s/it]\n",
      "Train:  50%|████▉     | 580/1163 [2:49:55<2:50:53, 17.59s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  50%|████▉     | 580/1163 [2:49:55<2:50:53, 17.59s/it]\n",
      "Train:  50%|████▉     | 580/1163 [2:49:55<2:50:53, 17.59s/it]\n",
      "Train:  50%|████▉     | 581/1163 [2:50:13<2:51:56, 17.73s/it]\n",
      "Train:  50%|█████     | 582/1163 [2:50:31<2:50:17, 17.59s/it]\n",
      "Train:  50%|█████     | 583/1163 [2:50:48<2:48:53, 17.47s/it]\n",
      "Train:  50%|█████     | 584/1163 [2:51:05<2:48:30, 17.46s/it]\n",
      "Train:  50%|█████     | 585/1163 [2:51:22<2:46:11, 17.25s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  50%|█████     | 585/1163 [2:51:22<2:46:11, 17.25s/it]\n",
      "Train:  50%|█████     | 585/1163 [2:51:22<2:46:11, 17.25s/it]\n",
      "Train:  50%|█████     | 586/1163 [2:51:39<2:45:25, 17.20s/it]\n",
      "Train:  50%|█████     | 587/1163 [2:51:58<2:49:08, 17.62s/it]\n",
      "Train:  51%|█████     | 588/1163 [2:52:15<2:46:42, 17.40s/it]\n",
      "Train:  51%|█████     | 589/1163 [2:52:31<2:45:04, 17.25s/it]\n",
      "Train:  51%|█████     | 590/1163 [2:52:49<2:45:06, 17.29s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  51%|█████     | 590/1163 [2:52:49<2:45:06, 17.29s/it]\n",
      "Train:  51%|█████     | 590/1163 [2:52:49<2:45:06, 17.29s/it]\n",
      "Train:  51%|█████     | 591/1163 [2:53:07<2:46:42, 17.49s/it]\n",
      "Train:  51%|█████     | 592/1163 [2:53:25<2:47:52, 17.64s/it]\n",
      "Train:  51%|█████     | 593/1163 [2:53:42<2:45:05, 17.38s/it]\n",
      "Train:  51%|█████     | 594/1163 [2:53:59<2:43:56, 17.29s/it]\n",
      "Train:  51%|█████     | 595/1163 [2:54:18<2:48:49, 17.83s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  51%|█████     | 595/1163 [2:54:18<2:48:49, 17.83s/it]\n",
      "Train:  51%|█████     | 595/1163 [2:54:18<2:48:49, 17.83s/it]\n",
      "Train:  51%|█████     | 596/1163 [2:54:35<2:47:03, 17.68s/it]\n",
      "Train:  51%|█████▏    | 597/1163 [2:54:52<2:45:15, 17.52s/it]\n",
      "Train:  51%|█████▏    | 598/1163 [2:55:09<2:42:25, 17.25s/it]\n",
      "Train:  52%|█████▏    | 599/1163 [2:55:27<2:43:53, 17.44s/it]\n",
      "Train:  52%|█████▏    | 600/1163 [2:55:44<2:42:07, 17.28s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  52%|█████▏    | 600/1163 [2:55:44<2:42:07, 17.28s/it]\n",
      "Train:  52%|█████▏    | 600/1163 [2:55:44<2:42:07, 17.28s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v12-20250928-082402/checkpoint-600\n",
      "\n",
      "Train:  52%|█████▏    | 601/1163 [2:56:03<2:48:30, 17.99s/it]\n",
      "Train:  52%|█████▏    | 602/1163 [2:56:20<2:45:49, 17.74s/it]\n",
      "Train:  52%|█████▏    | 603/1163 [2:56:39<2:46:40, 17.86s/it]\n",
      "Train:  52%|█████▏    | 604/1163 [2:56:57<2:49:14, 18.17s/it]\n",
      "Train:  52%|█████▏    | 605/1163 [2:57:14<2:45:27, 17.79s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  52%|█████▏    | 605/1163 [2:57:14<2:45:27, 17.79s/it]\n",
      "Train:  52%|█████▏    | 605/1163 [2:57:14<2:45:27, 17.79s/it]\n",
      "Train:  52%|█████▏    | 606/1163 [2:57:31<2:43:13, 17.58s/it]\n",
      "Train:  52%|█████▏    | 607/1163 [2:57:49<2:42:06, 17.49s/it]\n",
      "Train:  52%|█████▏    | 608/1163 [2:58:06<2:41:21, 17.44s/it]\n",
      "Train:  52%|█████▏    | 609/1163 [2:58:24<2:41:27, 17.49s/it]\n",
      "Train:  52%|█████▏    | 610/1163 [2:58:42<2:43:54, 17.78s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  52%|█████▏    | 610/1163 [2:58:42<2:43:54, 17.78s/it]\n",
      "Train:  52%|█████▏    | 610/1163 [2:58:42<2:43:54, 17.78s/it]\n",
      "Train:  53%|█████▎    | 611/1163 [2:58:59<2:41:32, 17.56s/it]\n",
      "Train:  53%|█████▎    | 612/1163 [2:59:17<2:41:09, 17.55s/it]\n",
      "Train:  53%|█████▎    | 613/1163 [2:59:33<2:38:41, 17.31s/it]\n",
      "Train:  53%|█████▎    | 614/1163 [2:59:53<2:43:16, 17.84s/it]\n",
      "Train:  53%|█████▎    | 615/1163 [3:00:11<2:44:03, 17.96s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  53%|█████▎    | 615/1163 [3:00:11<2:44:03, 17.96s/it]\n",
      "Train:  53%|█████▎    | 615/1163 [3:00:11<2:44:03, 17.96s/it]\n",
      "Train:  53%|█████▎    | 616/1163 [3:00:28<2:41:33, 17.72s/it]\n",
      "Train:  53%|█████▎    | 617/1163 [3:00:46<2:43:29, 17.97s/it]\n",
      "Train:  53%|█████▎    | 618/1163 [3:01:04<2:41:45, 17.81s/it]\n",
      "Train:  53%|█████▎    | 619/1163 [3:01:21<2:40:07, 17.66s/it]\n",
      "Train:  53%|█████▎    | 620/1163 [3:01:38<2:38:07, 17.47s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  53%|█████▎    | 620/1163 [3:01:38<2:38:07, 17.47s/it]\n",
      "Train:  53%|█████▎    | 620/1163 [3:01:38<2:38:07, 17.47s/it]\n",
      "Train:  53%|█████▎    | 621/1163 [3:01:55<2:35:59, 17.27s/it]\n",
      "Train:  53%|█████▎    | 622/1163 [3:02:12<2:35:27, 17.24s/it]\n",
      "Train:  54%|█████▎    | 623/1163 [3:02:29<2:35:07, 17.24s/it]\n",
      "Train:  54%|█████▎    | 624/1163 [3:02:47<2:34:37, 17.21s/it]\n",
      "Train:  54%|█████▎    | 625/1163 [3:03:04<2:35:31, 17.35s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  54%|█████▎    | 625/1163 [3:03:04<2:35:31, 17.35s/it]\n",
      "Train:  54%|█████▎    | 625/1163 [3:03:04<2:35:31, 17.35s/it]\n",
      "Train:  54%|█████▍    | 626/1163 [3:03:22<2:35:18, 17.35s/it]\n",
      "Train:  54%|█████▍    | 627/1163 [3:03:39<2:34:30, 17.30s/it]\n",
      "Train:  54%|█████▍    | 628/1163 [3:03:56<2:33:47, 17.25s/it]\n",
      "Train:  54%|█████▍    | 629/1163 [3:04:13<2:32:07, 17.09s/it]\n",
      "Train:  54%|█████▍    | 630/1163 [3:04:30<2:31:56, 17.10s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  54%|█████▍    | 630/1163 [3:04:30<2:31:56, 17.10s/it]\n",
      "Train:  54%|█████▍    | 630/1163 [3:04:30<2:31:56, 17.10s/it]\n",
      "Train:  54%|█████▍    | 631/1163 [3:04:48<2:35:11, 17.50s/it]\n",
      "Train:  54%|█████▍    | 632/1163 [3:05:06<2:34:46, 17.49s/it]\n",
      "Train:  54%|█████▍    | 633/1163 [3:05:25<2:38:27, 17.94s/it]\n",
      "Train:  55%|█████▍    | 634/1163 [3:05:42<2:37:14, 17.83s/it]\n",
      "Train:  55%|█████▍    | 635/1163 [3:05:59<2:34:52, 17.60s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  55%|█████▍    | 635/1163 [3:05:59<2:34:52, 17.60s/it]\n",
      "Train:  55%|█████▍    | 635/1163 [3:05:59<2:34:52, 17.60s/it]\n",
      "Train:  55%|█████▍    | 636/1163 [3:06:17<2:33:56, 17.53s/it]\n",
      "Train:  55%|█████▍    | 637/1163 [3:06:35<2:36:56, 17.90s/it]\n",
      "Train:  55%|█████▍    | 638/1163 [3:06:53<2:35:14, 17.74s/it]\n",
      "Train:  55%|█████▍    | 639/1163 [3:07:10<2:33:55, 17.62s/it]\n",
      "Train:  55%|█████▌    | 640/1163 [3:07:28<2:34:10, 17.69s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  55%|█████▌    | 640/1163 [3:07:28<2:34:10, 17.69s/it]\n",
      "Train:  55%|█████▌    | 640/1163 [3:07:28<2:34:10, 17.69s/it]\n",
      "Train:  55%|█████▌    | 641/1163 [3:07:45<2:31:39, 17.43s/it]\n",
      "Train:  55%|█████▌    | 642/1163 [3:08:03<2:32:48, 17.60s/it]\n",
      "Train:  55%|█████▌    | 643/1163 [3:08:21<2:34:40, 17.85s/it]\n",
      "Train:  55%|█████▌    | 644/1163 [3:08:39<2:33:48, 17.78s/it]\n",
      "Train:  55%|█████▌    | 645/1163 [3:08:55<2:30:22, 17.42s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  55%|█████▌    | 645/1163 [3:08:55<2:30:22, 17.42s/it]\n",
      "Train:  55%|█████▌    | 645/1163 [3:08:55<2:30:22, 17.42s/it]\n",
      "Train:  56%|█████▌    | 646/1163 [3:09:13<2:30:21, 17.45s/it]\n",
      "Train:  56%|█████▌    | 647/1163 [3:09:30<2:28:42, 17.29s/it]\n",
      "Train:  56%|█████▌    | 648/1163 [3:09:47<2:28:10, 17.26s/it]\n",
      "Train:  56%|█████▌    | 649/1163 [3:10:08<2:36:04, 18.22s/it]\n",
      "Train:  56%|█████▌    | 650/1163 [3:10:27<2:38:20, 18.52s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  56%|█████▌    | 650/1163 [3:10:27<2:38:20, 18.52s/it]\n",
      "Train:  56%|█████▌    | 650/1163 [3:10:27<2:38:20, 18.52s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v12-20250928-082402/checkpoint-650\n",
      "\n",
      "Train:  56%|█████▌    | 651/1163 [3:10:45<2:38:12, 18.54s/it]\n",
      "Train:  56%|█████▌    | 652/1163 [3:11:03<2:35:21, 18.24s/it]\n",
      "Train:  56%|█████▌    | 653/1163 [3:11:23<2:39:31, 18.77s/it]\n",
      "Train:  56%|█████▌    | 654/1163 [3:11:40<2:34:45, 18.24s/it]\n",
      "Train:  56%|█████▋    | 655/1163 [3:11:57<2:31:40, 17.91s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  56%|█████▋    | 655/1163 [3:11:57<2:31:40, 17.91s/it]\n",
      "Train:  56%|█████▋    | 655/1163 [3:11:57<2:31:40, 17.91s/it]\n",
      "Train:  56%|█████▋    | 656/1163 [3:12:15<2:31:00, 17.87s/it]\n",
      "Train:  56%|█████▋    | 657/1163 [3:12:33<2:30:30, 17.85s/it]\n",
      "Train:  57%|█████▋    | 658/1163 [3:12:50<2:28:24, 17.63s/it]\n",
      "Train:  57%|█████▋    | 659/1163 [3:13:06<2:25:45, 17.35s/it]\n",
      "Train:  57%|█████▋    | 660/1163 [3:13:23<2:23:53, 17.16s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  57%|█████▋    | 660/1163 [3:13:23<2:23:53, 17.16s/it]\n",
      "Train:  57%|█████▋    | 660/1163 [3:13:23<2:23:53, 17.16s/it]\n",
      "Train:  57%|█████▋    | 661/1163 [3:13:42<2:27:11, 17.59s/it]\n",
      "Train:  57%|█████▋    | 662/1163 [3:13:59<2:25:28, 17.42s/it]\n",
      "Train:  57%|█████▋    | 663/1163 [3:14:16<2:23:25, 17.21s/it]\n",
      "Train:  57%|█████▋    | 664/1163 [3:14:33<2:23:06, 17.21s/it]\n",
      "Train:  57%|█████▋    | 665/1163 [3:14:50<2:23:14, 17.26s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  57%|█████▋    | 665/1163 [3:14:50<2:23:14, 17.26s/it]\n",
      "Train:  57%|█████▋    | 665/1163 [3:14:50<2:23:14, 17.26s/it]\n",
      "Train:  57%|█████▋    | 666/1163 [3:15:07<2:22:26, 17.20s/it]\n",
      "Train:  57%|█████▋    | 667/1163 [3:15:25<2:24:58, 17.54s/it]\n",
      "Train:  57%|█████▋    | 668/1163 [3:15:43<2:23:51, 17.44s/it]\n",
      "Train:  58%|█████▊    | 669/1163 [3:16:01<2:26:25, 17.78s/it]\n",
      "Train:  58%|█████▊    | 670/1163 [3:16:19<2:25:21, 17.69s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  58%|█████▊    | 670/1163 [3:16:19<2:25:21, 17.69s/it]\n",
      "Train:  58%|█████▊    | 670/1163 [3:16:19<2:25:21, 17.69s/it]\n",
      "Train:  58%|█████▊    | 671/1163 [3:16:37<2:25:14, 17.71s/it]\n",
      "Train:  58%|█████▊    | 672/1163 [3:16:54<2:24:24, 17.65s/it]\n",
      "Train:  58%|█████▊    | 673/1163 [3:17:11<2:22:20, 17.43s/it]\n",
      "Train:  58%|█████▊    | 674/1163 [3:17:28<2:20:19, 17.22s/it]\n",
      "Train:  58%|█████▊    | 675/1163 [3:17:46<2:22:32, 17.53s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  58%|█████▊    | 675/1163 [3:17:46<2:22:32, 17.53s/it]\n",
      "Train:  58%|█████▊    | 675/1163 [3:17:46<2:22:32, 17.53s/it]\n",
      "Train:  58%|█████▊    | 676/1163 [3:18:03<2:22:01, 17.50s/it]\n",
      "Train:  58%|█████▊    | 677/1163 [3:18:21<2:22:01, 17.53s/it]\n",
      "Train:  58%|█████▊    | 678/1163 [3:18:38<2:20:45, 17.41s/it]\n",
      "Train:  58%|█████▊    | 679/1163 [3:18:55<2:20:27, 17.41s/it]\n",
      "Train:  58%|█████▊    | 680/1163 [3:19:13<2:20:46, 17.49s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  58%|█████▊    | 680/1163 [3:19:13<2:20:46, 17.49s/it]\n",
      "Train:  58%|█████▊    | 680/1163 [3:19:13<2:20:46, 17.49s/it]\n",
      "Train:  59%|█████▊    | 681/1163 [3:19:31<2:20:34, 17.50s/it]\n",
      "Train:  59%|█████▊    | 682/1163 [3:19:49<2:22:13, 17.74s/it]\n",
      "Train:  59%|█████▊    | 683/1163 [3:20:06<2:20:57, 17.62s/it]\n",
      "Train:  59%|█████▉    | 684/1163 [3:20:24<2:21:26, 17.72s/it]\n",
      "Train:  59%|█████▉    | 685/1163 [3:20:41<2:18:33, 17.39s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  59%|█████▉    | 685/1163 [3:20:41<2:18:33, 17.39s/it]\n",
      "Train:  59%|█████▉    | 685/1163 [3:20:41<2:18:33, 17.39s/it]\n",
      "Train:  59%|█████▉    | 686/1163 [3:20:58<2:18:19, 17.40s/it]\n",
      "Train:  59%|█████▉    | 687/1163 [3:21:15<2:16:11, 17.17s/it]\n",
      "Train:  59%|█████▉    | 688/1163 [3:21:34<2:19:34, 17.63s/it]\n",
      "Train:  59%|█████▉    | 689/1163 [3:21:51<2:18:39, 17.55s/it]\n",
      "Train:  59%|█████▉    | 690/1163 [3:22:09<2:19:51, 17.74s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  59%|█████▉    | 690/1163 [3:22:09<2:19:51, 17.74s/it]\n",
      "Train:  59%|█████▉    | 690/1163 [3:22:09<2:19:51, 17.74s/it]\n",
      "Train:  59%|█████▉    | 691/1163 [3:22:26<2:17:59, 17.54s/it]\n",
      "Train:  60%|█████▉    | 692/1163 [3:22:43<2:16:55, 17.44s/it]\n",
      "Train:  60%|█████▉    | 693/1163 [3:23:01<2:16:11, 17.39s/it]\n",
      "Train:  60%|█████▉    | 694/1163 [3:23:18<2:14:34, 17.22s/it]\n",
      "Train:  60%|█████▉    | 695/1163 [3:23:35<2:15:23, 17.36s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  60%|█████▉    | 695/1163 [3:23:35<2:15:23, 17.36s/it]\n",
      "Train:  60%|█████▉    | 695/1163 [3:23:35<2:15:23, 17.36s/it]\n",
      "Train:  60%|█████▉    | 696/1163 [3:23:55<2:19:35, 17.93s/it]\n",
      "Train:  60%|█████▉    | 697/1163 [3:24:12<2:17:58, 17.76s/it]\n",
      "Train:  60%|██████    | 698/1163 [3:24:30<2:17:56, 17.80s/it]\n",
      "Train:  60%|██████    | 699/1163 [3:24:47<2:15:36, 17.53s/it]\n",
      "Train:  60%|██████    | 700/1163 [3:25:07<2:21:10, 18.29s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  60%|██████    | 700/1163 [3:25:07<2:21:10, 18.29s/it]\n",
      "Train:  60%|██████    | 700/1163 [3:25:07<2:21:10, 18.29s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v12-20250928-082402/checkpoint-700\n",
      "\n",
      "Train:  60%|██████    | 701/1163 [3:25:26<2:22:29, 18.50s/it]\n",
      "Train:  60%|██████    | 702/1163 [3:25:43<2:18:11, 17.99s/it]\n",
      "Train:  60%|██████    | 703/1163 [3:25:59<2:15:23, 17.66s/it]\n",
      "Train:  61%|██████    | 704/1163 [3:26:16<2:12:41, 17.34s/it]\n",
      "Train:  61%|██████    | 705/1163 [3:26:33<2:12:39, 17.38s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  61%|██████    | 705/1163 [3:26:34<2:12:39, 17.38s/it]\n",
      "Train:  61%|██████    | 705/1163 [3:26:34<2:12:39, 17.38s/it]\n",
      "Train:  61%|██████    | 706/1163 [3:26:51<2:11:56, 17.32s/it]\n",
      "Train:  61%|██████    | 707/1163 [3:27:07<2:10:27, 17.17s/it]\n",
      "Train:  61%|██████    | 708/1163 [3:27:26<2:12:35, 17.48s/it]\n",
      "Train:  61%|██████    | 709/1163 [3:27:43<2:12:36, 17.53s/it]\n",
      "Train:  61%|██████    | 710/1163 [3:28:01<2:11:34, 17.43s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  61%|██████    | 710/1163 [3:28:01<2:11:34, 17.43s/it]\n",
      "Train:  61%|██████    | 710/1163 [3:28:01<2:11:34, 17.43s/it]\n",
      "Train:  61%|██████    | 711/1163 [3:28:17<2:09:58, 17.25s/it]\n",
      "Train:  61%|██████    | 712/1163 [3:28:35<2:09:28, 17.23s/it]\n",
      "Train:  61%|██████▏   | 713/1163 [3:28:53<2:11:57, 17.60s/it]\n",
      "Train:  61%|██████▏   | 714/1163 [3:29:10<2:11:26, 17.56s/it]\n",
      "Train:  61%|██████▏   | 715/1163 [3:29:30<2:15:11, 18.11s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  61%|██████▏   | 715/1163 [3:29:30<2:15:11, 18.11s/it]\n",
      "Train:  61%|██████▏   | 715/1163 [3:29:30<2:15:11, 18.11s/it]\n",
      "Train:  62%|██████▏   | 716/1163 [3:29:48<2:13:54, 17.98s/it]\n",
      "Train:  62%|██████▏   | 717/1163 [3:30:05<2:11:55, 17.75s/it]\n",
      "Train:  62%|██████▏   | 718/1163 [3:30:23<2:13:18, 17.98s/it]\n",
      "Train:  62%|██████▏   | 719/1163 [3:30:41<2:11:50, 17.82s/it]\n",
      "Train:  62%|██████▏   | 720/1163 [3:30:58<2:09:43, 17.57s/it]\n",
      "                                                             \n",
      "{'loss': 2.00068016, 'token_acc': 0.56699871, 'grad_norm': 1.17315423, 'learning_rate': 5.441e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056884, 'epoch': 0.5, 'global_step/max_steps': '580/1163', 'percentage': '49.87%', 'elapsed_time': '2h 49m 55s', 'remaining_time': '2h 50m 48s'}\n",
      "{'loss': 2.08912811, 'token_acc': 0.55701376, 'grad_norm': 1.3803997, 'learning_rate': 5.37e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.05689, 'epoch': 0.5, 'global_step/max_steps': '585/1163', 'percentage': '50.30%', 'elapsed_time': '2h 51m 22s', 'remaining_time': '2h 49m 19s'}\n",
      "{'loss': 1.97500515, 'token_acc': 0.57289516, 'grad_norm': 1.12336421, 'learning_rate': 5.299e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056896, 'epoch': 0.51, 'global_step/max_steps': '590/1163', 'percentage': '50.73%', 'elapsed_time': '2h 52m 49s', 'remaining_time': '2h 47m 50s'}\n",
      "{'loss': 2.07751503, 'token_acc': 0.55247956, 'grad_norm': 0.98547333, 'learning_rate': 5.228e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056891, 'epoch': 0.51, 'global_step/max_steps': '595/1163', 'percentage': '51.16%', 'elapsed_time': '2h 54m 18s', 'remaining_time': '2h 46m 23s'}\n",
      "{'loss': 2.00864086, 'token_acc': 0.56951081, 'grad_norm': 1.49887538, 'learning_rate': 5.156e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056902, 'epoch': 0.52, 'global_step/max_steps': '600/1163', 'percentage': '51.59%', 'elapsed_time': '2h 55m 44s', 'remaining_time': '2h 44m 53s'}\n",
      "{'loss': 1.89147301, 'token_acc': 0.59745151, 'grad_norm': 1.1963737, 'learning_rate': 5.085e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056886, 'epoch': 0.52, 'global_step/max_steps': '605/1163', 'percentage': '52.02%', 'elapsed_time': '2h 57m 14s', 'remaining_time': '2h 43m 28s'}\n",
      "{'loss': 1.96817036, 'token_acc': 0.58433769, 'grad_norm': 1.18819022, 'learning_rate': 5.014e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056887, 'epoch': 0.52, 'global_step/max_steps': '610/1163', 'percentage': '52.45%', 'elapsed_time': '2h 58m 42s', 'remaining_time': '2h 42m 0s'}\n",
      "{'loss': 1.89180775, 'token_acc': 0.59995701, 'grad_norm': 1.27436733, 'learning_rate': 4.943e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056883, 'epoch': 0.53, 'global_step/max_steps': '615/1163', 'percentage': '52.88%', 'elapsed_time': '3h 0m 11s', 'remaining_time': '2h 40m 33s'}\n",
      "{'loss': 1.92134476, 'token_acc': 0.58636522, 'grad_norm': 1.26802015, 'learning_rate': 4.872e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056885, 'epoch': 0.53, 'global_step/max_steps': '620/1163', 'percentage': '53.31%', 'elapsed_time': '3h 1m 38s', 'remaining_time': '2h 39m 5s'}\n",
      "{'loss': 1.96598873, 'token_acc': 0.58027011, 'grad_norm': 1.29927218, 'learning_rate': 4.801e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056895, 'epoch': 0.54, 'global_step/max_steps': '625/1163', 'percentage': '53.74%', 'elapsed_time': '3h 3m 4s', 'remaining_time': '2h 37m 35s'}\n",
      "{'loss': 1.90303459, 'token_acc': 0.58954748, 'grad_norm': 1.33993876, 'learning_rate': 4.73e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056907, 'epoch': 0.54, 'global_step/max_steps': '630/1163', 'percentage': '54.17%', 'elapsed_time': '3h 4m 30s', 'remaining_time': '2h 36m 5s'}\n",
      "{'loss': 1.94867077, 'token_acc': 0.57789177, 'grad_norm': 1.27368152, 'learning_rate': 4.659e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056899, 'epoch': 0.55, 'global_step/max_steps': '635/1163', 'percentage': '54.60%', 'elapsed_time': '3h 5m 59s', 'remaining_time': '2h 34m 39s'}\n",
      "{'loss': 1.9792942, 'token_acc': 0.57654672, 'grad_norm': 1.28766155, 'learning_rate': 4.588e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056894, 'epoch': 0.55, 'global_step/max_steps': '640/1163', 'percentage': '55.03%', 'elapsed_time': '3h 7m 28s', 'remaining_time': '2h 33m 12s'}\n",
      "{'loss': 2.04295769, 'token_acc': 0.56455766, 'grad_norm': 1.32006598, 'learning_rate': 4.517e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056897, 'epoch': 0.56, 'global_step/max_steps': '645/1163', 'percentage': '55.46%', 'elapsed_time': '3h 8m 55s', 'remaining_time': '2h 31m 43s'}\n",
      "{'loss': 2.02920208, 'token_acc': 0.56102461, 'grad_norm': 1.20258713, 'learning_rate': 4.446e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056879, 'epoch': 0.56, 'global_step/max_steps': '650/1163', 'percentage': '55.89%', 'elapsed_time': '3h 10m 27s', 'remaining_time': '2h 30m 18s'}\n",
      "{'loss': 1.98840046, 'token_acc': 0.57330671, 'grad_norm': 1.36492383, 'learning_rate': 4.376e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056868, 'epoch': 0.56, 'global_step/max_steps': '655/1163', 'percentage': '56.32%', 'elapsed_time': '3h 11m 57s', 'remaining_time': '2h 28m 52s'}\n",
      "{'loss': 1.98775368, 'token_acc': 0.56468339, 'grad_norm': 1.51479089, 'learning_rate': 4.305e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056877, 'epoch': 0.57, 'global_step/max_steps': '660/1163', 'percentage': '56.75%', 'elapsed_time': '3h 13m 23s', 'remaining_time': '2h 27m 23s'}\n",
      "{'loss': 1.89129295, 'token_acc': 0.5936057, 'grad_norm': 1.30078745, 'learning_rate': 4.235e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056881, 'epoch': 0.57, 'global_step/max_steps': '665/1163', 'percentage': '57.18%', 'elapsed_time': '3h 14m 50s', 'remaining_time': '2h 25m 54s'}\n",
      "{'loss': 1.85790939, 'token_acc': 0.59673872, 'grad_norm': 1.39550853, 'learning_rate': 4.164e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056878, 'epoch': 0.58, 'global_step/max_steps': '670/1163', 'percentage': '57.61%', 'elapsed_time': '3h 16m 19s', 'remaining_time': '2h 24m 27s'}\n",
      "{'loss': 2.03556099, 'token_acc': 0.56223129, 'grad_norm': 1.21587515, 'learning_rate': 4.094e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056881, 'epoch': 0.58, 'global_step/max_steps': '675/1163', 'percentage': '58.04%', 'elapsed_time': '3h 17m 46s', 'remaining_time': '2h 22m 58s'}\n",
      "{'loss': 1.91181889, 'token_acc': 0.59031922, 'grad_norm': 1.28398395, 'learning_rate': 4.025e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056884, 'epoch': 0.59, 'global_step/max_steps': '680/1163', 'percentage': '58.47%', 'elapsed_time': '3h 19m 13s', 'remaining_time': '2h 21m 30s'}\n",
      "{'loss': 1.91627045, 'token_acc': 0.58643303, 'grad_norm': 1.28776205, 'learning_rate': 3.955e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056885, 'epoch': 0.59, 'global_step/max_steps': '685/1163', 'percentage': '58.90%', 'elapsed_time': '3h 20m 41s', 'remaining_time': '2h 20m 2s'}\n",
      "{'loss': 1.86780853, 'token_acc': 0.59643853, 'grad_norm': 1.12215483, 'learning_rate': 3.885e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056883, 'epoch': 0.59, 'global_step/max_steps': '690/1163', 'percentage': '59.33%', 'elapsed_time': '3h 22m 9s', 'remaining_time': '2h 18m 34s'}\n",
      "{'loss': 2.01054993, 'token_acc': 0.57095375, 'grad_norm': 1.25385284, 'learning_rate': 3.816e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056892, 'epoch': 0.6, 'global_step/max_steps': '695/1163', 'percentage': '59.76%', 'elapsed_time': '3h 23m 35s', 'remaining_time': '2h 17m 5s'}\n",
      "{'loss': 1.8601263, 'token_acc': 0.6, 'grad_norm': 1.17153525, 'learning_rate': 3.747e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056875, 'epoch': 0.6, 'global_step/max_steps': '700/1163', 'percentage': '60.19%', 'elapsed_time': '3h 25m 7s', 'remaining_time': '2h 15m 40s'}\n",
      "{'loss': 1.89125919, 'token_acc': 0.59138987, 'grad_norm': 1.33727372, 'learning_rate': 3.678e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056881, 'epoch': 0.61, 'global_step/max_steps': '705/1163', 'percentage': '60.62%', 'elapsed_time': '3h 26m 33s', 'remaining_time': '2h 14m 11s'}\n",
      "{'loss': 2.0007843, 'token_acc': 0.57214878, 'grad_norm': 1.23877382, 'learning_rate': 3.61e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056884, 'epoch': 0.61, 'global_step/max_steps': '710/1163', 'percentage': '61.05%', 'elapsed_time': '3h 28m 1s', 'remaining_time': '2h 12m 43s'}\n",
      "{'loss': 1.93340778, 'token_acc': 0.58291643, 'grad_norm': 1.0629847, 'learning_rate': 3.542e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056878, 'epoch': 0.62, 'global_step/max_steps': '715/1163', 'percentage': '61.48%', 'elapsed_time': '3h 29m 30s', 'remaining_time': '2h 11m 16s'}\n",
      "{'loss': 1.9179306, 'token_acc': 0.58590308, 'grad_norm': 1.3527298, 'learning_rate': 3.474e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056878, 'epoch': 0.62, 'global_step/max_steps': '720/1163', 'percentage': '61.91%', 'elapsed_time': '3h 30m 58s', 'remaining_time': '2h 9m 48s'}\n",
      "Train:  62%|██████▏   | 720/1163 [3:30:58<2:09:43, 17.57s/it]\n",
      "Train:  62%|██████▏   | 720/1163 [3:30:58<2:09:43, 17.57s/it]\n",
      "Train:  62%|██████▏   | 721/1163 [3:31:16<2:10:27, 17.71s/it]\n",
      "Train:  62%|██████▏   | 722/1163 [3:31:33<2:09:13, 17.58s/it]\n",
      "Train:  62%|██████▏   | 723/1163 [3:31:50<2:07:49, 17.43s/it]\n",
      "Train:  62%|██████▏   | 724/1163 [3:32:07<2:06:15, 17.26s/it]\n",
      "Train:  62%|██████▏   | 725/1163 [3:32:24<2:06:05, 17.27s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  62%|██████▏   | 725/1163 [3:32:24<2:06:05, 17.27s/it]\n",
      "Train:  62%|██████▏   | 725/1163 [3:32:24<2:06:05, 17.27s/it]\n",
      "Train:  62%|██████▏   | 726/1163 [3:32:42<2:06:25, 17.36s/it]\n",
      "Train:  63%|██████▎   | 727/1163 [3:33:00<2:08:42, 17.71s/it]\n",
      "Train:  63%|██████▎   | 728/1163 [3:33:17<2:07:03, 17.52s/it]\n",
      "Train:  63%|██████▎   | 729/1163 [3:33:36<2:08:02, 17.70s/it]\n",
      "Train:  63%|██████▎   | 730/1163 [3:33:53<2:07:35, 17.68s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  63%|██████▎   | 730/1163 [3:33:53<2:07:35, 17.68s/it]\n",
      "Train:  63%|██████▎   | 730/1163 [3:33:53<2:07:35, 17.68s/it]\n",
      "Train:  63%|██████▎   | 731/1163 [3:34:10<2:04:54, 17.35s/it]\n",
      "Train:  63%|██████▎   | 732/1163 [3:34:27<2:03:29, 17.19s/it]\n",
      "Train:  63%|██████▎   | 733/1163 [3:34:44<2:03:55, 17.29s/it]\n",
      "Train:  63%|██████▎   | 734/1163 [3:35:02<2:05:10, 17.51s/it]\n",
      "Train:  63%|██████▎   | 735/1163 [3:35:19<2:04:00, 17.38s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  63%|██████▎   | 735/1163 [3:35:19<2:04:00, 17.38s/it]\n",
      "Train:  63%|██████▎   | 735/1163 [3:35:19<2:04:00, 17.38s/it]\n",
      "Train:  63%|██████▎   | 736/1163 [3:35:37<2:04:21, 17.47s/it]\n",
      "Train:  63%|██████▎   | 737/1163 [3:35:54<2:04:13, 17.50s/it]\n",
      "Train:  63%|██████▎   | 738/1163 [3:36:12<2:03:27, 17.43s/it]\n",
      "Train:  64%|██████▎   | 739/1163 [3:36:29<2:02:54, 17.39s/it]\n",
      "Train:  64%|██████▎   | 740/1163 [3:36:47<2:03:58, 17.58s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  64%|██████▎   | 740/1163 [3:36:47<2:03:58, 17.58s/it]\n",
      "Train:  64%|██████▎   | 740/1163 [3:36:47<2:03:58, 17.58s/it]\n",
      "Train:  64%|██████▎   | 741/1163 [3:37:05<2:04:11, 17.66s/it]\n",
      "Train:  64%|██████▍   | 742/1163 [3:37:23<2:04:16, 17.71s/it]\n",
      "Train:  64%|██████▍   | 743/1163 [3:37:41<2:04:12, 17.74s/it]\n",
      "Train:  64%|██████▍   | 744/1163 [3:37:57<2:02:14, 17.50s/it]\n",
      "Train:  64%|██████▍   | 745/1163 [3:38:15<2:01:51, 17.49s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  64%|██████▍   | 745/1163 [3:38:15<2:01:51, 17.49s/it]\n",
      "Train:  64%|██████▍   | 745/1163 [3:38:15<2:01:51, 17.49s/it]\n",
      "Train:  64%|██████▍   | 746/1163 [3:38:31<1:59:18, 17.17s/it]\n",
      "Train:  64%|██████▍   | 747/1163 [3:38:48<1:58:25, 17.08s/it]\n",
      "Train:  64%|██████▍   | 748/1163 [3:39:05<1:57:53, 17.04s/it]\n",
      "Train:  64%|██████▍   | 749/1163 [3:39:21<1:56:02, 16.82s/it]\n",
      "Train:  64%|██████▍   | 750/1163 [3:39:38<1:55:59, 16.85s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  64%|██████▍   | 750/1163 [3:39:38<1:55:59, 16.85s/it]\n",
      "Train:  64%|██████▍   | 750/1163 [3:39:38<1:55:59, 16.85s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v12-20250928-082402/checkpoint-750\n",
      "\n",
      "Train:  65%|██████▍   | 751/1163 [3:39:59<2:03:11, 17.94s/it]\n",
      "Train:  65%|██████▍   | 752/1163 [3:40:17<2:02:14, 17.85s/it]\n",
      "Train:  65%|██████▍   | 753/1163 [3:40:34<2:01:18, 17.75s/it]\n",
      "Train:  65%|██████▍   | 754/1163 [3:40:52<2:00:29, 17.68s/it]\n",
      "Train:  65%|██████▍   | 755/1163 [3:41:08<1:58:31, 17.43s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  65%|██████▍   | 755/1163 [3:41:08<1:58:31, 17.43s/it]\n",
      "Train:  65%|██████▍   | 755/1163 [3:41:08<1:58:31, 17.43s/it]\n",
      "Train:  65%|██████▌   | 756/1163 [3:41:26<1:58:13, 17.43s/it]\n",
      "Train:  65%|██████▌   | 757/1163 [3:41:43<1:56:34, 17.23s/it]\n",
      "Train:  65%|██████▌   | 758/1163 [3:42:01<1:58:34, 17.57s/it]\n",
      "Train:  65%|██████▌   | 759/1163 [3:42:18<1:58:03, 17.53s/it]\n",
      "Train:  65%|██████▌   | 760/1163 [3:42:36<1:57:12, 17.45s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  65%|██████▌   | 760/1163 [3:42:36<1:57:12, 17.45s/it]\n",
      "Train:  65%|██████▌   | 760/1163 [3:42:36<1:57:12, 17.45s/it]\n",
      "Train:  65%|██████▌   | 761/1163 [3:42:54<1:58:58, 17.76s/it]\n",
      "Train:  66%|██████▌   | 762/1163 [3:43:14<2:01:58, 18.25s/it]\n",
      "Train:  66%|██████▌   | 763/1163 [3:43:31<1:59:11, 17.88s/it]\n",
      "Train:  66%|██████▌   | 764/1163 [3:43:48<1:57:42, 17.70s/it]\n",
      "Train:  66%|██████▌   | 765/1163 [3:44:05<1:55:36, 17.43s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  66%|██████▌   | 765/1163 [3:44:05<1:55:36, 17.43s/it]\n",
      "Train:  66%|██████▌   | 765/1163 [3:44:05<1:55:36, 17.43s/it]\n",
      "Train:  66%|██████▌   | 766/1163 [3:44:21<1:53:59, 17.23s/it]\n",
      "Train:  66%|██████▌   | 767/1163 [3:44:40<1:56:15, 17.62s/it]\n",
      "Train:  66%|██████▌   | 768/1163 [3:44:59<1:59:08, 18.10s/it]\n",
      "Train:  66%|██████▌   | 769/1163 [3:45:16<1:57:05, 17.83s/it]\n",
      "Train:  66%|██████▌   | 770/1163 [3:45:35<1:57:48, 17.99s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  66%|██████▌   | 770/1163 [3:45:35<1:57:48, 17.99s/it]\n",
      "Train:  66%|██████▌   | 770/1163 [3:45:35<1:57:48, 17.99s/it]\n",
      "Train:  66%|██████▋   | 771/1163 [3:45:52<1:55:32, 17.69s/it]\n",
      "Train:  66%|██████▋   | 772/1163 [3:46:10<1:55:51, 17.78s/it]\n",
      "Train:  66%|██████▋   | 773/1163 [3:46:27<1:54:03, 17.55s/it]\n",
      "Train:  67%|██████▋   | 774/1163 [3:46:44<1:53:01, 17.43s/it]\n",
      "Train:  67%|██████▋   | 775/1163 [3:47:02<1:54:43, 17.74s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  67%|██████▋   | 775/1163 [3:47:02<1:54:43, 17.74s/it]\n",
      "Train:  67%|██████▋   | 775/1163 [3:47:02<1:54:43, 17.74s/it]\n",
      "Train:  67%|██████▋   | 776/1163 [3:47:19<1:53:09, 17.54s/it]\n",
      "Train:  67%|██████▋   | 777/1163 [3:47:37<1:53:54, 17.71s/it]\n",
      "Train:  67%|██████▋   | 778/1163 [3:47:55<1:52:20, 17.51s/it]\n",
      "Train:  67%|██████▋   | 779/1163 [3:48:12<1:51:18, 17.39s/it]\n",
      "Train:  67%|██████▋   | 780/1163 [3:48:31<1:54:06, 17.88s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  67%|██████▋   | 780/1163 [3:48:31<1:54:06, 17.88s/it]\n",
      "Train:  67%|██████▋   | 780/1163 [3:48:31<1:54:06, 17.88s/it]\n",
      "Train:  67%|██████▋   | 781/1163 [3:48:48<1:51:56, 17.58s/it]\n",
      "Train:  67%|██████▋   | 782/1163 [3:49:05<1:52:09, 17.66s/it]\n",
      "Train:  67%|██████▋   | 783/1163 [3:49:23<1:52:11, 17.71s/it]\n",
      "Train:  67%|██████▋   | 784/1163 [3:49:41<1:52:33, 17.82s/it]\n",
      "Train:  67%|██████▋   | 785/1163 [3:49:59<1:52:30, 17.86s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  67%|██████▋   | 785/1163 [3:49:59<1:52:30, 17.86s/it]\n",
      "Train:  67%|██████▋   | 785/1163 [3:49:59<1:52:30, 17.86s/it]\n",
      "Train:  68%|██████▊   | 786/1163 [3:50:16<1:50:21, 17.56s/it]\n",
      "Train:  68%|██████▊   | 787/1163 [3:50:32<1:47:49, 17.21s/it]\n",
      "Train:  68%|██████▊   | 788/1163 [3:50:50<1:48:51, 17.42s/it]\n",
      "Train:  68%|██████▊   | 789/1163 [3:51:08<1:48:57, 17.48s/it]\n",
      "Train:  68%|██████▊   | 790/1163 [3:51:25<1:48:07, 17.39s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  68%|██████▊   | 790/1163 [3:51:25<1:48:07, 17.39s/it]\n",
      "Train:  68%|██████▊   | 790/1163 [3:51:25<1:48:07, 17.39s/it]\n",
      "Train:  68%|██████▊   | 791/1163 [3:51:43<1:48:24, 17.49s/it]\n",
      "Train:  68%|██████▊   | 792/1163 [3:52:00<1:47:28, 17.38s/it]\n",
      "Train:  68%|██████▊   | 793/1163 [3:52:17<1:45:58, 17.18s/it]\n",
      "Train:  68%|██████▊   | 794/1163 [3:52:34<1:46:10, 17.26s/it]\n",
      "Train:  68%|██████▊   | 795/1163 [3:52:51<1:45:36, 17.22s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  68%|██████▊   | 795/1163 [3:52:51<1:45:36, 17.22s/it]\n",
      "Train:  68%|██████▊   | 795/1163 [3:52:51<1:45:36, 17.22s/it]\n",
      "Train:  68%|██████▊   | 796/1163 [3:53:09<1:45:16, 17.21s/it]\n",
      "Train:  69%|██████▊   | 797/1163 [3:53:26<1:45:11, 17.24s/it]\n",
      "Train:  69%|██████▊   | 798/1163 [3:53:43<1:44:20, 17.15s/it]\n",
      "Train:  69%|██████▊   | 799/1163 [3:54:00<1:44:16, 17.19s/it]\n",
      "Train:  69%|██████▉   | 800/1163 [3:54:19<1:46:20, 17.58s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  69%|██████▉   | 800/1163 [3:54:19<1:46:20, 17.58s/it]\n",
      "Train:  69%|██████▉   | 800/1163 [3:54:19<1:46:20, 17.58s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v12-20250928-082402/checkpoint-800\n",
      "\n",
      "Train:  69%|██████▉   | 801/1163 [3:54:38<1:49:48, 18.20s/it]\n",
      "Train:  69%|██████▉   | 802/1163 [3:54:56<1:48:22, 18.01s/it]\n",
      "Train:  69%|██████▉   | 803/1163 [3:55:13<1:46:54, 17.82s/it]\n",
      "Train:  69%|██████▉   | 804/1163 [3:55:32<1:48:30, 18.14s/it]\n",
      "Train:  69%|██████▉   | 805/1163 [3:55:50<1:47:12, 17.97s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  69%|██████▉   | 805/1163 [3:55:50<1:47:12, 17.97s/it]\n",
      "Train:  69%|██████▉   | 805/1163 [3:55:50<1:47:12, 17.97s/it]\n",
      "Train:  69%|██████▉   | 806/1163 [3:56:07<1:46:11, 17.85s/it]\n",
      "Train:  69%|██████▉   | 807/1163 [3:56:25<1:45:09, 17.72s/it]\n",
      "Train:  69%|██████▉   | 808/1163 [3:56:43<1:45:29, 17.83s/it]\n",
      "Train:  70%|██████▉   | 809/1163 [3:56:59<1:42:28, 17.37s/it]\n",
      "Train:  70%|██████▉   | 810/1163 [3:57:16<1:41:55, 17.32s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  70%|██████▉   | 810/1163 [3:57:16<1:41:55, 17.32s/it]\n",
      "Train:  70%|██████▉   | 810/1163 [3:57:16<1:41:55, 17.32s/it]\n",
      "Train:  70%|██████▉   | 811/1163 [3:57:34<1:41:59, 17.38s/it]\n",
      "Train:  70%|██████▉   | 812/1163 [3:57:51<1:41:46, 17.40s/it]\n",
      "Train:  70%|██████▉   | 813/1163 [3:58:08<1:41:07, 17.33s/it]\n",
      "Train:  70%|██████▉   | 814/1163 [3:58:26<1:41:31, 17.46s/it]\n",
      "Train:  70%|███████   | 815/1163 [3:58:43<1:40:46, 17.37s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  70%|███████   | 815/1163 [3:58:43<1:40:46, 17.37s/it]\n",
      "Train:  70%|███████   | 815/1163 [3:58:43<1:40:46, 17.37s/it]\n",
      "Train:  70%|███████   | 816/1163 [3:59:02<1:42:14, 17.68s/it]\n",
      "Train:  70%|███████   | 817/1163 [3:59:18<1:40:29, 17.43s/it]\n",
      "Train:  70%|███████   | 818/1163 [3:59:37<1:41:15, 17.61s/it]\n",
      "Train:  70%|███████   | 819/1163 [3:59:55<1:42:02, 17.80s/it]\n",
      "Train:  71%|███████   | 820/1163 [4:00:11<1:39:49, 17.46s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  71%|███████   | 820/1163 [4:00:11<1:39:49, 17.46s/it]\n",
      "Train:  71%|███████   | 820/1163 [4:00:11<1:39:49, 17.46s/it]\n",
      "Train:  71%|███████   | 821/1163 [4:00:28<1:38:12, 17.23s/it]\n",
      "Train:  71%|███████   | 822/1163 [4:00:46<1:39:14, 17.46s/it]\n",
      "Train:  71%|███████   | 823/1163 [4:01:04<1:39:43, 17.60s/it]\n",
      "Train:  71%|███████   | 824/1163 [4:01:21<1:38:21, 17.41s/it]\n",
      "Train:  71%|███████   | 825/1163 [4:01:39<1:38:18, 17.45s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  71%|███████   | 825/1163 [4:01:39<1:38:18, 17.45s/it]\n",
      "Train:  71%|███████   | 825/1163 [4:01:39<1:38:18, 17.45s/it]\n",
      "Train:  71%|███████   | 826/1163 [4:01:56<1:37:42, 17.40s/it]\n",
      "Train:  71%|███████   | 827/1163 [4:02:14<1:38:30, 17.59s/it]\n",
      "Train:  71%|███████   | 828/1163 [4:02:32<1:39:41, 17.86s/it]\n",
      "Train:  71%|███████▏  | 829/1163 [4:02:49<1:38:10, 17.64s/it]\n",
      "Train:  71%|███████▏  | 830/1163 [4:03:07<1:38:11, 17.69s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  71%|███████▏  | 830/1163 [4:03:07<1:38:11, 17.69s/it]\n",
      "Train:  71%|███████▏  | 830/1163 [4:03:07<1:38:11, 17.69s/it]\n",
      "Train:  71%|███████▏  | 831/1163 [4:03:25<1:37:23, 17.60s/it]\n",
      "Train:  72%|███████▏  | 832/1163 [4:03:42<1:36:55, 17.57s/it]\n",
      "Train:  72%|███████▏  | 833/1163 [4:03:59<1:35:40, 17.40s/it]\n",
      "Train:  72%|███████▏  | 834/1163 [4:04:16<1:34:39, 17.26s/it]\n",
      "Train:  72%|███████▏  | 835/1163 [4:04:34<1:35:03, 17.39s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  72%|███████▏  | 835/1163 [4:04:34<1:35:03, 17.39s/it]\n",
      "Train:  72%|███████▏  | 835/1163 [4:04:34<1:35:03, 17.39s/it]\n",
      "Train:  72%|███████▏  | 836/1163 [4:04:51<1:35:12, 17.47s/it]\n",
      "Train:  72%|███████▏  | 837/1163 [4:05:09<1:34:27, 17.39s/it]\n",
      "Train:  72%|███████▏  | 838/1163 [4:05:27<1:35:54, 17.71s/it]\n",
      "Train:  72%|███████▏  | 839/1163 [4:05:44<1:34:39, 17.53s/it]\n",
      "Train:  72%|███████▏  | 840/1163 [4:06:02<1:34:26, 17.54s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  72%|███████▏  | 840/1163 [4:06:02<1:34:26, 17.54s/it]\n",
      "Train:  72%|███████▏  | 840/1163 [4:06:02<1:34:26, 17.54s/it]\n",
      "Train:  72%|███████▏  | 841/1163 [4:06:19<1:33:26, 17.41s/it]\n",
      "Train:  72%|███████▏  | 842/1163 [4:06:36<1:32:46, 17.34s/it]\n",
      "Train:  72%|███████▏  | 843/1163 [4:06:54<1:33:42, 17.57s/it]\n",
      "Train:  73%|███████▎  | 844/1163 [4:07:13<1:35:23, 17.94s/it]\n",
      "Train:  73%|███████▎  | 845/1163 [4:07:30<1:33:08, 17.57s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  73%|███████▎  | 845/1163 [4:07:30<1:33:08, 17.57s/it]\n",
      "Train:  73%|███████▎  | 845/1163 [4:07:30<1:33:08, 17.57s/it]\n",
      "Train:  73%|███████▎  | 846/1163 [4:07:47<1:32:21, 17.48s/it]\n",
      "Train:  73%|███████▎  | 847/1163 [4:08:04<1:31:33, 17.38s/it]\n",
      "Train:  73%|███████▎  | 848/1163 [4:08:22<1:31:37, 17.45s/it]\n",
      "Train:  73%|███████▎  | 849/1163 [4:08:39<1:31:26, 17.47s/it]\n",
      "Train:  73%|███████▎  | 850/1163 [4:08:56<1:30:03, 17.26s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  73%|███████▎  | 850/1163 [4:08:56<1:30:03, 17.26s/it]\n",
      "Train:  73%|███████▎  | 850/1163 [4:08:56<1:30:03, 17.26s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v12-20250928-082402/checkpoint-850\n",
      "\n",
      "Train:  73%|███████▎  | 851/1163 [4:09:15<1:33:06, 17.91s/it]\n",
      "Train:  73%|███████▎  | 852/1163 [4:09:33<1:31:35, 17.67s/it]\n",
      "Train:  73%|███████▎  | 853/1163 [4:09:50<1:31:27, 17.70s/it]\n",
      "Train:  73%|███████▎  | 854/1163 [4:10:08<1:30:44, 17.62s/it]\n",
      "Train:  74%|███████▎  | 855/1163 [4:10:25<1:30:20, 17.60s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  74%|███████▎  | 855/1163 [4:10:25<1:30:20, 17.60s/it]\n",
      "Train:  74%|███████▎  | 855/1163 [4:10:25<1:30:20, 17.60s/it]\n",
      "Train:  74%|███████▎  | 856/1163 [4:10:44<1:31:18, 17.85s/it]\n",
      "Train:  74%|███████▎  | 857/1163 [4:11:00<1:29:16, 17.50s/it]\n",
      "Train:  74%|███████▍  | 858/1163 [4:11:18<1:29:25, 17.59s/it]\n",
      "Train:  74%|███████▍  | 859/1163 [4:11:35<1:27:59, 17.37s/it]\n",
      "Train:  74%|███████▍  | 860/1163 [4:11:53<1:28:49, 17.59s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  74%|███████▍  | 860/1163 [4:11:53<1:28:49, 17.59s/it]\n",
      "Train:  74%|███████▍  | 860/1163 [4:11:53<1:28:49, 17.59s/it]\n",
      "Train:  74%|███████▍  | 861/1163 [4:12:12<1:30:37, 18.00s/it]\n",
      "Train:  74%|███████▍  | 862/1163 [4:12:30<1:29:40, 17.87s/it]\n",
      "Train:  74%|███████▍  | 863/1163 [4:12:46<1:27:20, 17.47s/it]\n",
      "Train:  74%|███████▍  | 864/1163 [4:13:04<1:27:25, 17.55s/it]\n",
      "Train:  74%|███████▍  | 865/1163 [4:13:21<1:26:57, 17.51s/it]\n",
      "                                                             \n",
      "{'loss': 2.01245899, 'token_acc': 0.56691223, 'grad_norm': 1.36206067, 'learning_rate': 3.406e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056884, 'epoch': 0.62, 'global_step/max_steps': '725/1163', 'percentage': '62.34%', 'elapsed_time': '3h 32m 24s', 'remaining_time': '2h 8m 19s'}\n",
      "{'loss': 1.95454216, 'token_acc': 0.57632783, 'grad_norm': 1.23515117, 'learning_rate': 3.339e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.05688, 'epoch': 0.63, 'global_step/max_steps': '730/1163', 'percentage': '62.77%', 'elapsed_time': '3h 33m 53s', 'remaining_time': '2h 6m 52s'}\n",
      "{'loss': 1.96819324, 'token_acc': 0.58173542, 'grad_norm': 1.41074395, 'learning_rate': 3.272e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056888, 'epoch': 0.63, 'global_step/max_steps': '735/1163', 'percentage': '63.20%', 'elapsed_time': '3h 35m 19s', 'remaining_time': '2h 5m 23s'}\n",
      "{'loss': 1.91720963, 'token_acc': 0.59051989, 'grad_norm': 1.3171438, 'learning_rate': 3.206e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056888, 'epoch': 0.64, 'global_step/max_steps': '740/1163', 'percentage': '63.63%', 'elapsed_time': '3h 36m 47s', 'remaining_time': '2h 3m 55s'}\n",
      "{'loss': 1.92975311, 'token_acc': 0.5920385, 'grad_norm': 1.22026706, 'learning_rate': 3.139e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056888, 'epoch': 0.64, 'global_step/max_steps': '745/1163', 'percentage': '64.06%', 'elapsed_time': '3h 38m 15s', 'remaining_time': '2h 2m 27s'}\n",
      "{'loss': 1.80736427, 'token_acc': 0.60675483, 'grad_norm': 1.32317984, 'learning_rate': 3.073e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056907, 'epoch': 0.65, 'global_step/max_steps': '750/1163', 'percentage': '64.49%', 'elapsed_time': '3h 39m 38s', 'remaining_time': '2h 0m 57s'}\n",
      "{'loss': 1.87980633, 'token_acc': 0.59381588, 'grad_norm': 1.31018078, 'learning_rate': 3.008e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056898, 'epoch': 0.65, 'global_step/max_steps': '755/1163', 'percentage': '64.92%', 'elapsed_time': '3h 41m 8s', 'remaining_time': '1h 59m 30s'}\n",
      "{'loss': 1.83964272, 'token_acc': 0.60785076, 'grad_norm': 1.25833726, 'learning_rate': 2.943e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056901, 'epoch': 0.65, 'global_step/max_steps': '760/1163', 'percentage': '65.35%', 'elapsed_time': '3h 42m 36s', 'remaining_time': '1h 58m 2s'}\n",
      "{'loss': 2.03343315, 'token_acc': 0.56322694, 'grad_norm': 1.82395792, 'learning_rate': 2.878e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056896, 'epoch': 0.66, 'global_step/max_steps': '765/1163', 'percentage': '65.78%', 'elapsed_time': '3h 44m 5s', 'remaining_time': '1h 56m 34s'}\n",
      "{'loss': 1.83682346, 'token_acc': 0.60570011, 'grad_norm': 1.41695142, 'learning_rate': 2.814e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056887, 'epoch': 0.66, 'global_step/max_steps': '770/1163', 'percentage': '66.21%', 'elapsed_time': '3h 45m 35s', 'remaining_time': '1h 55m 8s'}\n",
      "{'loss': 1.89859924, 'token_acc': 0.59265891, 'grad_norm': 1.28640819, 'learning_rate': 2.75e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056888, 'epoch': 0.67, 'global_step/max_steps': '775/1163', 'percentage': '66.64%', 'elapsed_time': '3h 47m 2s', 'remaining_time': '1h 53m 40s'}\n",
      "{'loss': 1.95143242, 'token_acc': 0.57994639, 'grad_norm': 1.17674899, 'learning_rate': 2.687e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056886, 'epoch': 0.67, 'global_step/max_steps': '780/1163', 'percentage': '67.07%', 'elapsed_time': '3h 48m 31s', 'remaining_time': '1h 52m 12s'}\n",
      "{'loss': 1.91283283, 'token_acc': 0.5882703, 'grad_norm': 1.37502146, 'learning_rate': 2.624e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056883, 'epoch': 0.68, 'global_step/max_steps': '785/1163', 'percentage': '67.50%', 'elapsed_time': '3h 49m 59s', 'remaining_time': '1h 50m 44s'}\n",
      "{'loss': 1.87573986, 'token_acc': 0.60100052, 'grad_norm': 1.48874688, 'learning_rate': 2.562e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056891, 'epoch': 0.68, 'global_step/max_steps': '790/1163', 'percentage': '67.93%', 'elapsed_time': '3h 51m 25s', 'remaining_time': '1h 49m 16s'}\n",
      "{'loss': 1.9867363, 'token_acc': 0.57644301, 'grad_norm': 1.42572439, 'learning_rate': 2.5e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056899, 'epoch': 0.68, 'global_step/max_steps': '795/1163', 'percentage': '68.36%', 'elapsed_time': '3h 52m 51s', 'remaining_time': '1h 47m 47s'}\n",
      "{'loss': 1.88225136, 'token_acc': 0.59500971, 'grad_norm': 1.16751146, 'learning_rate': 2.439e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056901, 'epoch': 0.69, 'global_step/max_steps': '800/1163', 'percentage': '68.79%', 'elapsed_time': '3h 54m 19s', 'remaining_time': '1h 46m 19s'}\n",
      "{'loss': 1.93939686, 'token_acc': 0.5824936, 'grad_norm': 1.35606229, 'learning_rate': 2.378e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056888, 'epoch': 0.69, 'global_step/max_steps': '805/1163', 'percentage': '69.22%', 'elapsed_time': '3h 55m 50s', 'remaining_time': '1h 44m 52s'}\n",
      "{'loss': 1.78522549, 'token_acc': 0.62192471, 'grad_norm': 1.43972707, 'learning_rate': 2.318e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056894, 'epoch': 0.7, 'global_step/max_steps': '810/1163', 'percentage': '69.65%', 'elapsed_time': '3h 57m 16s', 'remaining_time': '1h 43m 24s'}\n",
      "{'loss': 1.85819626, 'token_acc': 0.59482286, 'grad_norm': 1.56367493, 'learning_rate': 2.258e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056897, 'epoch': 0.7, 'global_step/max_steps': '815/1163', 'percentage': '70.08%', 'elapsed_time': '3h 58m 43s', 'remaining_time': '1h 41m 56s'}\n",
      "{'loss': 1.92712593, 'token_acc': 0.58554729, 'grad_norm': 1.59451902, 'learning_rate': 2.199e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056896, 'epoch': 0.71, 'global_step/max_steps': '820/1163', 'percentage': '70.51%', 'elapsed_time': '4h 0m 11s', 'remaining_time': '1h 40m 28s'}\n",
      "{'loss': 1.894491, 'token_acc': 0.59346143, 'grad_norm': 1.35942972, 'learning_rate': 2.14e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056899, 'epoch': 0.71, 'global_step/max_steps': '825/1163', 'percentage': '70.94%', 'elapsed_time': '4h 1m 39s', 'remaining_time': '1h 39m 0s'}\n",
      "{'loss': 2.0105999, 'token_acc': 0.56340247, 'grad_norm': 1.36789453, 'learning_rate': 2.082e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056895, 'epoch': 0.71, 'global_step/max_steps': '830/1163', 'percentage': '71.37%', 'elapsed_time': '4h 3m 7s', 'remaining_time': '1h 37m 32s'}\n",
      "{'loss': 1.92134018, 'token_acc': 0.58790309, 'grad_norm': 1.53482199, 'learning_rate': 2.024e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056901, 'epoch': 0.72, 'global_step/max_steps': '835/1163', 'percentage': '71.80%', 'elapsed_time': '4h 4m 34s', 'remaining_time': '1h 36m 4s'}\n",
      "{'loss': 1.87576427, 'token_acc': 0.59834549, 'grad_norm': 1.27903032, 'learning_rate': 1.967e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.0569, 'epoch': 0.72, 'global_step/max_steps': '840/1163', 'percentage': '72.23%', 'elapsed_time': '4h 6m 2s', 'remaining_time': '1h 34m 36s'}\n",
      "{'loss': 1.87322216, 'token_acc': 0.60016353, 'grad_norm': 1.42239571, 'learning_rate': 1.911e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.0569, 'epoch': 0.73, 'global_step/max_steps': '845/1163', 'percentage': '72.66%', 'elapsed_time': '4h 7m 30s', 'remaining_time': '1h 33m 8s'}\n",
      "{'loss': 1.99498196, 'token_acc': 0.5722999, 'grad_norm': 1.39314997, 'learning_rate': 1.856e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056906, 'epoch': 0.73, 'global_step/max_steps': '850/1163', 'percentage': '73.09%', 'elapsed_time': '4h 8m 56s', 'remaining_time': '1h 31m 40s'}\n",
      "{'loss': 1.99955616, 'token_acc': 0.56929461, 'grad_norm': 1.45186138, 'learning_rate': 1.801e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056901, 'epoch': 0.74, 'global_step/max_steps': '855/1163', 'percentage': '73.52%', 'elapsed_time': '4h 10m 25s', 'remaining_time': '1h 30m 12s'}\n",
      "{'loss': 1.97495289, 'token_acc': 0.57508385, 'grad_norm': 1.50136173, 'learning_rate': 1.746e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056901, 'epoch': 0.74, 'global_step/max_steps': '860/1163', 'percentage': '73.95%', 'elapsed_time': '4h 11m 53s', 'remaining_time': '1h 28m 44s'}\n",
      "{'loss': 1.83765335, 'token_acc': 0.60912698, 'grad_norm': 1.44913507, 'learning_rate': 1.693e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056899, 'epoch': 0.74, 'global_step/max_steps': '865/1163', 'percentage': '74.38%', 'elapsed_time': '4h 13m 21s', 'remaining_time': '1h 27m 17s'}\n",
      "Train:  74%|███████▍  | 865/1163 [4:13:21<1:26:57, 17.51s/it]\n",
      "Train:  74%|███████▍  | 865/1163 [4:13:21<1:26:57, 17.51s/it]\n",
      "Train:  74%|███████▍  | 866/1163 [4:13:40<1:28:36, 17.90s/it]\n",
      "Train:  75%|███████▍  | 867/1163 [4:13:58<1:28:33, 17.95s/it]\n",
      "Train:  75%|███████▍  | 868/1163 [4:14:16<1:27:15, 17.75s/it]\n",
      "Train:  75%|███████▍  | 869/1163 [4:14:33<1:26:27, 17.64s/it]\n",
      "Train:  75%|███████▍  | 870/1163 [4:14:50<1:25:25, 17.49s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  75%|███████▍  | 870/1163 [4:14:50<1:25:25, 17.49s/it]\n",
      "Train:  75%|███████▍  | 870/1163 [4:14:50<1:25:25, 17.49s/it]\n",
      "Train:  75%|███████▍  | 871/1163 [4:15:08<1:25:05, 17.49s/it]\n",
      "Train:  75%|███████▍  | 872/1163 [4:15:25<1:24:04, 17.33s/it]\n",
      "Train:  75%|███████▌  | 873/1163 [4:15:43<1:24:47, 17.54s/it]\n",
      "Train:  75%|███████▌  | 874/1163 [4:16:00<1:24:00, 17.44s/it]\n",
      "Train:  75%|███████▌  | 875/1163 [4:16:18<1:24:43, 17.65s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  75%|███████▌  | 875/1163 [4:16:18<1:24:43, 17.65s/it]\n",
      "Train:  75%|███████▌  | 875/1163 [4:16:18<1:24:43, 17.65s/it]\n",
      "Train:  75%|███████▌  | 876/1163 [4:16:35<1:23:37, 17.48s/it]\n",
      "Train:  75%|███████▌  | 877/1163 [4:16:54<1:25:14, 17.88s/it]\n",
      "Train:  75%|███████▌  | 878/1163 [4:17:12<1:24:53, 17.87s/it]\n",
      "Train:  76%|███████▌  | 879/1163 [4:17:30<1:25:40, 18.10s/it]\n",
      "Train:  76%|███████▌  | 880/1163 [4:17:50<1:28:01, 18.66s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  76%|███████▌  | 880/1163 [4:17:50<1:28:01, 18.66s/it]\n",
      "Train:  76%|███████▌  | 880/1163 [4:17:50<1:28:01, 18.66s/it]\n",
      "Train:  76%|███████▌  | 881/1163 [4:18:08<1:26:18, 18.36s/it]\n",
      "Train:  76%|███████▌  | 882/1163 [4:18:25<1:24:02, 17.94s/it]\n",
      "Train:  76%|███████▌  | 883/1163 [4:18:42<1:22:51, 17.76s/it]\n",
      "Train:  76%|███████▌  | 884/1163 [4:19:00<1:22:18, 17.70s/it]\n",
      "Train:  76%|███████▌  | 885/1163 [4:19:19<1:23:41, 18.06s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  76%|███████▌  | 885/1163 [4:19:19<1:23:41, 18.06s/it]\n",
      "Train:  76%|███████▌  | 885/1163 [4:19:19<1:23:41, 18.06s/it]\n",
      "Train:  76%|███████▌  | 886/1163 [4:19:36<1:22:17, 17.82s/it]\n",
      "Train:  76%|███████▋  | 887/1163 [4:19:54<1:22:15, 17.88s/it]\n",
      "Train:  76%|███████▋  | 888/1163 [4:20:11<1:20:40, 17.60s/it]\n",
      "Train:  76%|███████▋  | 889/1163 [4:20:28<1:19:07, 17.33s/it]\n",
      "Train:  77%|███████▋  | 890/1163 [4:20:46<1:20:10, 17.62s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  77%|███████▋  | 890/1163 [4:20:46<1:20:10, 17.62s/it]\n",
      "Train:  77%|███████▋  | 890/1163 [4:20:46<1:20:10, 17.62s/it]\n",
      "Train:  77%|███████▋  | 891/1163 [4:21:03<1:19:30, 17.54s/it]\n",
      "Train:  77%|███████▋  | 892/1163 [4:21:22<1:20:09, 17.75s/it]\n",
      "Train:  77%|███████▋  | 893/1163 [4:21:39<1:18:55, 17.54s/it]\n",
      "Train:  77%|███████▋  | 894/1163 [4:21:56<1:17:50, 17.36s/it]\n",
      "Train:  77%|███████▋  | 895/1163 [4:22:12<1:16:00, 17.02s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  77%|███████▋  | 895/1163 [4:22:12<1:16:00, 17.02s/it]\n",
      "Train:  77%|███████▋  | 895/1163 [4:22:12<1:16:00, 17.02s/it]\n",
      "Train:  77%|███████▋  | 896/1163 [4:22:30<1:16:51, 17.27s/it]\n",
      "Train:  77%|███████▋  | 897/1163 [4:22:47<1:16:20, 17.22s/it]\n",
      "Train:  77%|███████▋  | 898/1163 [4:23:03<1:15:12, 17.03s/it]\n",
      "Train:  77%|███████▋  | 899/1163 [4:23:21<1:15:57, 17.26s/it]\n",
      "Train:  77%|███████▋  | 900/1163 [4:23:38<1:15:18, 17.18s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  77%|███████▋  | 900/1163 [4:23:38<1:15:18, 17.18s/it]\n",
      "Train:  77%|███████▋  | 900/1163 [4:23:38<1:15:18, 17.18s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v12-20250928-082402/checkpoint-900\n",
      "\n",
      "Train:  77%|███████▋  | 901/1163 [4:23:57<1:17:36, 17.77s/it]\n",
      "Train:  78%|███████▊  | 902/1163 [4:24:16<1:18:43, 18.10s/it]\n",
      "Train:  78%|███████▊  | 903/1163 [4:24:34<1:17:32, 17.90s/it]\n",
      "Train:  78%|███████▊  | 904/1163 [4:24:51<1:17:14, 17.89s/it]\n",
      "Train:  78%|███████▊  | 905/1163 [4:25:10<1:17:34, 18.04s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  78%|███████▊  | 905/1163 [4:25:10<1:17:34, 18.04s/it]\n",
      "Train:  78%|███████▊  | 905/1163 [4:25:10<1:17:34, 18.04s/it]\n",
      "Train:  78%|███████▊  | 906/1163 [4:25:28<1:16:59, 17.97s/it]\n",
      "Train:  78%|███████▊  | 907/1163 [4:25:45<1:16:24, 17.91s/it]\n",
      "Train:  78%|███████▊  | 908/1163 [4:26:03<1:15:52, 17.85s/it]\n",
      "Train:  78%|███████▊  | 909/1163 [4:26:21<1:15:19, 17.79s/it]\n",
      "Train:  78%|███████▊  | 910/1163 [4:26:41<1:17:55, 18.48s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  78%|███████▊  | 910/1163 [4:26:41<1:17:55, 18.48s/it]\n",
      "Train:  78%|███████▊  | 910/1163 [4:26:41<1:17:55, 18.48s/it]\n",
      "Train:  78%|███████▊  | 911/1163 [4:26:58<1:16:35, 18.24s/it]\n",
      "Train:  78%|███████▊  | 912/1163 [4:27:16<1:15:08, 17.96s/it]\n",
      "Train:  79%|███████▊  | 913/1163 [4:27:32<1:12:52, 17.49s/it]\n",
      "Train:  79%|███████▊  | 914/1163 [4:27:50<1:13:02, 17.60s/it]\n",
      "Train:  79%|███████▊  | 915/1163 [4:28:08<1:13:31, 17.79s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  79%|███████▊  | 915/1163 [4:28:08<1:13:31, 17.79s/it]\n",
      "Train:  79%|███████▊  | 915/1163 [4:28:08<1:13:31, 17.79s/it]\n",
      "Train:  79%|███████▉  | 916/1163 [4:28:26<1:12:48, 17.68s/it]\n",
      "Train:  79%|███████▉  | 917/1163 [4:28:44<1:13:46, 17.99s/it]\n",
      "Train:  79%|███████▉  | 918/1163 [4:29:02<1:12:51, 17.84s/it]\n",
      "Train:  79%|███████▉  | 919/1163 [4:29:19<1:11:15, 17.52s/it]\n",
      "Train:  79%|███████▉  | 920/1163 [4:29:36<1:10:09, 17.32s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  79%|███████▉  | 920/1163 [4:29:36<1:10:09, 17.32s/it]\n",
      "Train:  79%|███████▉  | 920/1163 [4:29:36<1:10:09, 17.32s/it]\n",
      "Train:  79%|███████▉  | 921/1163 [4:29:53<1:10:00, 17.36s/it]\n",
      "Train:  79%|███████▉  | 922/1163 [4:30:10<1:09:01, 17.18s/it]\n",
      "Train:  79%|███████▉  | 923/1163 [4:30:27<1:09:18, 17.33s/it]\n",
      "Train:  79%|███████▉  | 924/1163 [4:30:46<1:10:59, 17.82s/it]\n",
      "Train:  80%|███████▉  | 925/1163 [4:31:07<1:13:42, 18.58s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  80%|███████▉  | 925/1163 [4:31:07<1:13:42, 18.58s/it]\n",
      "Train:  80%|███████▉  | 925/1163 [4:31:07<1:13:42, 18.58s/it]\n",
      "Train:  80%|███████▉  | 926/1163 [4:31:26<1:13:47, 18.68s/it]\n",
      "Train:  80%|███████▉  | 927/1163 [4:31:43<1:11:25, 18.16s/it]\n",
      "Train:  80%|███████▉  | 928/1163 [4:32:01<1:10:56, 18.11s/it]\n",
      "Train:  80%|███████▉  | 929/1163 [4:32:19<1:10:23, 18.05s/it]\n",
      "Train:  80%|███████▉  | 930/1163 [4:32:36<1:09:12, 17.82s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  80%|███████▉  | 930/1163 [4:32:36<1:09:12, 17.82s/it]\n",
      "Train:  80%|███████▉  | 930/1163 [4:32:36<1:09:12, 17.82s/it]\n",
      "Train:  80%|████████  | 931/1163 [4:32:54<1:09:25, 17.96s/it]\n",
      "Train:  80%|████████  | 932/1163 [4:33:13<1:10:05, 18.20s/it]\n",
      "Train:  80%|████████  | 933/1163 [4:33:30<1:08:41, 17.92s/it]\n",
      "Train:  80%|████████  | 934/1163 [4:33:48<1:08:18, 17.90s/it]\n",
      "Train:  80%|████████  | 935/1163 [4:34:06<1:07:38, 17.80s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  80%|████████  | 935/1163 [4:34:06<1:07:38, 17.80s/it]\n",
      "Train:  80%|████████  | 935/1163 [4:34:06<1:07:38, 17.80s/it]\n",
      "Train:  80%|████████  | 936/1163 [4:34:24<1:08:18, 18.06s/it]\n",
      "Train:  81%|████████  | 937/1163 [4:34:43<1:08:53, 18.29s/it]\n",
      "Train:  81%|████████  | 938/1163 [4:35:00<1:06:57, 17.86s/it]\n",
      "Train:  81%|████████  | 939/1163 [4:35:17<1:06:08, 17.72s/it]\n",
      "Train:  81%|████████  | 940/1163 [4:35:35<1:06:17, 17.83s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  81%|████████  | 940/1163 [4:35:35<1:06:17, 17.83s/it]\n",
      "Train:  81%|████████  | 940/1163 [4:35:35<1:06:17, 17.83s/it]\n",
      "Train:  81%|████████  | 941/1163 [4:35:53<1:05:37, 17.73s/it]\n",
      "Train:  81%|████████  | 942/1163 [4:36:10<1:04:38, 17.55s/it]\n",
      "Train:  81%|████████  | 943/1163 [4:36:28<1:04:53, 17.70s/it]\n",
      "Train:  81%|████████  | 944/1163 [4:36:45<1:04:06, 17.56s/it]\n",
      "Train:  81%|████████▏ | 945/1163 [4:37:03<1:03:59, 17.61s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  81%|████████▏ | 945/1163 [4:37:03<1:03:59, 17.61s/it]\n",
      "Train:  81%|████████▏ | 945/1163 [4:37:03<1:03:59, 17.61s/it]\n",
      "Train:  81%|████████▏ | 946/1163 [4:37:24<1:06:58, 18.52s/it]\n",
      "Train:  81%|████████▏ | 947/1163 [4:37:42<1:06:43, 18.53s/it]\n",
      "Train:  82%|████████▏ | 948/1163 [4:37:59<1:04:31, 18.01s/it]\n",
      "Train:  82%|████████▏ | 949/1163 [4:38:17<1:04:32, 18.10s/it]\n",
      "Train:  82%|████████▏ | 950/1163 [4:38:36<1:04:46, 18.25s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  82%|████████▏ | 950/1163 [4:38:36<1:04:46, 18.25s/it]\n",
      "Train:  82%|████████▏ | 950/1163 [4:38:36<1:04:46, 18.25s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v12-20250928-082402/checkpoint-950\n",
      "\n",
      "Train:  82%|████████▏ | 951/1163 [4:38:54<1:04:35, 18.28s/it]\n",
      "Train:  82%|████████▏ | 952/1163 [4:39:12<1:03:45, 18.13s/it]\n",
      "Train:  82%|████████▏ | 953/1163 [4:39:31<1:04:42, 18.49s/it]\n",
      "Train:  82%|████████▏ | 954/1163 [4:39:49<1:03:59, 18.37s/it]\n",
      "Train:  82%|████████▏ | 955/1163 [4:40:09<1:05:08, 18.79s/it]\n",
      "                                                             \n",
      "\n",
      "Train:  82%|████████▏ | 955/1163 [4:40:09<1:05:08, 18.79s/it]\n",
      "Train:  82%|████████▏ | 955/1163 [4:40:09<1:05:08, 18.79s/it]\n",
      "Train:  82%|████████▏ | 956/1163 [4:40:26<1:03:07, 18.30s/it]\n",
      "Train:  82%|████████▏ | 957/1163 [4:40:45<1:03:17, 18.43s/it]\n",
      "Train:  82%|████████▏ | 958/1163 [4:41:03<1:02:25, 18.27s/it]\n",
      "Train:  82%|████████▏ | 959/1163 [4:41:21<1:01:28, 18.08s/it]\n",
      "Train:  83%|████████▎ | 960/1163 [4:41:37<59:43, 17.65s/it]  \n",
      "                                                           \n",
      "\n",
      "Train:  83%|████████▎ | 960/1163 [4:41:37<59:43, 17.65s/it]\n",
      "Train:  83%|████████▎ | 960/1163 [4:41:37<59:43, 17.65s/it]\n",
      "Train:  83%|████████▎ | 961/1163 [4:41:56<1:00:17, 17.91s/it]\n",
      "Train:  83%|████████▎ | 962/1163 [4:42:14<59:59, 17.91s/it]  \n",
      "Train:  83%|████████▎ | 963/1163 [4:42:31<59:20, 17.80s/it]\n",
      "Train:  83%|████████▎ | 964/1163 [4:42:49<58:30, 17.64s/it]\n",
      "Train:  83%|████████▎ | 965/1163 [4:43:06<57:58, 17.57s/it]\n",
      "                                                           \n",
      "\n",
      "Train:  83%|████████▎ | 965/1163 [4:43:06<57:58, 17.57s/it]\n",
      "Train:  83%|████████▎ | 965/1163 [4:43:06<57:58, 17.57s/it]\n",
      "Train:  83%|████████▎ | 966/1163 [4:43:23<57:15, 17.44s/it]\n",
      "Train:  83%|████████▎ | 967/1163 [4:43:41<57:04, 17.47s/it]\n",
      "Train:  83%|████████▎ | 968/1163 [4:43:59<57:11, 17.60s/it]\n",
      "Train:  83%|████████▎ | 969/1163 [4:44:16<56:48, 17.57s/it]\n",
      "Train:  83%|████████▎ | 970/1163 [4:44:34<56:26, 17.55s/it]\n",
      "                                                           \n",
      "\n",
      "Train:  83%|████████▎ | 970/1163 [4:44:34<56:26, 17.55s/it]\n",
      "Train:  83%|████████▎ | 970/1163 [4:44:34<56:26, 17.55s/it]\n",
      "Train:  83%|████████▎ | 971/1163 [4:44:53<58:00, 18.13s/it]\n",
      "Train:  84%|████████▎ | 972/1163 [4:45:11<57:41, 18.12s/it]\n",
      "Train:  84%|████████▎ | 973/1163 [4:45:28<56:16, 17.77s/it]\n",
      "Train:  84%|████████▎ | 974/1163 [4:45:45<55:16, 17.55s/it]\n",
      "Train:  84%|████████▍ | 975/1163 [4:46:03<54:56, 17.53s/it]\n",
      "                                                           \n",
      "\n",
      "Train:  84%|████████▍ | 975/1163 [4:46:03<54:56, 17.53s/it]\n",
      "Train:  84%|████████▍ | 975/1163 [4:46:03<54:56, 17.53s/it]\n",
      "Train:  84%|████████▍ | 976/1163 [4:46:21<54:59, 17.65s/it]\n",
      "Train:  84%|████████▍ | 977/1163 [4:46:37<54:04, 17.44s/it]\n",
      "Train:  84%|████████▍ | 978/1163 [4:46:55<53:30, 17.36s/it]\n",
      "Train:  84%|████████▍ | 979/1163 [4:47:12<53:00, 17.28s/it]\n",
      "Train:  84%|████████▍ | 980/1163 [4:47:29<52:17, 17.15s/it]\n",
      "                                                           \n",
      "\n",
      "Train:  84%|████████▍ | 980/1163 [4:47:29<52:17, 17.15s/it]\n",
      "Train:  84%|████████▍ | 980/1163 [4:47:29<52:17, 17.15s/it]\n",
      "Train:  84%|████████▍ | 981/1163 [4:47:46<52:28, 17.30s/it]\n",
      "Train:  84%|████████▍ | 982/1163 [4:48:05<53:13, 17.64s/it]\n",
      "Train:  85%|████████▍ | 983/1163 [4:48:22<52:17, 17.43s/it]\n",
      "Train:  85%|████████▍ | 984/1163 [4:48:41<53:44, 18.01s/it]\n",
      "Train:  85%|████████▍ | 985/1163 [4:48:58<52:31, 17.70s/it]\n",
      "                                                           \n",
      "\n",
      "Train:  85%|████████▍ | 985/1163 [4:48:58<52:31, 17.70s/it]\n",
      "Train:  85%|████████▍ | 985/1163 [4:48:58<52:31, 17.70s/it]\n",
      "Train:  85%|████████▍ | 986/1163 [4:49:15<51:58, 17.62s/it]\n",
      "Train:  85%|████████▍ | 987/1163 [4:49:32<51:08, 17.43s/it]\n",
      "Train:  85%|████████▍ | 988/1163 [4:49:50<51:06, 17.52s/it]\n",
      "Train:  85%|████████▌ | 989/1163 [4:50:09<51:35, 17.79s/it]\n",
      "Train:  85%|████████▌ | 990/1163 [4:50:26<51:02, 17.70s/it]\n",
      "                                                           \n",
      "\n",
      "Train:  85%|████████▌ | 990/1163 [4:50:26<51:02, 17.70s/it]\n",
      "Train:  85%|████████▌ | 990/1163 [4:50:26<51:02, 17.70s/it]\n",
      "Train:  85%|████████▌ | 991/1163 [4:50:44<51:00, 17.79s/it]\n",
      "Train:  85%|████████▌ | 992/1163 [4:51:01<49:55, 17.52s/it]\n",
      "Train:  85%|████████▌ | 993/1163 [4:51:18<48:52, 17.25s/it]\n",
      "Train:  85%|████████▌ | 994/1163 [4:51:35<48:44, 17.30s/it]\n",
      "Train:  86%|████████▌ | 995/1163 [4:51:52<48:14, 17.23s/it]\n",
      "                                                           \n",
      "\n",
      "Train:  86%|████████▌ | 995/1163 [4:51:52<48:14, 17.23s/it]\n",
      "Train:  86%|████████▌ | 995/1163 [4:51:52<48:14, 17.23s/it]\n",
      "Train:  86%|████████▌ | 996/1163 [4:52:10<48:25, 17.40s/it]\n",
      "Train:  86%|████████▌ | 997/1163 [4:52:27<48:17, 17.45s/it]\n",
      "Train:  86%|████████▌ | 998/1163 [4:52:45<48:10, 17.52s/it]\n",
      "Train:  86%|████████▌ | 999/1163 [4:53:02<47:46, 17.48s/it]\n",
      "Train:  86%|████████▌ | 1000/1163 [4:53:19<47:06, 17.34s/it]\n",
      "                                                            \n",
      "\n",
      "Train:  86%|████████▌ | 1000/1163 [4:53:19<47:06, 17.34s/it]\n",
      "Train:  86%|████████▌ | 1000/1163 [4:53:19<47:06, 17.34s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v12-20250928-082402/checkpoint-1000\n",
      "\n",
      "Train:  86%|████████▌ | 1001/1163 [4:53:39<48:14, 17.86s/it]\n",
      "Train:  86%|████████▌ | 1002/1163 [4:53:56<47:13, 17.60s/it]\n",
      "Train:  86%|████████▌ | 1003/1163 [4:54:14<47:39, 17.87s/it]\n",
      "Train:  86%|████████▋ | 1004/1163 [4:54:31<46:58, 17.73s/it]\n",
      "Train:  86%|████████▋ | 1005/1163 [4:54:49<46:34, 17.69s/it]\n",
      "                                                            \n",
      "\n",
      "Train:  86%|████████▋ | 1005/1163 [4:54:49<46:34, 17.69s/it]\n",
      "Train:  86%|████████▋ | 1005/1163 [4:54:49<46:34, 17.69s/it]\n",
      "Train:  87%|████████▋ | 1006/1163 [4:55:08<47:11, 18.03s/it]\n",
      "Train:  87%|████████▋ | 1007/1163 [4:55:25<46:33, 17.91s/it]\n",
      "Train:  87%|████████▋ | 1008/1163 [4:55:43<45:54, 17.77s/it]\n",
      "Train:  87%|████████▋ | 1009/1163 [4:56:01<45:30, 17.73s/it]\n",
      "Train:  87%|████████▋ | 1010/1163 [4:56:18<45:07, 17.70s/it]\n",
      "                                                            \n",
      "{'loss': 1.88623238, 'token_acc': 0.59603776, 'grad_norm': 1.56919074, 'learning_rate': 1.64e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056896, 'epoch': 0.75, 'global_step/max_steps': '870/1163', 'percentage': '74.81%', 'elapsed_time': '4h 14m 50s', 'remaining_time': '1h 25m 49s'}\n",
      "{'loss': 1.86661949, 'token_acc': 0.59974706, 'grad_norm': 1.43179953, 'learning_rate': 1.587e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056896, 'epoch': 0.75, 'global_step/max_steps': '875/1163', 'percentage': '75.24%', 'elapsed_time': '4h 16m 18s', 'remaining_time': '1h 24m 21s'}\n",
      "{'loss': 1.9644783, 'token_acc': 0.57749581, 'grad_norm': 1.03207445, 'learning_rate': 1.536e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.05688, 'epoch': 0.76, 'global_step/max_steps': '880/1163', 'percentage': '75.67%', 'elapsed_time': '4h 17m 50s', 'remaining_time': '1h 22m 55s'}\n",
      "{'loss': 1.81722088, 'token_acc': 0.60806854, 'grad_norm': 1.13905895, 'learning_rate': 1.485e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056878, 'epoch': 0.76, 'global_step/max_steps': '885/1163', 'percentage': '76.10%', 'elapsed_time': '4h 19m 19s', 'remaining_time': '1h 21m 27s'}\n",
      "{'loss': 1.91790199, 'token_acc': 0.59190745, 'grad_norm': 1.20191634, 'learning_rate': 1.434e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056881, 'epoch': 0.77, 'global_step/max_steps': '890/1163', 'percentage': '76.53%', 'elapsed_time': '4h 20m 46s', 'remaining_time': '1h 19m 59s'}\n",
      "{'loss': 1.98825779, 'token_acc': 0.57661721, 'grad_norm': 1.79305089, 'learning_rate': 1.385e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056888, 'epoch': 0.77, 'global_step/max_steps': '895/1163', 'percentage': '76.96%', 'elapsed_time': '4h 22m 12s', 'remaining_time': '1h 18m 30s'}\n",
      "{'loss': 1.89238949, 'token_acc': 0.59659733, 'grad_norm': 1.3837769, 'learning_rate': 1.336e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056894, 'epoch': 0.77, 'global_step/max_steps': '900/1163', 'percentage': '77.39%', 'elapsed_time': '4h 23m 38s', 'remaining_time': '1h 17m 2s'}\n",
      "{'loss': 2.06057777, 'token_acc': 0.55284922, 'grad_norm': 1.36979926, 'learning_rate': 1.288e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.05688, 'epoch': 0.78, 'global_step/max_steps': '905/1163', 'percentage': '77.82%', 'elapsed_time': '4h 25m 10s', 'remaining_time': '1h 15m 35s'}\n",
      "{'loss': 1.79497757, 'token_acc': 0.61364534, 'grad_norm': 1.00158846, 'learning_rate': 1.241e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056869, 'epoch': 0.78, 'global_step/max_steps': '910/1163', 'percentage': '78.25%', 'elapsed_time': '4h 26m 41s', 'remaining_time': '1h 14m 8s'}\n",
      "{'loss': 2.00375729, 'token_acc': 0.57570855, 'grad_norm': 1.28398514, 'learning_rate': 1.194e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.05687, 'epoch': 0.79, 'global_step/max_steps': '915/1163', 'percentage': '78.68%', 'elapsed_time': '4h 28m 8s', 'remaining_time': '1h 12m 40s'}\n",
      "{'loss': 1.87540684, 'token_acc': 0.59880549, 'grad_norm': 1.51598096, 'learning_rate': 1.149e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056873, 'epoch': 0.79, 'global_step/max_steps': '920/1163', 'percentage': '79.11%', 'elapsed_time': '4h 29m 36s', 'remaining_time': '1h 11m 12s'}\n",
      "{'loss': 1.92374668, 'token_acc': 0.58219582, 'grad_norm': 1.06372285, 'learning_rate': 1.104e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056861, 'epoch': 0.8, 'global_step/max_steps': '925/1163', 'percentage': '79.54%', 'elapsed_time': '4h 31m 7s', 'remaining_time': '1h 9m 45s'}\n",
      "{'loss': 2.00694828, 'token_acc': 0.56907663, 'grad_norm': 1.47651362, 'learning_rate': 1.059e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056857, 'epoch': 0.8, 'global_step/max_steps': '930/1163', 'percentage': '79.97%', 'elapsed_time': '4h 32m 36s', 'remaining_time': '1h 8m 17s'}\n",
      "{'loss': 1.89044533, 'token_acc': 0.59563186, 'grad_norm': 1.40524828, 'learning_rate': 1.016e-05, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056851, 'epoch': 0.8, 'global_step/max_steps': '935/1163', 'percentage': '80.40%', 'elapsed_time': '4h 34m 6s', 'remaining_time': '1h 6m 50s'}\n",
      "{'loss': 1.9781004, 'token_acc': 0.57474323, 'grad_norm': 1.18493044, 'learning_rate': 9.73e-06, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056845, 'epoch': 0.81, 'global_step/max_steps': '940/1163', 'percentage': '80.83%', 'elapsed_time': '4h 35m 35s', 'remaining_time': '1h 5m 22s'}\n",
      "{'loss': 1.90511169, 'token_acc': 0.59599174, 'grad_norm': 1.26413155, 'learning_rate': 9.32e-06, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056846, 'epoch': 0.81, 'global_step/max_steps': '945/1163', 'percentage': '81.26%', 'elapsed_time': '4h 37m 3s', 'remaining_time': '1h 3m 54s'}\n",
      "{'loss': 1.92472897, 'token_acc': 0.58145977, 'grad_norm': 1.27767777, 'learning_rate': 8.91e-06, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056829, 'epoch': 0.82, 'global_step/max_steps': '950/1163', 'percentage': '81.69%', 'elapsed_time': '4h 38m 36s', 'remaining_time': '1h 2m 27s'}\n",
      "{'loss': 1.91978474, 'token_acc': 0.58301579, 'grad_norm': 1.11167324, 'learning_rate': 8.51e-06, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056811, 'epoch': 0.82, 'global_step/max_steps': '955/1163', 'percentage': '82.12%', 'elapsed_time': '4h 40m 9s', 'remaining_time': '1h 1m 1s'}\n",
      "{'loss': 1.94762192, 'token_acc': 0.58415678, 'grad_norm': 1.60415828, 'learning_rate': 8.11e-06, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056811, 'epoch': 0.83, 'global_step/max_steps': '960/1163', 'percentage': '82.55%', 'elapsed_time': '4h 41m 37s', 'remaining_time': '59m 33s'}\n",
      "{'loss': 1.93085175, 'token_acc': 0.5868127, 'grad_norm': 1.54147196, 'learning_rate': 7.73e-06, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056809, 'epoch': 0.83, 'global_step/max_steps': '965/1163', 'percentage': '82.98%', 'elapsed_time': '4h 43m 6s', 'remaining_time': '58m 5s'}\n",
      "{'loss': 1.77476978, 'token_acc': 0.61193859, 'grad_norm': 1.45665252, 'learning_rate': 7.35e-06, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.05681, 'epoch': 0.83, 'global_step/max_steps': '970/1163', 'percentage': '83.40%', 'elapsed_time': '4h 44m 34s', 'remaining_time': '56m 37s'}\n",
      "{'loss': 1.93414803, 'token_acc': 0.58103627, 'grad_norm': 1.25664341, 'learning_rate': 6.99e-06, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056807, 'epoch': 0.84, 'global_step/max_steps': '975/1163', 'percentage': '83.83%', 'elapsed_time': '4h 46m 3s', 'remaining_time': '55m 9s'}\n",
      "{'loss': 1.89744873, 'token_acc': 0.59039613, 'grad_norm': 1.54785359, 'learning_rate': 6.63e-06, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056813, 'epoch': 0.84, 'global_step/max_steps': '980/1163', 'percentage': '84.26%', 'elapsed_time': '4h 47m 29s', 'remaining_time': '53m 40s'}\n",
      "{'loss': 2.04886036, 'token_acc': 0.55939183, 'grad_norm': 1.69966638, 'learning_rate': 6.28e-06, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056809, 'epoch': 0.85, 'global_step/max_steps': '985/1163', 'percentage': '84.69%', 'elapsed_time': '4h 48m 58s', 'remaining_time': '52m 13s'}\n",
      "{'loss': 1.96154499, 'token_acc': 0.58301199, 'grad_norm': 1.51622653, 'learning_rate': 5.94e-06, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056809, 'epoch': 0.85, 'global_step/max_steps': '990/1163', 'percentage': '85.12%', 'elapsed_time': '4h 50m 26s', 'remaining_time': '50m 45s'}\n",
      "{'loss': 1.99437046, 'token_acc': 0.577893, 'grad_norm': 1.42476022, 'learning_rate': 5.61e-06, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056815, 'epoch': 0.86, 'global_step/max_steps': '995/1163', 'percentage': '85.55%', 'elapsed_time': '4h 51m 52s', 'remaining_time': '49m 16s'}\n",
      "{'loss': 1.78082924, 'token_acc': 0.61321225, 'grad_norm': 1.42208695, 'learning_rate': 5.28e-06, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056817, 'epoch': 0.86, 'global_step/max_steps': '1000/1163', 'percentage': '85.98%', 'elapsed_time': '4h 53m 19s', 'remaining_time': '47m 48s'}\n",
      "{'loss': 1.90336342, 'token_acc': 0.58781646, 'grad_norm': 1.41845596, 'learning_rate': 4.97e-06, 'memory(GiB)': 22.35, 'train_speed(iter/s)': 0.056812, 'epoch': 0.86, 'global_step/max_steps': '1005/1163', 'percentage': '86.41%', 'elapsed_time': '4h 54m 49s', 'remaining_time': '46m 21s'}\n",
      "{'loss': 1.99607334, 'token_acc': 0.5714361, 'grad_norm': 1.62798035, 'learning_rate': 4.66e-06, 'memory(GiB)': 22.46, 'train_speed(iter/s)': 0.056808, 'epoch': 0.87, 'global_step/max_steps': '1010/1163', 'percentage': '86.84%', 'elapsed_time': '4h 56m 18s', 'remaining_time': '44m 53s'}\n",
      "Train:  87%|████████▋ | 1010/1163 [4:56:18<45:07, 17.70s/it]\n",
      "Train:  87%|████████▋ | 1010/1163 [4:56:18<45:07, 17.70s/it]\n",
      "Train:  87%|████████▋ | 1011/1163 [4:56:37<45:42, 18.04s/it]\n",
      "Train:  87%|████████▋ | 1012/1163 [4:56:54<44:49, 17.81s/it]\n",
      "Train:  87%|████████▋ | 1013/1163 [4:57:12<44:13, 17.69s/it]\n",
      "Train:  87%|████████▋ | 1014/1163 [4:57:28<43:06, 17.36s/it]\n",
      "Train:  87%|████████▋ | 1015/1163 [4:57:46<42:48, 17.35s/it]\n",
      "                                                            \n",
      "\n",
      "Train:  87%|████████▋ | 1015/1163 [4:57:46<42:48, 17.35s/it]\n",
      "Train:  87%|████████▋ | 1015/1163 [4:57:46<42:48, 17.35s/it]\n",
      "Train:  87%|████████▋ | 1016/1163 [4:58:03<42:30, 17.35s/it]\n",
      "Train:  87%|████████▋ | 1017/1163 [4:58:21<42:27, 17.45s/it]\n",
      "Train:  88%|████████▊ | 1018/1163 [4:58:39<42:42, 17.67s/it]\n",
      "Train:  88%|████████▊ | 1019/1163 [4:58:56<42:18, 17.63s/it]\n",
      "Train:  88%|████████▊ | 1020/1163 [4:59:14<42:16, 17.74s/it]\n",
      "                                                            \n",
      "\n",
      "Train:  88%|████████▊ | 1020/1163 [4:59:14<42:16, 17.74s/it]\n",
      "Train:  88%|████████▊ | 1020/1163 [4:59:14<42:16, 17.74s/it]\n",
      "Train:  88%|████████▊ | 1021/1163 [4:59:35<44:14, 18.70s/it]\n",
      "Train:  88%|████████▊ | 1022/1163 [4:59:53<43:00, 18.30s/it]\n",
      "Train:  88%|████████▊ | 1023/1163 [5:00:10<42:18, 18.13s/it]\n",
      "Train:  88%|████████▊ | 1024/1163 [5:00:28<41:29, 17.91s/it]\n",
      "Train:  88%|████████▊ | 1025/1163 [5:00:46<41:23, 18.00s/it]\n",
      "                                                            \n",
      "\n",
      "Train:  88%|████████▊ | 1025/1163 [5:00:46<41:23, 18.00s/it]\n",
      "Train:  88%|████████▊ | 1025/1163 [5:00:46<41:23, 18.00s/it]\n",
      "Train:  88%|████████▊ | 1026/1163 [5:01:03<40:23, 17.69s/it]\n",
      "Train:  88%|████████▊ | 1027/1163 [5:01:20<39:40, 17.50s/it]\n",
      "Train:  88%|████████▊ | 1028/1163 [5:01:38<39:39, 17.62s/it]\n",
      "Train:  88%|████████▊ | 1029/1163 [5:01:55<39:14, 17.57s/it]\n",
      "Train:  89%|████████▊ | 1030/1163 [5:02:13<38:39, 17.44s/it]\n",
      "                                                            \n",
      "\n",
      "Train:  89%|████████▊ | 1030/1163 [5:02:13<38:39, 17.44s/it]\n",
      "Train:  89%|████████▊ | 1030/1163 [5:02:13<38:39, 17.44s/it]\n",
      "Train:  89%|████████▊ | 1031/1163 [5:02:30<38:14, 17.38s/it]\n",
      "Train:  89%|████████▊ | 1032/1163 [5:02:47<37:52, 17.35s/it]\n",
      "Train:  89%|████████▉ | 1033/1163 [5:03:05<37:39, 17.38s/it]\n",
      "Train:  89%|████████▉ | 1034/1163 [5:03:22<37:10, 17.29s/it]\n",
      "Train:  89%|████████▉ | 1035/1163 [5:03:39<37:02, 17.37s/it]\n",
      "                                                            \n",
      "\n",
      "Train:  89%|████████▉ | 1035/1163 [5:03:39<37:02, 17.37s/it]\n",
      "Train:  89%|████████▉ | 1035/1163 [5:03:39<37:02, 17.37s/it]\n",
      "Train:  89%|████████▉ | 1036/1163 [5:03:56<36:31, 17.26s/it]\n",
      "Train:  89%|████████▉ | 1037/1163 [5:04:15<37:08, 17.69s/it]\n",
      "Train:  89%|████████▉ | 1038/1163 [5:04:32<36:32, 17.54s/it]\n",
      "Train:  89%|████████▉ | 1039/1163 [5:04:50<36:22, 17.60s/it]\n",
      "Train:  89%|████████▉ | 1040/1163 [5:05:07<35:33, 17.35s/it]\n",
      "                                                            \n",
      "\n",
      "Train:  89%|████████▉ | 1040/1163 [5:05:07<35:33, 17.35s/it]\n",
      "Train:  89%|████████▉ | 1040/1163 [5:05:07<35:33, 17.35s/it]\n",
      "Train:  90%|████████▉ | 1041/1163 [5:05:24<35:39, 17.53s/it]\n",
      "Train:  90%|████████▉ | 1042/1163 [5:05:43<35:49, 17.76s/it]\n",
      "Train:  90%|████████▉ | 1043/1163 [5:06:00<35:08, 17.57s/it]\n",
      "Train:  90%|████████▉ | 1044/1163 [5:06:17<34:30, 17.40s/it]\n",
      "Train:  90%|████████▉ | 1045/1163 [5:06:35<34:23, 17.48s/it]\n",
      "                                                            \n",
      "\n",
      "Train:  90%|████████▉ | 1045/1163 [5:06:35<34:23, 17.48s/it]\n",
      "Train:  90%|████████▉ | 1045/1163 [5:06:35<34:23, 17.48s/it]\n",
      "Train:  90%|████████▉ | 1046/1163 [5:06:52<34:02, 17.46s/it]\n",
      "Train:  90%|█████████ | 1047/1163 [5:07:09<33:25, 17.29s/it]\n",
      "Train:  90%|█████████ | 1048/1163 [5:07:26<33:01, 17.23s/it]\n",
      "Train:  90%|█████████ | 1049/1163 [5:07:45<33:41, 17.73s/it]\n",
      "Train:  90%|█████████ | 1050/1163 [5:08:02<32:56, 17.49s/it]\n",
      "                                                            \n",
      "\n",
      "Train:  90%|█████████ | 1050/1163 [5:08:02<32:56, 17.49s/it]\n",
      "Train:  90%|█████████ | 1050/1163 [5:08:02<32:56, 17.49s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v12-20250928-082402/checkpoint-1050\n",
      "\n",
      "Train:  90%|█████████ | 1051/1163 [5:08:21<33:41, 18.05s/it]\n",
      "Train:  90%|█████████ | 1052/1163 [5:08:39<33:23, 18.05s/it]\n",
      "Train:  91%|█████████ | 1053/1163 [5:08:57<32:49, 17.91s/it]\n",
      "Train:  91%|█████████ | 1054/1163 [5:09:14<32:00, 17.62s/it]\n",
      "Train:  91%|█████████ | 1055/1163 [5:09:31<31:32, 17.52s/it]\n",
      "                                                            \n",
      "\n",
      "Train:  91%|█████████ | 1055/1163 [5:09:31<31:32, 17.52s/it]\n",
      "Train:  91%|█████████ | 1055/1163 [5:09:31<31:32, 17.52s/it]\n",
      "Train:  91%|█████████ | 1056/1163 [5:09:49<31:43, 17.79s/it]\n",
      "Train:  91%|█████████ | 1057/1163 [5:10:07<31:22, 17.76s/it]\n",
      "Train:  91%|█████████ | 1058/1163 [5:10:24<30:39, 17.52s/it]\n",
      "Train:  91%|█████████ | 1059/1163 [5:10:41<30:09, 17.40s/it]\n",
      "Train:  91%|█████████ | 1060/1163 [5:10:58<29:45, 17.34s/it]\n",
      "                                                            \n",
      "\n",
      "Train:  91%|█████████ | 1060/1163 [5:10:58<29:45, 17.34s/it]\n",
      "Train:  91%|█████████ | 1060/1163 [5:10:58<29:45, 17.34s/it]\n",
      "Train:  91%|█████████ | 1061/1163 [5:11:16<29:48, 17.53s/it]\n",
      "Train:  91%|█████████▏| 1062/1163 [5:11:33<28:58, 17.21s/it]\n",
      "Train:  91%|█████████▏| 1063/1163 [5:11:51<28:54, 17.35s/it]\n",
      "Train:  91%|█████████▏| 1064/1163 [5:12:08<28:31, 17.28s/it]\n",
      "Train:  92%|█████████▏| 1065/1163 [5:12:24<27:54, 17.09s/it]\n",
      "                                                            \n",
      "\n",
      "Train:  92%|█████████▏| 1065/1163 [5:12:24<27:54, 17.09s/it]\n",
      "Train:  92%|█████████▏| 1065/1163 [5:12:24<27:54, 17.09s/it]\n",
      "Train:  92%|█████████▏| 1066/1163 [5:12:41<27:36, 17.07s/it]\n",
      "Train:  92%|█████████▏| 1067/1163 [5:12:59<27:44, 17.34s/it]\n",
      "Train:  92%|█████████▏| 1068/1163 [5:13:17<27:47, 17.55s/it]\n",
      "Train:  92%|█████████▏| 1069/1163 [5:13:36<28:04, 17.92s/it]\n",
      "Train:  92%|█████████▏| 1070/1163 [5:13:53<27:13, 17.56s/it]\n",
      "                                                            \n",
      "\n",
      "Train:  92%|█████████▏| 1070/1163 [5:13:53<27:13, 17.56s/it]\n",
      "Train:  92%|█████████▏| 1070/1163 [5:13:53<27:13, 17.56s/it]\n",
      "Train:  92%|█████████▏| 1071/1163 [5:14:10<26:37, 17.37s/it]\n",
      "Train:  92%|█████████▏| 1072/1163 [5:14:28<26:38, 17.57s/it]\n",
      "Train:  92%|█████████▏| 1073/1163 [5:14:45<26:13, 17.48s/it]\n",
      "Train:  92%|█████████▏| 1074/1163 [5:15:03<26:15, 17.71s/it]\n",
      "Train:  92%|█████████▏| 1075/1163 [5:15:21<26:09, 17.84s/it]\n",
      "                                                            \n",
      "\n",
      "Train:  92%|█████████▏| 1075/1163 [5:15:21<26:09, 17.84s/it]\n",
      "Train:  92%|█████████▏| 1075/1163 [5:15:21<26:09, 17.84s/it]\n",
      "Train:  93%|█████████▎| 1076/1163 [5:15:39<25:33, 17.62s/it]\n",
      "Train:  93%|█████████▎| 1077/1163 [5:15:58<26:00, 18.14s/it]\n",
      "Train:  93%|█████████▎| 1078/1163 [5:16:15<25:16, 17.84s/it]\n",
      "Train:  93%|█████████▎| 1079/1163 [5:16:33<25:03, 17.90s/it]\n",
      "Train:  93%|█████████▎| 1080/1163 [5:16:51<24:42, 17.86s/it]\n",
      "                                                            \n",
      "\n",
      "Train:  93%|█████████▎| 1080/1163 [5:16:51<24:42, 17.86s/it]\n",
      "Train:  93%|█████████▎| 1080/1163 [5:16:51<24:42, 17.86s/it]\n",
      "Train:  93%|█████████▎| 1081/1163 [5:17:08<24:14, 17.74s/it]\n",
      "Train:  93%|█████████▎| 1082/1163 [5:17:26<23:44, 17.59s/it]\n",
      "Train:  93%|█████████▎| 1083/1163 [5:17:44<23:44, 17.80s/it]\n",
      "Train:  93%|█████████▎| 1084/1163 [5:18:01<23:14, 17.65s/it]\n",
      "Train:  93%|█████████▎| 1085/1163 [5:18:18<22:48, 17.54s/it]\n",
      "                                                            \n",
      "\n",
      "Train:  93%|█████████▎| 1085/1163 [5:18:18<22:48, 17.54s/it]\n",
      "Train:  93%|█████████▎| 1085/1163 [5:18:18<22:48, 17.54s/it]\n",
      "Train:  93%|█████████▎| 1086/1163 [5:18:35<22:08, 17.26s/it]\n",
      "Train:  93%|█████████▎| 1087/1163 [5:18:53<21:59, 17.36s/it]\n",
      "Train:  94%|█████████▎| 1088/1163 [5:19:12<22:30, 18.01s/it]\n",
      "Train:  94%|█████████▎| 1089/1163 [5:19:29<21:57, 17.80s/it]\n",
      "Train:  94%|█████████▎| 1090/1163 [5:19:47<21:42, 17.84s/it]\n",
      "                                                            \n",
      "\n",
      "Train:  94%|█████████▎| 1090/1163 [5:19:47<21:42, 17.84s/it]\n",
      "Train:  94%|█████████▎| 1090/1163 [5:19:47<21:42, 17.84s/it]\n",
      "Train:  94%|█████████▍| 1091/1163 [5:20:05<21:22, 17.81s/it]\n",
      "Train:  94%|█████████▍| 1092/1163 [5:20:25<21:54, 18.51s/it]\n",
      "Train:  94%|█████████▍| 1093/1163 [5:20:43<21:18, 18.26s/it]\n",
      "Train:  94%|█████████▍| 1094/1163 [5:21:00<20:35, 17.90s/it]\n",
      "Train:  94%|█████████▍| 1095/1163 [5:21:17<19:53, 17.56s/it]\n",
      "                                                            \n",
      "\n",
      "Train:  94%|█████████▍| 1095/1163 [5:21:17<19:53, 17.56s/it]\n",
      "Train:  94%|█████████▍| 1095/1163 [5:21:17<19:53, 17.56s/it]\n",
      "Train:  94%|█████████▍| 1096/1163 [5:21:35<19:44, 17.68s/it]\n",
      "Train:  94%|█████████▍| 1097/1163 [5:21:52<19:21, 17.60s/it]\n",
      "Train:  94%|█████████▍| 1098/1163 [5:22:10<19:04, 17.61s/it]\n",
      "Train:  94%|█████████▍| 1099/1163 [5:22:27<18:38, 17.47s/it]\n",
      "Train:  95%|█████████▍| 1100/1163 [5:22:45<18:31, 17.64s/it]\n",
      "                                                            \n",
      "\n",
      "Train:  95%|█████████▍| 1100/1163 [5:22:45<18:31, 17.64s/it]\n",
      "Train:  95%|█████████▍| 1100/1163 [5:22:45<18:31, 17.64s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v12-20250928-082402/checkpoint-1100\n",
      "\n",
      "Train:  95%|█████████▍| 1101/1163 [5:23:04<18:46, 18.16s/it]\n",
      "Train:  95%|█████████▍| 1102/1163 [5:23:23<18:28, 18.17s/it]\n",
      "Train:  95%|█████████▍| 1103/1163 [5:23:41<18:09, 18.15s/it]\n",
      "Train:  95%|█████████▍| 1104/1163 [5:23:58<17:39, 17.95s/it]\n",
      "Train:  95%|█████████▌| 1105/1163 [5:24:16<17:20, 17.94s/it]\n",
      "                                                            \n",
      "\n",
      "Train:  95%|█████████▌| 1105/1163 [5:24:16<17:20, 17.94s/it]\n",
      "Train:  95%|█████████▌| 1105/1163 [5:24:16<17:20, 17.94s/it]\n",
      "Train:  95%|█████████▌| 1106/1163 [5:24:33<16:46, 17.67s/it]\n",
      "Train:  95%|█████████▌| 1107/1163 [5:24:50<16:13, 17.39s/it]\n",
      "Train:  95%|█████████▌| 1108/1163 [5:25:07<15:46, 17.20s/it]\n",
      "Train:  95%|█████████▌| 1109/1163 [5:25:23<15:19, 17.02s/it]\n",
      "Train:  95%|█████████▌| 1110/1163 [5:25:42<15:26, 17.49s/it]\n",
      "                                                            \n",
      "\n",
      "Train:  95%|█████████▌| 1110/1163 [5:25:42<15:26, 17.49s/it]\n",
      "Train:  95%|█████████▌| 1110/1163 [5:25:42<15:26, 17.49s/it]\n",
      "Train:  96%|█████████▌| 1111/1163 [5:26:00<15:24, 17.78s/it]\n",
      "Train:  96%|█████████▌| 1112/1163 [5:26:18<15:13, 17.90s/it]\n",
      "Train:  96%|█████████▌| 1113/1163 [5:26:36<14:44, 17.69s/it]\n",
      "Train:  96%|█████████▌| 1114/1163 [5:26:56<15:00, 18.37s/it]\n",
      "Train:  96%|█████████▌| 1115/1163 [5:27:12<14:13, 17.79s/it]\n",
      "                                                            \n",
      "\n",
      "Train:  96%|█████████▌| 1115/1163 [5:27:12<14:13, 17.79s/it]\n",
      "Train:  96%|█████████▌| 1115/1163 [5:27:12<14:13, 17.79s/it]\n",
      "Train:  96%|█████████▌| 1116/1163 [5:27:30<14:05, 17.98s/it]\n",
      "Train:  96%|█████████▌| 1117/1163 [5:27:47<13:33, 17.68s/it]\n",
      "Train:  96%|█████████▌| 1118/1163 [5:28:04<13:04, 17.43s/it]\n",
      "Train:  96%|█████████▌| 1119/1163 [5:28:22<12:55, 17.62s/it]\n",
      "Train:  96%|█████████▋| 1120/1163 [5:28:40<12:42, 17.73s/it]\n",
      "                                                            \n",
      "\n",
      "Train:  96%|█████████▋| 1120/1163 [5:28:40<12:42, 17.73s/it]\n",
      "Train:  96%|█████████▋| 1120/1163 [5:28:40<12:42, 17.73s/it]\n",
      "Train:  96%|█████████▋| 1121/1163 [5:28:58<12:18, 17.58s/it]\n",
      "Train:  96%|█████████▋| 1122/1163 [5:29:15<11:56, 17.48s/it]\n",
      "Train:  97%|█████████▋| 1123/1163 [5:29:31<11:27, 17.20s/it]\n",
      "Train:  97%|█████████▋| 1124/1163 [5:29:49<11:14, 17.29s/it]\n",
      "Train:  97%|█████████▋| 1125/1163 [5:30:06<10:59, 17.34s/it]\n",
      "                                                            \n",
      "\n",
      "Train:  97%|█████████▋| 1125/1163 [5:30:06<10:59, 17.34s/it]\n",
      "Train:  97%|█████████▋| 1125/1163 [5:30:06<10:59, 17.34s/it]\n",
      "Train:  97%|█████████▋| 1126/1163 [5:30:24<10:44, 17.43s/it]\n",
      "Train:  97%|█████████▋| 1127/1163 [5:30:42<10:33, 17.59s/it]\n",
      "Train:  97%|█████████▋| 1128/1163 [5:31:00<10:23, 17.82s/it]\n",
      "Train:  97%|█████████▋| 1129/1163 [5:31:18<10:04, 17.79s/it]\n",
      "Train:  97%|█████████▋| 1130/1163 [5:31:37<09:55, 18.04s/it]\n",
      "                                                            \n",
      "\n",
      "Train:  97%|█████████▋| 1130/1163 [5:31:37<09:55, 18.04s/it]\n",
      "Train:  97%|█████████▋| 1130/1163 [5:31:37<09:55, 18.04s/it]\n",
      "Train:  97%|█████████▋| 1131/1163 [5:31:54<09:31, 17.85s/it]\n",
      "Train:  97%|█████████▋| 1132/1163 [5:32:11<09:05, 17.60s/it]\n",
      "Train:  97%|█████████▋| 1133/1163 [5:32:28<08:42, 17.40s/it]\n",
      "Train:  98%|█████████▊| 1134/1163 [5:32:46<08:28, 17.55s/it]\n",
      "Train:  98%|█████████▊| 1135/1163 [5:33:04<08:14, 17.67s/it]\n",
      "                                                            \n",
      "\n",
      "Train:  98%|█████████▊| 1135/1163 [5:33:04<08:14, 17.67s/it]\n",
      "Train:  98%|█████████▊| 1135/1163 [5:33:04<08:14, 17.67s/it]\n",
      "Train:  98%|█████████▊| 1136/1163 [5:33:21<07:53, 17.54s/it]\n",
      "Train:  98%|█████████▊| 1137/1163 [5:33:39<07:36, 17.55s/it]\n",
      "Train:  98%|█████████▊| 1138/1163 [5:33:55<07:11, 17.27s/it]\n",
      "Train:  98%|█████████▊| 1139/1163 [5:34:12<06:53, 17.22s/it]\n",
      "Train:  98%|█████████▊| 1140/1163 [5:34:30<06:35, 17.21s/it]\n",
      "                                                            \n",
      "\n",
      "Train:  98%|█████████▊| 1140/1163 [5:34:30<06:35, 17.21s/it]\n",
      "Train:  98%|█████████▊| 1140/1163 [5:34:30<06:35, 17.21s/it]\n",
      "Train:  98%|█████████▊| 1141/1163 [5:34:46<06:15, 17.08s/it]\n",
      "Train:  98%|█████████▊| 1142/1163 [5:35:04<06:00, 17.15s/it]\n",
      "Train:  98%|█████████▊| 1143/1163 [5:35:20<05:39, 16.98s/it]\n",
      "Train:  98%|█████████▊| 1144/1163 [5:35:38<05:29, 17.36s/it]\n",
      "Train:  98%|█████████▊| 1145/1163 [5:35:56<05:15, 17.53s/it]\n",
      "                                                            \n",
      "\n",
      "Train:  98%|█████████▊| 1145/1163 [5:35:56<05:15, 17.53s/it]\n",
      "Train:  98%|█████████▊| 1145/1163 [5:35:56<05:15, 17.53s/it]\n",
      "Train:  99%|█████████▊| 1146/1163 [5:36:14<04:56, 17.42s/it]\n",
      "Train:  99%|█████████▊| 1147/1163 [5:36:32<04:41, 17.61s/it]\n",
      "Train:  99%|█████████▊| 1148/1163 [5:36:49<04:23, 17.57s/it]\n",
      "Train:  99%|█████████▉| 1149/1163 [5:37:06<04:04, 17.46s/it]\n",
      "Train:  99%|█████████▉| 1150/1163 [5:37:24<03:47, 17.46s/it]\n",
      "                                                            \n",
      "\n",
      "Train:  99%|█████████▉| 1150/1163 [5:37:24<03:47, 17.46s/it]\n",
      "Train:  99%|█████████▉| 1150/1163 [5:37:24<03:47, 17.46s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v12-20250928-082402/checkpoint-1150\n",
      "\n",
      "Train:  99%|█████████▉| 1151/1163 [5:37:43<03:34, 17.90s/it]\n",
      "Train:  99%|█████████▉| 1152/1163 [5:38:00<03:15, 17.79s/it]\n",
      "Train:  99%|█████████▉| 1153/1163 [5:38:18<02:57, 17.74s/it]\n",
      "Train:  99%|█████████▉| 1154/1163 [5:38:35<02:38, 17.59s/it]\n",
      "Train:  99%|█████████▉| 1155/1163 [5:38:52<02:18, 17.26s/it]\n",
      "                                                            \n",
      "{'loss': 1.95553932, 'token_acc': 0.57660654, 'grad_norm': 1.19273508, 'learning_rate': 4.37e-06, 'memory(GiB)': 22.46, 'train_speed(iter/s)': 0.05681, 'epoch': 0.87, 'global_step/max_steps': '1015/1163', 'percentage': '87.27%', 'elapsed_time': '4h 57m 46s', 'remaining_time': '43m 25s'}\n",
      "{'loss': 1.87168922, 'token_acc': 0.59814844, 'grad_norm': 1.23753321, 'learning_rate': 4.08e-06, 'memory(GiB)': 22.46, 'train_speed(iter/s)': 0.056808, 'epoch': 0.88, 'global_step/max_steps': '1020/1163', 'percentage': '87.70%', 'elapsed_time': '4h 59m 14s', 'remaining_time': '41m 57s'}\n",
      "{'loss': 1.79272556, 'token_acc': 0.60748565, 'grad_norm': 1.25344265, 'learning_rate': 3.81e-06, 'memory(GiB)': 22.46, 'train_speed(iter/s)': 0.056796, 'epoch': 0.88, 'global_step/max_steps': '1025/1163', 'percentage': '88.13%', 'elapsed_time': '5h 0m 46s', 'remaining_time': '40m 29s'}\n",
      "{'loss': 1.89231644, 'token_acc': 0.59752755, 'grad_norm': 1.51880288, 'learning_rate': 3.54e-06, 'memory(GiB)': 22.46, 'train_speed(iter/s)': 0.056801, 'epoch': 0.89, 'global_step/max_steps': '1030/1163', 'percentage': '88.56%', 'elapsed_time': '5h 2m 13s', 'remaining_time': '39m 1s'}\n",
      "{'loss': 1.91366711, 'token_acc': 0.59132971, 'grad_norm': 1.50815856, 'learning_rate': 3.28e-06, 'memory(GiB)': 22.46, 'train_speed(iter/s)': 0.056806, 'epoch': 0.89, 'global_step/max_steps': '1035/1163', 'percentage': '88.99%', 'elapsed_time': '5h 3m 39s', 'remaining_time': '37m 33s'}\n",
      "{'loss': 2.00576859, 'token_acc': 0.56877661, 'grad_norm': 1.90443158, 'learning_rate': 3.03e-06, 'memory(GiB)': 22.46, 'train_speed(iter/s)': 0.056808, 'epoch': 0.89, 'global_step/max_steps': '1040/1163', 'percentage': '89.42%', 'elapsed_time': '5h 5m 7s', 'remaining_time': '36m 5s'}\n",
      "{'loss': 1.97117691, 'token_acc': 0.57653061, 'grad_norm': 1.33541763, 'learning_rate': 2.79e-06, 'memory(GiB)': 22.46, 'train_speed(iter/s)': 0.056807, 'epoch': 0.9, 'global_step/max_steps': '1045/1163', 'percentage': '89.85%', 'elapsed_time': '5h 6m 35s', 'remaining_time': '34m 37s'}\n",
      "{'loss': 2.02240295, 'token_acc': 0.56743151, 'grad_norm': 1.38194537, 'learning_rate': 2.56e-06, 'memory(GiB)': 22.46, 'train_speed(iter/s)': 0.05681, 'epoch': 0.9, 'global_step/max_steps': '1050/1163', 'percentage': '90.28%', 'elapsed_time': '5h 8m 2s', 'remaining_time': '33m 9s'}\n",
      "{'loss': 1.84407997, 'token_acc': 0.60206288, 'grad_norm': 1.35894799, 'learning_rate': 2.34e-06, 'memory(GiB)': 22.46, 'train_speed(iter/s)': 0.056806, 'epoch': 0.91, 'global_step/max_steps': '1055/1163', 'percentage': '90.71%', 'elapsed_time': '5h 9m 31s', 'remaining_time': '31m 41s'}\n",
      "{'loss': 1.89220238, 'token_acc': 0.59975753, 'grad_norm': 1.66547072, 'learning_rate': 2.13e-06, 'memory(GiB)': 22.46, 'train_speed(iter/s)': 0.056808, 'epoch': 0.91, 'global_step/max_steps': '1060/1163', 'percentage': '91.14%', 'elapsed_time': '5h 10m 58s', 'remaining_time': '30m 13s'}\n",
      "{'loss': 1.93005791, 'token_acc': 0.58390573, 'grad_norm': 1.48641086, 'learning_rate': 1.93e-06, 'memory(GiB)': 22.46, 'train_speed(iter/s)': 0.056815, 'epoch': 0.92, 'global_step/max_steps': '1065/1163', 'percentage': '91.57%', 'elapsed_time': '5h 12m 24s', 'remaining_time': '28m 44s'}\n",
      "{'loss': 1.85361099, 'token_acc': 0.60495744, 'grad_norm': 1.69223213, 'learning_rate': 1.74e-06, 'memory(GiB)': 22.46, 'train_speed(iter/s)': 0.056813, 'epoch': 0.92, 'global_step/max_steps': '1070/1163', 'percentage': '92.00%', 'elapsed_time': '5h 13m 53s', 'remaining_time': '27m 16s'}\n",
      "{'loss': 1.88895798, 'token_acc': 0.59738782, 'grad_norm': 1.34799683, 'learning_rate': 1.56e-06, 'memory(GiB)': 22.46, 'train_speed(iter/s)': 0.056811, 'epoch': 0.93, 'global_step/max_steps': '1075/1163', 'percentage': '92.43%', 'elapsed_time': '5h 15m 21s', 'remaining_time': '25m 48s'}\n",
      "{'loss': 2.0181076, 'token_acc': 0.56316398, 'grad_norm': 1.42009771, 'learning_rate': 1.39e-06, 'memory(GiB)': 22.46, 'train_speed(iter/s)': 0.056807, 'epoch': 0.93, 'global_step/max_steps': '1080/1163', 'percentage': '92.86%', 'elapsed_time': '5h 16m 51s', 'remaining_time': '24m 21s'}\n",
      "{'loss': 1.87068977, 'token_acc': 0.59399804, 'grad_norm': 1.50827515, 'learning_rate': 1.23e-06, 'memory(GiB)': 22.46, 'train_speed(iter/s)': 0.056808, 'epoch': 0.93, 'global_step/max_steps': '1085/1163', 'percentage': '93.29%', 'elapsed_time': '5h 18m 18s', 'remaining_time': '22m 53s'}\n",
      "{'loss': 1.85043354, 'token_acc': 0.60347894, 'grad_norm': 1.49117613, 'learning_rate': 1.07e-06, 'memory(GiB)': 22.46, 'train_speed(iter/s)': 0.056805, 'epoch': 0.94, 'global_step/max_steps': '1090/1163', 'percentage': '93.72%', 'elapsed_time': '5h 19m 47s', 'remaining_time': '21m 25s'}\n",
      "{'loss': 1.88291836, 'token_acc': 0.59628647, 'grad_norm': 1.63425243, 'learning_rate': 9.3e-07, 'memory(GiB)': 22.46, 'train_speed(iter/s)': 0.056801, 'epoch': 0.94, 'global_step/max_steps': '1095/1163', 'percentage': '94.15%', 'elapsed_time': '5h 21m 17s', 'remaining_time': '19m 57s'}\n",
      "{'loss': 1.94772549, 'token_acc': 0.58208718, 'grad_norm': 1.5270083, 'learning_rate': 8e-07, 'memory(GiB)': 22.46, 'train_speed(iter/s)': 0.056801, 'epoch': 0.95, 'global_step/max_steps': '1100/1163', 'percentage': '94.58%', 'elapsed_time': '5h 22m 45s', 'remaining_time': '18m 29s'}\n",
      "{'loss': 1.98101292, 'token_acc': 0.57605079, 'grad_norm': 1.40449262, 'learning_rate': 6.8e-07, 'memory(GiB)': 22.46, 'train_speed(iter/s)': 0.056792, 'epoch': 0.95, 'global_step/max_steps': '1105/1163', 'percentage': '95.01%', 'elapsed_time': '5h 24m 16s', 'remaining_time': '17m 1s'}\n",
      "{'loss': 1.90314331, 'token_acc': 0.58782874, 'grad_norm': 1.32873428, 'learning_rate': 5.7e-07, 'memory(GiB)': 22.46, 'train_speed(iter/s)': 0.056799, 'epoch': 0.96, 'global_step/max_steps': '1110/1163', 'percentage': '95.44%', 'elapsed_time': '5h 25m 42s', 'remaining_time': '15m 33s'}\n",
      "{'loss': 1.85303059, 'token_acc': 0.60083545, 'grad_norm': 1.63825583, 'learning_rate': 4.7e-07, 'memory(GiB)': 22.46, 'train_speed(iter/s)': 0.056792, 'epoch': 0.96, 'global_step/max_steps': '1115/1163', 'percentage': '95.87%', 'elapsed_time': '5h 27m 12s', 'remaining_time': '14m 5s'}\n",
      "{'loss': 1.86403656, 'token_acc': 0.60180433, 'grad_norm': 1.49730897, 'learning_rate': 3.7e-07, 'memory(GiB)': 22.46, 'train_speed(iter/s)': 0.056792, 'epoch': 0.96, 'global_step/max_steps': '1120/1163', 'percentage': '96.30%', 'elapsed_time': '5h 28m 40s', 'remaining_time': '12m 37s'}\n",
      "{'loss': 1.91199436, 'token_acc': 0.59371532, 'grad_norm': 1.76668394, 'learning_rate': 2.9e-07, 'memory(GiB)': 22.46, 'train_speed(iter/s)': 0.056798, 'epoch': 0.97, 'global_step/max_steps': '1125/1163', 'percentage': '96.73%', 'elapsed_time': '5h 30m 6s', 'remaining_time': '11m 9s'}\n",
      "{'loss': 1.87104816, 'token_acc': 0.59582447, 'grad_norm': 1.23698497, 'learning_rate': 2.2e-07, 'memory(GiB)': 22.46, 'train_speed(iter/s)': 0.056791, 'epoch': 0.97, 'global_step/max_steps': '1130/1163', 'percentage': '97.16%', 'elapsed_time': '5h 31m 37s', 'remaining_time': '9m 41s'}\n",
      "{'loss': 1.89753933, 'token_acc': 0.58934796, 'grad_norm': 1.47906804, 'learning_rate': 1.6e-07, 'memory(GiB)': 22.46, 'train_speed(iter/s)': 0.056793, 'epoch': 0.98, 'global_step/max_steps': '1135/1163', 'percentage': '97.59%', 'elapsed_time': '5h 33m 4s', 'remaining_time': '8m 13s'}\n",
      "{'loss': 1.88475914, 'token_acc': 0.59737956, 'grad_norm': 1.53758097, 'learning_rate': 1.1e-07, 'memory(GiB)': 22.46, 'train_speed(iter/s)': 0.0568, 'epoch': 0.98, 'global_step/max_steps': '1140/1163', 'percentage': '98.02%', 'elapsed_time': '5h 34m 30s', 'remaining_time': '6m 44s'}\n",
      "{'loss': 2.07217216, 'token_acc': 0.55813821, 'grad_norm': 1.24643672, 'learning_rate': 7e-08, 'memory(GiB)': 22.46, 'train_speed(iter/s)': 0.056803, 'epoch': 0.99, 'global_step/max_steps': '1145/1163', 'percentage': '98.45%', 'elapsed_time': '5h 35m 56s', 'remaining_time': '5m 16s'}\n",
      "{'loss': 1.94158401, 'token_acc': 0.58341198, 'grad_norm': 1.26454473, 'learning_rate': 3e-08, 'memory(GiB)': 22.46, 'train_speed(iter/s)': 0.056805, 'epoch': 0.99, 'global_step/max_steps': '1150/1163', 'percentage': '98.88%', 'elapsed_time': '5h 37m 24s', 'remaining_time': '3m 48s'}\n",
      "{'loss': 2.02101917, 'token_acc': 0.57124214, 'grad_norm': 1.52176332, 'learning_rate': 1e-08, 'memory(GiB)': 22.46, 'train_speed(iter/s)': 0.056806, 'epoch': 0.99, 'global_step/max_steps': '1155/1163', 'percentage': '99.31%', 'elapsed_time': '5h 38m 52s', 'remaining_time': '2m 20s'}\n",
      "Train:  99%|█████████▉| 1155/1163 [5:38:52<02:18, 17.26s/it]\n",
      "Train:  99%|█████████▉| 1155/1163 [5:38:52<02:18, 17.26s/it]\n",
      "Train:  99%|█████████▉| 1156/1163 [5:39:09<02:02, 17.45s/it]\n",
      "Train:  99%|█████████▉| 1157/1163 [5:39:26<01:43, 17.27s/it]\n",
      "Train: 100%|█████████▉| 1158/1163 [5:39:43<01:25, 17.14s/it]\n",
      "Train: 100%|█████████▉| 1159/1163 [5:40:00<01:08, 17.11s/it]\n",
      "Train: 100%|█████████▉| 1160/1163 [5:40:19<00:52, 17.55s/it]\n",
      "                                                            \n",
      "\n",
      "Train: 100%|█████████▉| 1160/1163 [5:40:19<00:52, 17.55s/it]\n",
      "Train: 100%|█████████▉| 1160/1163 [5:40:19<00:52, 17.55s/it]\n",
      "Train: 100%|█████████▉| 1161/1163 [5:40:37<00:35, 17.61s/it]\n",
      "Train: 100%|█████████▉| 1162/1163 [5:40:54<00:17, 17.58s/it]\n",
      "Train: 100%|██████████| 1163/1163 [5:40:55<00:00, 12.64s/it][INFO:swift] Saving model checkpoint to /mnt/workspace/output/v12-20250928-082402/checkpoint-1163\n",
      "\n",
      "                                                            \n",
      "\n",
      "Train: 100%|██████████| 1163/1163 [5:40:57<00:00, 12.64s/it]\n",
      "Train: 100%|██████████| 1163/1163 [5:40:57<00:00, 12.64s/it]\n",
      "Train: 100%|██████████| 1163/1163 [5:40:57<00:00, 17.59s/it]\n",
      "[INFO:swift] last_model_checkpoint: /mnt/workspace/output/v12-20250928-082402/checkpoint-1163\n",
      "[INFO:swift] best_model_checkpoint: None\n",
      "[INFO:swift] images_dir: /mnt/workspace/output/v12-20250928-082402/images\n",
      "[INFO:swift] End time of running main: 2025-09-28 14:08:48.085814\n",
      "\n",
      "{'loss': 1.85713425, 'token_acc': 0.59883066, 'grad_norm': 1.30872047, 'learning_rate': 0.0, 'memory(GiB)': 22.46, 'train_speed(iter/s)': 0.056808, 'epoch': 1.0, 'global_step/max_steps': '1160/1163', 'percentage': '99.74%', 'elapsed_time': '5h 40m 19s', 'remaining_time': '52s'}\n",
      "{'train_runtime': 20457.4981, 'train_samples_per_second': 1.818, 'train_steps_per_second': 0.057, 'train_loss': 2.00754228, 'epoch': 1.0, 'global_step/max_steps': '1163/1163', 'percentage': '100.00%', 'elapsed_time': '5h 40m 57s', 'remaining_time': '0s'}\n",
      "\n",
      "\n",
      "结束时间: 2025-09-28 14:08:50\n",
      "总执行时间: 5:45:04\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import os\n",
    "import sys\n",
    "!pip install git+https://github.com/mobiusml/hqq.git; \n",
    "'''\n",
    "nohup bash -c \" \\\n",
    "CUDA_VISIBLE_DEVICES=0 \\\n",
    "swift sft \\\n",
    "    --model Qwen/Qwen2.5-7B-Instruct \\\n",
    "    --train_type lora \\\n",
    "    --dataset '/mnt/workspace/final_data/train.json' \\\n",
    "    --torch_dtype bfloat16 \\\n",
    "    --quant_method hqq \\\n",
    "    --quant_bits 4 \\\n",
    "    --num_train_epochs 1 \\\n",
    "    --per_device_train_batch_size 2 \\\n",
    "    --per_device_eval_batch_size 1 \\\n",
    "    --learning_rate 1e-4 \\\n",
    "    --lora_rank 8 \\\n",
    "    --lora_alpha 32 \\\n",
    "    --target_modules all-linear \\\n",
    "    --gradient_accumulation_steps 16 \\\n",
    "    --eval_steps 50 \\\n",
    "    --save_steps 50 \\\n",
    "    --save_total_limit 2 \\\n",
    "    --logging_steps 5 \\\n",
    "    --max_length 1024 \\\n",
    "    --output_dir output \\\n",
    "    --system 'You are a helpful assistant.' \\\n",
    "    --warmup_ratio 0.05 \\\n",
    "    --dataloader_num_workers 4 \\\n",
    "    --model_author swift \\\n",
    "    --model_name swift-robot \\\n",
    "\" &\n",
    "'''\n",
    "def run_swift_sft():\n",
    "    # 记录开始时间\n",
    "    start_time = time.time()\n",
    "    print(f\"开始时间: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(start_time))}\\n\")\n",
    "    \n",
    "    # 构建要执行的命令列表\n",
    "    command_list = [\n",
    "        \"swift\", \"sft\",\n",
    "        \"--model\", \"Qwen/Qwen2.5-7B-Instruct\",\n",
    "        \"--train_type\", \"lora\",\n",
    "        \"--dataset\", \"/mnt/workspace/final_data/train.json\",\n",
    "        \"--torch_dtype\", \"bfloat16\",\n",
    "        \"--quant_method\", \"hqq\",\n",
    "        \"--quant_bits\", \"4\",\n",
    "        \"--num_train_epochs\", \"1\",\n",
    "        \"--per_device_train_batch_size\", \"2\",\n",
    "        \"--per_device_eval_batch_size\", \"1\",\n",
    "        \"--learning_rate\", \"1e-4\",\n",
    "        \"--lora_rank\", \"8\",\n",
    "        \"--lora_alpha\", \"32\",\n",
    "        \"--gradient_accumulation_steps\", \"16\",\n",
    "        \"--eval_steps\", \"50\",\n",
    "        \"--save_steps\", \"50\",\n",
    "        \"--save_total_limit\", \"2\",\n",
    "        \"--logging_steps\", \"5\",\n",
    "        \"--max_length\", \"1024\",\n",
    "        \"--output_dir\", \"output\",\n",
    "        \"--system\", \"You are a helpful assistant.\",\n",
    "        \"--warmup_ratio\", \"0.05\",\n",
    "        \"--dataloader_num_workers\", \"4\",\n",
    "        \"--model_author\", \"swift\",\n",
    "        \"--model_name\", \"swift-robot\"\n",
    "    ]\n",
    "    # 显示命令回显\n",
    "    print(\"即将执行的命令:\")\n",
    "    print(f\"CUDA_VISIBLE_DEVICES=0 { ' '.join(command_list) }\\n\")\n",
    "    print(\"开始执行命令，实时日志如下：\\n\")\n",
    "    \n",
    "    try:\n",
    "        # 设置环境变量\n",
    "        env = dict(os.environ)\n",
    "        env[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "        \n",
    "        # 执行命令并实时输出日志\n",
    "        process = subprocess.Popen(\n",
    "            command_list,\n",
    "            env=env,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.STDOUT,\n",
    "            text=True,\n",
    "            bufsize=1  # 行缓冲\n",
    "        )\n",
    "        \n",
    "        # 实时读取并打印输出\n",
    "        for line in process.stdout:\n",
    "            print(line, end='')  # end='' 避免重复换行\n",
    "            sys.stdout.flush()  # 强制刷新输出缓冲区\n",
    "            \n",
    "        # 等待进程完成并获取返回码\n",
    "        return_code = process.wait()\n",
    "        if return_code != 0:\n",
    "            raise subprocess.CalledProcessError(return_code, command_list)\n",
    "        \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"\\n\\n命令执行出错，返回码: {e.returncode}\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"\\n\\n发生异常: {e}\")\n",
    "        return\n",
    "    \n",
    "    # 记录结束时间\n",
    "    end_time = time.time()\n",
    "    print(f\"\\n\\n结束时间: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(end_time))}\")\n",
    "    \n",
    "    # 计算并输出时间差\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"总执行时间: {timedelta(seconds=int(elapsed_time))}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_swift_sft()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c1fd4e-a9e3-44de-859c-016dee66f862",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
